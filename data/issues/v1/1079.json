{
  "url": "https://api.github.com/repos/shap/shap/issues/1079",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1079/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1079/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1079/events",
  "html_url": "https://github.com/shap/shap/issues/1079",
  "id": 574030609,
  "node_id": "MDU6SXNzdWU1NzQwMzA2MDk=",
  "number": 1079,
  "title": "Error using DeepExplainer in TF 2.1",
  "user": {
    "login": "Labaien96",
    "id": 37838057,
    "node_id": "MDQ6VXNlcjM3ODM4MDU3",
    "avatar_url": "https://avatars.githubusercontent.com/u/37838057?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Labaien96",
    "html_url": "https://github.com/Labaien96",
    "followers_url": "https://api.github.com/users/Labaien96/followers",
    "following_url": "https://api.github.com/users/Labaien96/following{/other_user}",
    "gists_url": "https://api.github.com/users/Labaien96/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Labaien96/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Labaien96/subscriptions",
    "organizations_url": "https://api.github.com/users/Labaien96/orgs",
    "repos_url": "https://api.github.com/users/Labaien96/repos",
    "events_url": "https://api.github.com/users/Labaien96/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Labaien96/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2020-03-02T14:56:11Z",
  "updated_at": "2021-02-22T23:10:03Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello,\r\n\r\nI am having some problems with both the DeepExplainer and the GradientExplainer in TensorFlow 2.1. I use a Keras model called rrn_model, that it is composed by an LSTM, an attention layer and a softmax, and when I run the following:\r\n\r\nimport shap\r\ne = shap.DeepExplainer(rnn_model, features_test[0:100])\r\nshap_val = e.shap_values(features_test[0:100])\r\n\r\nI get this error:\r\n\r\n\r\nStagingError: in converted code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/shap/explainers/deep/deep_tf.py:244 grad_graph  *\r\n        x_grad = tape.gradient(out, shap_rAnD)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py:1029 gradient\r\n        unconnected_gradients=unconnected_gradients)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py:77 imperative_grad\r\n        compat.as_str(unconnected_gradients.value))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py:137 _gradient_function\r\n        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/registry.py:97 lookup\r\n        \"%s registry has no entry for: %s\" % (self._name, name))\r\n\r\n    LookupError: gradient registry has no entry for: shap_BatchMatMulV2\r\n\r\nDoes somebody know what does it mean?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1079/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1079/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
