{
  "url": "https://api.github.com/repos/shap/shap/issues/1365",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1365/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1365/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1365/events",
  "html_url": "https://github.com/shap/shap/issues/1365",
  "id": 679166081,
  "node_id": "MDU6SXNzdWU2NzkxNjYwODE=",
  "number": 1365,
  "title": "Proposal for adding functionality 'calculating + accessing individual feature contributions in the case that link=\"logit\"'",
  "user": {
    "login": "jasper-vdm",
    "id": 57139655,
    "node_id": "MDQ6VXNlcjU3MTM5NjU1",
    "avatar_url": "https://avatars.githubusercontent.com/u/57139655?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jasper-vdm",
    "html_url": "https://github.com/jasper-vdm",
    "followers_url": "https://api.github.com/users/jasper-vdm/followers",
    "following_url": "https://api.github.com/users/jasper-vdm/following{/other_user}",
    "gists_url": "https://api.github.com/users/jasper-vdm/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jasper-vdm/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jasper-vdm/subscriptions",
    "organizations_url": "https://api.github.com/users/jasper-vdm/orgs",
    "repos_url": "https://api.github.com/users/jasper-vdm/repos",
    "events_url": "https://api.github.com/users/jasper-vdm/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jasper-vdm/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-08-14T13:42:26Z",
  "updated_at": "2020-08-14T13:42:26Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "In some cases (e.g. when applying the TreeExplainer to a LightGBM classifier for the UCI Adult income dataset), it does not seem currently possible to directly extract the expected value and the SHAP values in a 'link=\"identity\"'-like way.\r\n\r\nWhen instantiating an explainer with link=\"identity\", the base_value[i] and model_output_value[i][j] for output class i and instance j from test dataset X_test are simply equal to\r\n\r\n- base_value[i] = explainer.expected_value[i]\r\n- model_output_value[i][j] = explainer.expected_value[i] + sum(explainer.shap_values(X=X_test)[i][j,:] )\r\n\r\nThis has the advantage that not only the base_value[i] and model_output_value[i][j] are straightforward to calculate, but also that the each individual feature contribution contribution_feature_k[i][j,k] for the k-th feature is directly equal to its corresponding SHAP value, i.e.\r\n\r\n- contribution_feature_k[i][j,k] =  explainer.shap_values(X=X_test)[i][j,k]\r\n\r\nOn the other hand, if we are restricted to using link=\"logit\" (e.g. when applying the TreeExplainer to a LightGBM classifier for the UCI Adult income dataset), we have to calculate base_value[i] and model_output_value[i][j,:] for class i and instance j from test dataset X_test as follows:\r\n\r\n- base_value[i] = convert_func(explainer.expected_value[i])\r\n- model_output_value[i][j] = convert_func(explainer.expected_value[i] + sum(explainer.shap_values(X=X_test)[i][j,:]))\r\n\r\nwhereby convert_func = lambda x: 1 / (1 + np.exp(-x)) is the _logit_inverse-function (also defined in shap/shap/links.py). This approach is used in the function format_data(data) in shap/shap/plots/_force_matplotlib.py to prepare the data for plotting. \r\n\r\nCalculating the individual feature contributions (contribution_feature_k[i][j,k] for the k-th feature) to the model_output_value[i][j,:] is a more complex challenge and seems ambiguous since its contribution depends on when the contribution is added to x in the _logit_inverse-function \r\ne.g. imagine that all SHAP values explainer.shap_values(X=X_test)[i][j,:] for output class i and instance j of X_test have the same sign, the contribution contribution_feature_k[i][j,k] of the k-th feature to the model_output_value[i][j] will be larger when calculated using the following equation\r\n\r\n- contribution_feature_k[i][j,k] = convert_func(explainer.expected_value[i] + explainer.expected_value(X=X_test)[i][j,k]) -  convert_func(explainer.expected_value[i])\r\n\r\nthan when calculated using the following equation\r\n\r\n- contribution_feature_k[i][j,k] = convert_func(explainer.expected_value[i] + sum(explainer.shap_values(X=X_test)[i][j,:])) - convert_func(explainer.expected_value[i] + sum(explainer.shap_values(X=X_test)[i][j,:]) - explainer.expected_value(X=X_test)[i][j,k])\r\n\r\nThe correct way to calculate the feature contribution contribution_feature_k[i][j,k] is then to treat the different possible sums in a Shapley-like way. However, this is computationally very inefficient. Therefore, I would like to suggest to use a stepwise approximate method, thereby ensuring that the following equation remains valid:\r\n\r\n- model_output_value[i][j] = base_value[i] + sum(contribution_feature_k[i][j,:])\r\n\r\nI have experimented a little bit with this method and it gives promising results. Would it be worthwile adding a functionality to the shap-package so that these approximate contributions contribution_feature_k[i][j,:] as well as base_value[i] and model_output_value[i][j] can be accessed directly by the user in the case that link=\"logit\"?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1365/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1365/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
