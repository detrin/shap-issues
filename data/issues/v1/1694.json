{
  "url": "https://api.github.com/repos/shap/shap/issues/1694",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1694/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1694/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1694/events",
  "html_url": "https://github.com/shap/shap/issues/1694",
  "id": 773518362,
  "node_id": "MDU6SXNzdWU3NzM1MTgzNjI=",
  "number": 1694,
  "title": "AttributeError: 'KerasTensor' object has no attribute 'graph'",
  "user": {
    "login": "imrankhan441",
    "id": 26671669,
    "node_id": "MDQ6VXNlcjI2NjcxNjY5",
    "avatar_url": "https://avatars.githubusercontent.com/u/26671669?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/imrankhan441",
    "html_url": "https://github.com/imrankhan441",
    "followers_url": "https://api.github.com/users/imrankhan441/followers",
    "following_url": "https://api.github.com/users/imrankhan441/following{/other_user}",
    "gists_url": "https://api.github.com/users/imrankhan441/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/imrankhan441/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/imrankhan441/subscriptions",
    "organizations_url": "https://api.github.com/users/imrankhan441/orgs",
    "repos_url": "https://api.github.com/users/imrankhan441/repos",
    "events_url": "https://api.github.com/users/imrankhan441/events{/privacy}",
    "received_events_url": "https://api.github.com/users/imrankhan441/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 24,
  "created_at": "2020-12-23T06:20:25Z",
  "updated_at": "2022-07-01T08:15:10Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "# **Code**\r\n```\r\n!pip install -U tensorflow\r\n!pip install -U keras\r\n!pip install -U shap\r\n\r\n# This model training code is directly from:\r\n# https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\r\n\r\n'''Trains an LSTM model on the IMDB sentiment classification task.\r\nThe dataset is actually too small for LSTM to be of any advantage\r\ncompared to simpler, much faster methods such as TF-IDF + LogReg.\r\n# Notes\r\n- RNNs are tricky. Choice of batch size is important,\r\nchoice of loss and optimizer is critical, etc.\r\nSome configurations won't converge.\r\n- LSTM loss decrease patterns during training can be quite different\r\nfrom what you see with CNNs/MLPs/etc.\r\n'''\r\nfrom __future__ import print_function\r\n\r\nfrom keras.preprocessing import sequence\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Embedding\r\nfrom keras.layers import LSTM\r\nfrom keras.datasets import imdb\r\n\r\nmax_features = 20000\r\nmaxlen = 80  # cut texts after this number of words (among top max_features most common words)\r\nbatch_size = 32\r\n\r\nprint('Loading data...')\r\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\nprint(len(x_train), 'train sequences')\r\nprint(len(x_test), 'test sequences')\r\n\r\nprint('Pad sequences (samples x time)')\r\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\r\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\r\nprint('x_train shape:', x_train.shape)\r\nprint('x_test shape:', x_test.shape)\r\n\r\nprint('Build model...')\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features, 128))\r\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\n\r\n# try using different optimizers and different optimizer configs\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\nprint('Train...')\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=15,\r\n          validation_data=(x_test, y_test))\r\nscore, acc = model.evaluate(x_test, y_test,\r\n                            batch_size=batch_size)\r\nprint('Test score:', score)\r\nprint('Test accuracy:', acc)\r\n\r\n\r\nimport shap\r\n\r\n# we use the first 100 training examples as our background dataset to integrate over\r\nexplainer = shap.DeepExplainer(model, x_train[:100])\r\n\r\n# explain the first 10 predictions\r\n# explaining each prediction requires 2 * background dataset size runs\r\nshap_values = explainer.shap_values(x_test[:10])\r\n\r\n# init the JS visualization code\r\nshap.initjs()\r\n\r\n# transform the indexes to words\r\nimport numpy as np\r\nwords = imdb.get_word_index()\r\nnum2word = {}\r\nfor w in words.keys():\r\n    num2word[words[w]] = w\r\nx_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, \"NONE\"), x_test[i]))) for i in range(10)])\r\n\r\n# plot the explanation of the first prediction\r\n# Note the model is \"multi-output\" because it is rank-2 but only has one column\r\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], x_test_words[0])\r\n\r\n```\r\n\r\n\r\n\r\n# **Error**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-13-d0b49e7ececc> in <module>\r\n      2 \r\n      3 # we use the first 100 training examples as our background dataset to integrate over\r\n----> 4 explainer = shap.DeepExplainer(model, x_train[:100])\r\n      5 \r\n      6 # explain the first 10 predictions\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/shap/explainers/_deep/__init__.py in __init__(self, model, data, session, learning_phase_flags)\r\n     82 \r\n     83         if framework == 'tensorflow':\r\n---> 84             self.explainer = TFDeep(model, data, session, learning_phase_flags)\r\n     85         elif framework == 'pytorch':\r\n     86             self.explainer = PyTorchDeep(model, data)\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/shap/explainers/_deep/deep_tf.py in __init__(self, model, data, session, learning_phase_flags)\r\n    129             self.session = _get_session(session)\r\n    130 \r\n--> 131         self.graph = _get_graph(self)\r\n    132 \r\n    133         # if no learning phase flags were given we go looking for them\r\n\r\n/srv/conda/envs/notebook/lib/python3.7/site-packages/shap/explainers/tf_utils.py in _get_graph(explainer)\r\n     44         return explainer.session.graph\r\n     45     else:\r\n---> 46         return explainer.model_output.graph\r\n     47 \r\n     48 def _get_model_inputs(model):\r\n\r\nAttributeError: 'KerasTensor' object has no attribute 'graph'\r\n\r\n```\r\n\r\n\r\n# **Please Fix this as soon as possible**",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1694/reactions",
    "total_count": 23,
    "+1": 23,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1694/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
