{
  "url": "https://api.github.com/repos/shap/shap/issues/1935",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1935/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1935/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1935/events",
  "html_url": "https://github.com/shap/shap/issues/1935",
  "id": 856803859,
  "node_id": "MDU6SXNzdWU4NTY4MDM4NTk=",
  "number": 1935,
  "title": "new_base_value meaning",
  "user": {
    "login": "alberto-bracci",
    "id": 52134230,
    "node_id": "MDQ6VXNlcjUyMTM0MjMw",
    "avatar_url": "https://avatars.githubusercontent.com/u/52134230?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/alberto-bracci",
    "html_url": "https://github.com/alberto-bracci",
    "followers_url": "https://api.github.com/users/alberto-bracci/followers",
    "following_url": "https://api.github.com/users/alberto-bracci/following{/other_user}",
    "gists_url": "https://api.github.com/users/alberto-bracci/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/alberto-bracci/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/alberto-bracci/subscriptions",
    "organizations_url": "https://api.github.com/users/alberto-bracci/orgs",
    "repos_url": "https://api.github.com/users/alberto-bracci/repos",
    "events_url": "https://api.github.com/users/alberto-bracci/events{/privacy}",
    "received_events_url": "https://api.github.com/users/alberto-bracci/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-04-13T10:04:49Z",
  "updated_at": "2021-04-13T10:04:49Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "In the decision_plot() function there is a new_base_value argument that let you show the decision path w.r.t. a different base value. \r\nIn practice, this seems to be done by simply linearly rescaling all shap values such that the new_base_value + shap values = prediction. \r\n\r\nI know this is the first heuristic one can think of, but I was wondering whether it has any physical meaning. \r\nIn general: is it possible to compute shap values w.r.t. a different baseline, maybe a different one for each prediction if we know a more meaningful best guess than the training average?\r\n\r\nFrom the theory it seems the assumptions and theorems work only if the baseline is unique and is the prediction when all features are missing. In this way the linear rescaling done with new_base_value holds no meaning though.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1935/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1935/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
