{
  "url": "https://api.github.com/repos/shap/shap/issues/865",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/865/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/865/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/865/events",
  "html_url": "https://github.com/shap/shap/issues/865",
  "id": 511998465,
  "node_id": "MDU6SXNzdWU1MTE5OTg0NjU=",
  "number": 865,
  "title": "GradientExplainer has no expected values: how to interpret it.",
  "user": {
    "login": "1vecera",
    "id": 32644386,
    "node_id": "MDQ6VXNlcjMyNjQ0Mzg2",
    "avatar_url": "https://avatars.githubusercontent.com/u/32644386?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/1vecera",
    "html_url": "https://github.com/1vecera",
    "followers_url": "https://api.github.com/users/1vecera/followers",
    "following_url": "https://api.github.com/users/1vecera/following{/other_user}",
    "gists_url": "https://api.github.com/users/1vecera/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/1vecera/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/1vecera/subscriptions",
    "organizations_url": "https://api.github.com/users/1vecera/orgs",
    "repos_url": "https://api.github.com/users/1vecera/repos",
    "events_url": "https://api.github.com/users/1vecera/events{/privacy}",
    "received_events_url": "https://api.github.com/users/1vecera/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2019-10-24T14:53:12Z",
  "updated_at": "2020-12-16T16:32:57Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I use GradientExplainer to explain a Recurrent Neural Net with a continuous target. I used KernelExplainer and switched to GradientExplainer as I expect it to be a better approximation of SHAP values. \r\n\r\n[However, it has no expected_values attr. The code is commented out.](https://github.com/slundberg/shap/blob/master/shap/explainers/gradient.py#L184)\r\n\r\nIn the documentation, it is usually written:\r\n> For models with a single output this returns a matrix of SHAP values (# samples x # features). Each row sums to the difference between the model output for that sample and the expected value of the model output (which is stored as expected_value attribute of the explainer). For models with vector outputs, this returns a list of such matrices, one for each output.\r\n\r\nSo I'm not sure how to interpret the values without the expectation. If a fix is required, can I somehow calculate it from the gradients?\r\n\r\nThanks, @slundberg ! Amazing package!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/865/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/865/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
