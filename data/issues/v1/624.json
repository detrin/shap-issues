{
  "url": "https://api.github.com/repos/shap/shap/issues/624",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/624/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/624/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/624/events",
  "html_url": "https://github.com/shap/shap/issues/624",
  "id": 450579741,
  "node_id": "MDU6SXNzdWU0NTA1Nzk3NDE=",
  "number": 624,
  "title": "ZestFinance writeup on SHAP and why it shouldn't be used on its own",
  "user": {
    "login": "InfiniteDoLoop",
    "id": 40615060,
    "node_id": "MDQ6VXNlcjQwNjE1MDYw",
    "avatar_url": "https://avatars.githubusercontent.com/u/40615060?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/InfiniteDoLoop",
    "html_url": "https://github.com/InfiniteDoLoop",
    "followers_url": "https://api.github.com/users/InfiniteDoLoop/followers",
    "following_url": "https://api.github.com/users/InfiniteDoLoop/following{/other_user}",
    "gists_url": "https://api.github.com/users/InfiniteDoLoop/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/InfiniteDoLoop/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/InfiniteDoLoop/subscriptions",
    "organizations_url": "https://api.github.com/users/InfiniteDoLoop/orgs",
    "repos_url": "https://api.github.com/users/InfiniteDoLoop/repos",
    "events_url": "https://api.github.com/users/InfiniteDoLoop/events{/privacy}",
    "received_events_url": "https://api.github.com/users/InfiniteDoLoop/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 13,
  "created_at": "2019-05-31T01:57:37Z",
  "updated_at": "2023-08-01T06:24:29Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi Scott,\r\n\r\nFirst off, thanks for the work you've done on SHAP. I think it'll definitely help people get more comfortable with ML model results and make them mainstream.\r\n\r\nI came across the following article from **ZestFinance** which references your package and was an interesting read:\r\n[Why Lenders Shouldn't 'Just Use SHAP' To Explain Machine Learning Credit Models](https://www.zestfinance.com/blog/why-you-shouldnt-just-use-shap-to-power-your-ml-explainability-requirements)\r\n\r\nIt seems to have some details on what your package is missing and what they've enhanced to make it usable for credit underwriting. Wanted to check in with you for some clarification as it seems this package does include some of these functions they describe but I could be wrong. Apologies in advance for the barrage of questions btw :)\r\n\r\n**1) Margin Space vs Score Space**\r\n\r\n> The score space is very different mathematically from the credit model’s actual output, which is said to be in “margin space.” Margin space numbers fall in a narrow range from 0 to 1. In general, the relationship between the model’s actual output in margin space and the acceptance threshold in score space is extremely non-linear, and you have to transform the model’s output to generate the number the lending business wants.\r\n\r\nIt sounds like **Margin Space** refers to raw output from obtained from XGboost model in log odds scale and **Score Space** is this output transformed to probability space since they mention it is a non-linear transformation. Is this something currently supported when running:\r\n\r\n`shap.TreeExplainer(model, model_output = 'probability', feature_dependence = \"independent\", data = X)`\r\n\r\n**2) Explanation by reference**\r\n\r\n> There are many details you need to get right in this process, including the appropriate application of sample weights, mapping to score space at the approval cut-off, sampling methods, and accompanying documentation. Out of the box, SHAP doesn’t allow you to easily do this.\r\n\r\nI think the previous code in *(1)* is still applicable here, but the sampling of X is important to obtain an appropriate reference point. As an example, let 80% be the cutoff, where a score below 80% is approved for credit. Should the subsample of X include all potential approvals or should it be sampled such that the expected value is equal to 80% to obtain a valid reference point?\r\n\r\n**3) You want to use modeling methods other than XGBoost**\r\n\r\n> What’s more, SHAP cannot explain ensembles of continuous and tree-based models, such as stacked or deeply stacked models that combine xgboost and deep neural networks.\r\n\r\nI'm sure the other model types can be tackled by the explainers included in your package. When it comes to stacking, the shap values for each variable in the stacked model can be determined by computing a weighted sum of the shap values from the individual models. Is this correct?\r\n\r\n**4) Even on a simple XGBoost model, SHAP fails to uncover the underlying geometry** \r\n\r\nI don't have a specific question on this section, but would be interested in any comments/insights you may have on why the separation of SHAP values is less distinct than what ZAML produces. \r\n\r\nThanks for your time and looking forward to seeing what you'll be working on next!\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/624/reactions",
    "total_count": 3,
    "+1": 3,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/624/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
