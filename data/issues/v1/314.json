{
  "url": "https://api.github.com/repos/shap/shap/issues/314",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/314/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/314/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/314/events",
  "html_url": "https://github.com/shap/shap/issues/314",
  "id": 378142513,
  "node_id": "MDU6SXNzdWUzNzgxNDI1MTM=",
  "number": 314,
  "title": "KernelExplainer with textual data using pipeline",
  "user": {
    "login": "ghost",
    "id": 10137,
    "node_id": "MDQ6VXNlcjEwMTM3",
    "avatar_url": "https://avatars.githubusercontent.com/u/10137?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ghost",
    "html_url": "https://github.com/ghost",
    "followers_url": "https://api.github.com/users/ghost/followers",
    "following_url": "https://api.github.com/users/ghost/following{/other_user}",
    "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ghost/subscriptions",
    "organizations_url": "https://api.github.com/users/ghost/orgs",
    "repos_url": "https://api.github.com/users/ghost/repos",
    "events_url": "https://api.github.com/users/ghost/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ghost/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 15,
  "created_at": "2018-11-07T04:54:11Z",
  "updated_at": "2020-10-01T16:43:10Z",
  "closed_at": "2018-11-13T01:12:32Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi I was looking through and I found no examples using KernelExplainer to explain text data predictions so I decided to test it out using the dataset i found on https://www.superdatascience.com/machine-learning/. \r\n\r\nI encountered a problem in the KernelExplainer part at the last bit, where I believe the problem is the way I input the data and model into the explainer. Can anyone advise me on what I should revise so as to make the explainer work? Thanks.\r\n\r\nDataset: https://drive.google.com/file/d/1-pzY7IQVyB_GmT5dT0yRx3hYzOFGrZSr/view?usp=sharing\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nimport re\r\nimport nltk\r\n\r\n#Load the data\r\nos.chdir('C:\\\\Users\\\\Win\\\\Desktop\\\\MyLearning\\\\Explainability\\\\SHAP')\r\nreview = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t')\r\n\r\n#Clean the data\r\nnltk.download('stopwords')\r\nfrom nltk.corpus import stopwords\r\nfrom nltk.stem.porter import PorterStemmer\r\n\r\ndef clean_text(df_text_column, data):   \r\n    corpus = []\r\n    for i in range(0, len(data)):\r\n        text = re.sub('[^a-zA-Z]', ' ', df_text_column[i])\r\n        text = text.lower()\r\n        text = text.split()\r\n        ps = PorterStemmer()\r\n        text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\r\n        text = ' '.join(text)\r\n        corpus.append(text)\r\n    return corpus\r\n\r\nX = pd.DataFrame({'Review':clean_text(review['Review'],review)})['Review']\r\ny = review['Liked']\r\n\r\n# Splitting the dataset into the Training set and Test set\r\nfrom sklearn.model_selection import train_test_split\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\r\n\r\n# Creating the pipeline\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nvect = TfidfVectorizer() \r\nfrom sklearn.ensemble import RandomForestClassifier\r\nrf = RandomForestClassifier()\r\nfrom sklearn.pipeline import make_pipeline\r\nnp.random.seed(0)\r\nrf_pipe = make_pipeline(vect, rf)\r\nrf_pipe.steps\r\nrf_pipe.fit(X_train, y_train)\r\n\r\ny_pred = rf_pipe.predict(X_test)\r\ny_prob = rf_pipe.predict_proba(X_test)\r\n\r\n#Performance Metrics\r\nfrom sklearn import metrics\r\nmetrics.accuracy_score(y_test, y_pred) #Accuracy\r\nmetrics.roc_auc_score(y_test, y_prob[:, 1]) #ROC-AUC score\r\n\r\n# use Kernel SHAP to explain test set predictions\r\nimport shap\r\nexplainer = shap.KernelExplainer(rf_pipe.predict_proba, X_train, link=\"logit\")\r\nshap_values = explainer.shap_values(X_test, nsamples=100)\r\n\r\n# plot the SHAP values\r\nshap.force_plot(explainer.expected_value[0], shap_values[0][0,:], X_test.iloc[0,:], link=\"logit\")\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/314/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/314/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
