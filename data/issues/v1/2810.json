{
  "url": "https://api.github.com/repos/shap/shap/issues/2810",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2810/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2810/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2810/events",
  "html_url": "https://github.com/shap/shap/issues/2810",
  "id": 1503888450,
  "node_id": "I_kwDOBHDcK85Zo4RC",
  "number": 2810,
  "title": "Import shap causes UnknownError raised (Fail to find the dnn implementation)",
  "user": {
    "login": "mxdlzg",
    "id": 18144577,
    "node_id": "MDQ6VXNlcjE4MTQ0NTc3",
    "avatar_url": "https://avatars.githubusercontent.com/u/18144577?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/mxdlzg",
    "html_url": "https://github.com/mxdlzg",
    "followers_url": "https://api.github.com/users/mxdlzg/followers",
    "following_url": "https://api.github.com/users/mxdlzg/following{/other_user}",
    "gists_url": "https://api.github.com/users/mxdlzg/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/mxdlzg/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/mxdlzg/subscriptions",
    "organizations_url": "https://api.github.com/users/mxdlzg/orgs",
    "repos_url": "https://api.github.com/users/mxdlzg/repos",
    "events_url": "https://api.github.com/users/mxdlzg/events{/privacy}",
    "received_events_url": "https://api.github.com/users/mxdlzg/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2022-12-20T02:20:47Z",
  "updated_at": "2022-12-20T02:22:10Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "# Error\r\nSimple lstm model constructed by tensorflow 2.10. Everything was fine without shap imported.\r\nBUT, if \"**import shap**\" was added, it throw an exception.\r\n\r\n**{{function_node __wrapped__CudnnRNNV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation. \t [[{{node CudnnRNNV3}}]] [Op:CudnnRNNV3]**\r\n\r\n# Code\r\n```\r\nimport argparse\r\nimport numpy as np\r\nimport shap\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom data import load_data\r\n\r\nparser = argparse.ArgumentParser(description='Deep Knowledge tracing model')\r\nparser.add_argument('-epsilon', type=float, default=0.1, help='Epsilon value for Adam Optimizer')\r\nparser.add_argument('-l2_lambda', type=float, default=0.3, help='Lambda for l2 loss')\r\nparser.add_argument('-learning_rate', type=float, default=0.1, help='Learning rate')\r\nparser.add_argument('-max_grad_norm', type=float, default=20, help='Clip gradients to this norm')\r\nparser.add_argument('-keep_prob', type=float, default=0.6, help='Keep probability for dropout')\r\nparser.add_argument('-hidden_layer_num', type=int, default=1, help='The number of hidden layers')\r\nparser.add_argument('-hidden_size', type=int, default=200, help='The number of hidden nodes')\r\nparser.add_argument('-evaluation_interval', type=int, default=1, help='Evalutaion and print result every x epochs')\r\nparser.add_argument('-batch_size', type=int, default=32, help='Batch size for training')\r\nparser.add_argument('-epochs', type=int, default=150, help='Number of epochs to train')\r\nparser.add_argument('-allow_soft_placement', type=bool, default=True, help='Allow device soft device placement')\r\nparser.add_argument('-log_device_placement', type=bool, default=False, help='Log placement ofops on devices')\r\nparser.add_argument('-train_data_path', type=str, default='data/0910_b_train.csv', help='Path to the training dataset')\r\nparser.add_argument('-test_data_path', type=str, default='data/0910_b_test.csv',help='Path to the testing dataset')\r\n\r\nargs = parser.parse_args()\r\nprint(args)\r\n\r\n\r\ntrain_data_path = args.train_data_path\r\ntest_data_path = args.test_data_path\r\nbatch_size = args.batch_size\r\ntrain_students, train_max_num_problems, train_max_skill_num = load_data(train_data_path)\r\nnum_steps = train_max_num_problems\r\nnum_skills = train_max_skill_num\r\nnum_layers = 1\r\ntest_students, test_max_num_problems, test_max_skill_num = load_data(test_data_path)\r\nseq_len = 50\r\n\r\n\r\nclass DKT(keras.Model):\r\n\tdef __init__(self, num_skills, seq_len, hidden_size, dropout_rate):\r\n\t\tsuper(DKT, self).__init__()\r\n\t\tself.num_skills = num_skills\r\n\t\tself.seq_len = seq_len\r\n\t\tself.hidden_size = hidden_size\r\n\t\tself.dropout_rate = dropout_rate\r\n\t\tself.embedding = keras.layers.Embedding(num_skills+1, hidden_size, input_length=seq_len, mask_zero=True)\r\n\t\tself.lstm = keras.layers.LSTM(self.hidden_size, return_sequences=True, return_state=True)\r\n\t\tself.dropout = keras.layers.Dropout(self.dropout_rate)\r\n\t\tself.dense = keras.layers.Dense(1, activation='sigmoid')\r\n\r\n\tdef call(self, inputs, training=True):\r\n\t\tx = self.embedding(inputs)\r\n\t\tx = self.dropout(x, training=training)\r\n\t\tx, _, _ = self.lstm(x)\r\n\t\tx = self.dropout(x, training=training)\r\n\t\tx = self.dense(x)\r\n\t\treturn x\r\n\r\n# Eager execution is an imperative programming environment that evaluates operations immediately, without building graphs\r\ntf.config.run_functions_eagerly(True)\r\n\r\nmodel = DKT(num_skills, seq_len, 128, 0.1)\r\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\r\n\r\nproblems = []\r\ncorrects = []\r\nfor i in range(len(train_students)):\r\n\tproblems.append(train_students[i][1])\r\n\tcorrects.append(train_students[i][2])\r\n\r\n\r\ntrain_students_problems = np.reshape(tf.keras.preprocessing.sequence.pad_sequences(problems, padding=\"post\", maxlen=seq_len), [-1, seq_len])\r\ntrain_students_corrects = np.reshape(tf.keras.preprocessing.sequence.pad_sequences(corrects, padding=\"post\", maxlen=seq_len, value=2), [-1,seq_len,1])\r\n\r\nproblems = []\r\ncorrects = []\r\nfor i in range(len(test_students)):\r\n\tproblems.append(test_students[i][1])\r\n\tcorrects.append(test_students[i][2])\r\n\r\ntest_students_problems = np.reshape(tf.keras.preprocessing.sequence.pad_sequences(problems, padding=\"post\", maxlen=seq_len), [-1,seq_len])\r\ntest_students_corrects = np.reshape(tf.keras.preprocessing.sequence.pad_sequences(corrects, padding=\"post\", maxlen=seq_len, value=2), [-1,seq_len,1])\r\n\r\n\r\nmodel.fit(train_students_problems, train_students_corrects, epochs=1, batch_size=batch_size, validation_data=(test_students_problems, test_students_corrects))\r\nmodel.evaluate(test_students_problems, test_students_corrects, batch_size=batch_size)\r\n\r\n\r\n## SHAP\r\nshap.initjs()\r\nshap_values = explainer.shap_values(do_test, check_additivity=False)\r\nw = shap.force_plot(explainer.expected_value[13], shap_values[13][1], [str(it) for it in do_test[1]])\r\nshap.save_html(f\"shap_pd_single%d.html\" % 0, w, False)\r\n```\r\n# Detail\r\n```F:\\anaconda3\\python.exe \"F:\\JetBrains\\PyCharm 2021.1.3\\plugins\\python\\helpers\\pydev\\pydevd.py\" --multiproc --qt-support=auto --client 127.0.0.1 --port 62623 --file F:/Work/xxx/LearningModel/DKT-explian/dkt.py\r\nConnected to pydev debugger (build 213.6461.77)\r\nNamespace(allow_soft_placement=True, batch_size=32, epochs=150, epsilon=0.1, evaluation_interval=1, hidden_layer_num=1, hidden_size=200, keep_prob=0.6, l2_lambda=0.3, learning_rate=0.1, log_device_placement=False, max_grad_norm=20, test_data_path='data/0910_b_test.csv', train_data_path='data/0910_b_train.csv')\r\nthe number of rows is 10116\r\nThe number of students is  3134\r\nFinish reading data\r\nthe number of rows is 2532\r\nThe number of students is  786\r\nFinish reading data\r\n2022-12-20 10:06:13.160514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-12-20 10:06:13.748946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1930 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970M, pci bus id: 0000:01:00.0, compute capability: 5.2\r\nEven though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\r\n2022-12-20 10:06:14.658000: E tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\r\n2022-12-20 10:06:14.660336: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at cudnn_rnn_ops.cc:1557 : UNKNOWN: Fail to find the dnn implementation.\r\nTraceback (most recent call last):\r\n  File \"f:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"F:/Work/xxx/LearningModel/DKT-explian/dkt.py\", line 57, in call\r\n    x, _, _ = self.lstm(x)\r\ntensorflow.python.framework.errors_impl.UnknownError: Exception encountered when calling layer \"lstm\" \"                 f\"(type LSTM).\r\n\r\n{{function_node __wrapped__CudnnRNNV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Fail to find the dnn implementation.\r\n\t [[{{node CudnnRNNV3}}]] [Op:CudnnRNNV3]\r\n\r\nCall arguments received by layer \"lstm\" \"                 f\"(type LSTM):\r\n  • inputs=tf.Tensor(shape=(32, 50, 128), dtype=float32)\r\n  • mask=tf.Tensor(shape=(32, 50), dtype=bool)\r\n  • training=True\r\n  • initial_state=None\r\npython-BaseException\r\n\r\nProcess finished with exit code -1073741510 (0xC000013A: interrupted by Ctrl+C)\r\n```\r\n# Env\r\nTensorflow-2.10.1\r\nshap-0.41.0\r\nnumpy-1.20.3\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2810/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2810/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
