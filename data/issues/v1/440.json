{
  "url": "https://api.github.com/repos/shap/shap/issues/440",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/440/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/440/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/440/events",
  "html_url": "https://github.com/shap/shap/issues/440",
  "id": 409046928,
  "node_id": "MDU6SXNzdWU0MDkwNDY5Mjg=",
  "number": 440,
  "title": "Question about handling pretrained embeddings variables",
  "user": {
    "login": "mattivi",
    "id": 1651448,
    "node_id": "MDQ6VXNlcjE2NTE0NDg=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1651448?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/mattivi",
    "html_url": "https://github.com/mattivi",
    "followers_url": "https://api.github.com/users/mattivi/followers",
    "following_url": "https://api.github.com/users/mattivi/following{/other_user}",
    "gists_url": "https://api.github.com/users/mattivi/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/mattivi/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/mattivi/subscriptions",
    "organizations_url": "https://api.github.com/users/mattivi/orgs",
    "repos_url": "https://api.github.com/users/mattivi/repos",
    "events_url": "https://api.github.com/users/mattivi/events{/privacy}",
    "received_events_url": "https://api.github.com/users/mattivi/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2019-02-12T00:25:39Z",
  "updated_at": "2019-03-20T11:25:05Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, \r\nI am using SHAP to explain the output of an autoencoder model built with Keras.\r\nAs input I have many numerical and categorical variables.  \r\nI am one-hot encoding variables with low cardinality, and substituting high cardinality variables with  embeddings learned on another task. E.g. instead of one-hot encoding or label encoding a variable with 8000 categories, I replace it with other 100 learned embedding features, as in this example:\r\n- original: [numerical_1, categorical_1, ...]\r\n- replaced with pretrained embeddings: [numerical_1, categorical_1_dim1, categorical_1_dim2, ..., categorical_1_dim100]\r\n\r\nFollowing #397, in case of **one-hot encoded variable**:\r\n- to explain a single category, we have already a SHAP value for the [category_0, category_1, category_2 ……]\r\n- to explain the original variable BEFORE one-hot encoding, we can take the SUM over all one-hot encoded variables (SUM over [category_0, category_1, category_2 ……])\r\n\r\nIn case of **pretrained embeddings** [categorical_1_dim1, categorical_1_dim2, ..., categorical_1_dim100].. \r\n- to explain the original variable BEFORE embeddings, we can similarly take the SUM over all dimensions (SUM over [categorical_1_dim1, categorical_1_dim2, ..., categorical_1_dim100])\r\n\r\nIs there any way that SHAP can explain the original category for the embedded feature? Back to the example, SHAP to provide a value to one or more of the original 8000 categories that were replaced with the pretrained embeddings. \r\n\r\nThanks a lot for your suggestions!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/440/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/440/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
