{
  "url": "https://api.github.com/repos/shap/shap/issues/884",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/884/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/884/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/884/events",
  "html_url": "https://github.com/shap/shap/issues/884",
  "id": 518997969,
  "node_id": "MDU6SXNzdWU1MTg5OTc5Njk=",
  "number": 884,
  "title": "Error with Pyspark GBTClassifier",
  "user": {
    "login": "allard-jeff",
    "id": 43180588,
    "node_id": "MDQ6VXNlcjQzMTgwNTg4",
    "avatar_url": "https://avatars.githubusercontent.com/u/43180588?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/allard-jeff",
    "html_url": "https://github.com/allard-jeff",
    "followers_url": "https://api.github.com/users/allard-jeff/followers",
    "following_url": "https://api.github.com/users/allard-jeff/following{/other_user}",
    "gists_url": "https://api.github.com/users/allard-jeff/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/allard-jeff/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/allard-jeff/subscriptions",
    "organizations_url": "https://api.github.com/users/allard-jeff/orgs",
    "repos_url": "https://api.github.com/users/allard-jeff/repos",
    "events_url": "https://api.github.com/users/allard-jeff/events{/privacy}",
    "received_events_url": "https://api.github.com/users/allard-jeff/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 35,
  "created_at": "2019-11-07T02:15:48Z",
  "updated_at": "2022-03-25T11:47:42Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "@QuentinAmbard \r\n\r\nI just installed Shap from PyPi (0.32.0) and running a version of your test still produces the same error - shown below. Is there something that I am missing in the use of Shap with a pyspark model?\r\n\r\n\r\n```\r\nimport pyspark\r\nprint(pyspark.__version__)\r\nimport shap\r\nprint(shap.__version__)\r\nimport sklearn.datasets\r\nfrom pyspark.sql import SparkSession\r\nfrom pyspark import SparkContext, SparkConf\r\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer\r\nfrom pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier, GBTClassifier\r\nimport pandas as pd\r\n\r\niris_sk = sklearn.datasets.load_iris()\r\niris = pd.DataFrame(data= np.c_[iris_sk['data'], iris_sk['target']], columns= iris_sk['feature_names'] + ['target'])[:100]\r\nspark = SparkSession.builder.config(conf=SparkConf().set(\"spark.master\", \"local[*]\")).getOrCreate()\r\n\r\ncol = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"type\"]\r\niris = spark.createDataFrame(iris, col)\r\niris = VectorAssembler(inputCols=col[:-1],outputCol=\"features\").transform(iris)\r\niris = StringIndexer(inputCol=\"type\", outputCol=\"label\").fit(iris).transform(iris)\r\n\r\nclassifier = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\r\nmodel = classifier.fit(iris)\r\nexplainer = shap.TreeExplainer(model)\r\nX = pd.DataFrame(data=iris_sk.data, columns=iris_sk.feature_names)[:100] # pylint: disable=E1101\r\nshap_values = explainer.shap_values(X)\r\n```\r\n\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-31-f47b3a56c25f> in <module>\r\n     23 explainer = shap.TreeExplainer(model)\r\n     24 X = pd.DataFrame(data=iris_sk.data, columns=iris_sk.feature_names)[:100] # pylint: disable=E1101\r\n---> 25 shap_values = explainer.shap_values(X)\r\n\r\n/mnt1/anaconda3/lib/python3.7/site-packages/shap/explainers/tree.py in shap_values(self, X, y, tree_limit, approximate, check_additivity)\r\n    283 \r\n    284         if check_additivity and self.model_output == \"margin\":\r\n--> 285             self.assert_additivity(out, self.model.predict(X))\r\n    286 \r\n    287         return out\r\n\r\n/mnt1/anaconda3/lib/python3.7/site-packages/shap/explainers/tree.py in predict(self, X, y, output, tree_limit)\r\n    785             import pyspark\r\n    786             #TODO support predict for pyspark\r\n--> 787             raise NotImplementedError(\"Predict with pyspark isn't implemented\")\r\n    788 \r\n    789         # see if we have a default tree_limit in place.\r\n\r\nNotImplementedError: Predict with pyspark isn't implemented\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/884/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/884/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
