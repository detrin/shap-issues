{
  "url": "https://api.github.com/repos/shap/shap/issues/2847",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2847/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2847/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2847/events",
  "html_url": "https://github.com/shap/shap/issues/2847",
  "id": 1562058507,
  "node_id": "I_kwDOBHDcK85dGx8L",
  "number": 2847,
  "title": "Does normalize Force-plot make sense?",
  "user": {
    "login": "mehrshadf",
    "id": 43025929,
    "node_id": "MDQ6VXNlcjQzMDI1OTI5",
    "avatar_url": "https://avatars.githubusercontent.com/u/43025929?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/mehrshadf",
    "html_url": "https://github.com/mehrshadf",
    "followers_url": "https://api.github.com/users/mehrshadf/followers",
    "following_url": "https://api.github.com/users/mehrshadf/following{/other_user}",
    "gists_url": "https://api.github.com/users/mehrshadf/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/mehrshadf/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/mehrshadf/subscriptions",
    "organizations_url": "https://api.github.com/users/mehrshadf/orgs",
    "repos_url": "https://api.github.com/users/mehrshadf/repos",
    "events_url": "https://api.github.com/users/mehrshadf/events{/privacy}",
    "received_events_url": "https://api.github.com/users/mehrshadf/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": true,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2023-01-30T09:26:40Z",
  "updated_at": "2023-06-03T23:58:33Z",
  "closed_at": "2023-06-03T23:58:32Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi! I tried to normalize the SHAP values (coming from Tree Explainer for a regression problem) for each observation and created a plot conceptually similar to the force plot, but the sum of SHAP values set to be equal to 1 for each sample (I wanted to see the variability of features contribution in my sample space more distinctly than the force plot). I have two questions: 1) Is this a legitimate use of SHAP values? , and 2) I observed that when the model output is very close to the “explainer.expected_value” (by comparing my plot with a normal force plot), the contribution of the feature is very different when the model output is higher and lower than “explainer.expected_value” (by very different I mean the most “important” feature based on global analysis, for example, has a smaller or comparable contribution with regard to the other features). Since I observed this behavior also for different datasets, I am now wondering if it is an inherent characteristic of my model or if SHAP value calculations are sensitive to model output being close to expectations. Thanks in advance.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2847/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2847/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
