{
  "url": "https://api.github.com/repos/shap/shap/issues/1892",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1892/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1892/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1892/events",
  "html_url": "https://github.com/shap/shap/issues/1892",
  "id": 837883769,
  "node_id": "MDU6SXNzdWU4Mzc4ODM3Njk=",
  "number": 1892,
  "title": "Are Shap feature importance (the global one) additive?",
  "user": {
    "login": "ZhangMengxia",
    "id": 17790770,
    "node_id": "MDQ6VXNlcjE3NzkwNzcw",
    "avatar_url": "https://avatars.githubusercontent.com/u/17790770?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ZhangMengxia",
    "html_url": "https://github.com/ZhangMengxia",
    "followers_url": "https://api.github.com/users/ZhangMengxia/followers",
    "following_url": "https://api.github.com/users/ZhangMengxia/following{/other_user}",
    "gists_url": "https://api.github.com/users/ZhangMengxia/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ZhangMengxia/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ZhangMengxia/subscriptions",
    "organizations_url": "https://api.github.com/users/ZhangMengxia/orgs",
    "repos_url": "https://api.github.com/users/ZhangMengxia/repos",
    "events_url": "https://api.github.com/users/ZhangMengxia/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ZhangMengxia/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-03-22T16:12:59Z",
  "updated_at": "2021-03-24T18:05:45Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Dear authors,\r\n\r\nI know that for a single observation, the Shap values for features are additive. Namely, they add up to the difference between the focal prediction and the expected prediction.\r\n\r\nThe Shap feature importance is the mean absolute Shap value for a feature (generated by the following code). I wonder whether it is still additive?\r\n\r\n<img width=\"717\" alt=\"Screen Shot 2021-03-20 at 11 24 36 PM\" src=\"https://user-images.githubusercontent.com/17790770/112020692-cc09ab00-8aed-11eb-9d33-611df5d12c6c.png\">\r\n\r\nI care about this because I have a model where I use restaurant chain affiliation and age to predict restaurant survival. For some reason, we use a group of dummies of age (age=1,2,3,..., >10). Then each age dummy has a SHAP feature importance. I wonder whether we can sum up the SHAP feature importance of age dummies, so I can compare the importance of chain affiliation and age overall?\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1892/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1892/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
