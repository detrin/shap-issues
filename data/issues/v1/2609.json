{
  "url": "https://api.github.com/repos/shap/shap/issues/2609",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2609/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2609/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2609/events",
  "html_url": "https://github.com/shap/shap/issues/2609",
  "id": 1293346491,
  "node_id": "I_kwDOBHDcK85NFua7",
  "number": 2609,
  "title": "Explanation for Hybrid Transformer Network",
  "user": {
    "login": "Subh1m",
    "id": 11595859,
    "node_id": "MDQ6VXNlcjExNTk1ODU5",
    "avatar_url": "https://avatars.githubusercontent.com/u/11595859?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Subh1m",
    "html_url": "https://github.com/Subh1m",
    "followers_url": "https://api.github.com/users/Subh1m/followers",
    "following_url": "https://api.github.com/users/Subh1m/following{/other_user}",
    "gists_url": "https://api.github.com/users/Subh1m/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Subh1m/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Subh1m/subscriptions",
    "organizations_url": "https://api.github.com/users/Subh1m/orgs",
    "repos_url": "https://api.github.com/users/Subh1m/repos",
    "events_url": "https://api.github.com/users/Subh1m/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Subh1m/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2022-07-04T16:03:35Z",
  "updated_at": "2022-07-04T16:13:21Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Is it possible to generate an explanation for a hybrid network of a combination of MLPs and transformers?\r\n\r\nExample:\r\n1. Network 1 = Multilayer perception which gets numerical columns (features) as input\r\n2. Network 2 = Sequence data input for transformer network 1\r\n3. Network 3 = Sequence data input for transformer network 2\r\n4. Concatenate 1= [Network1, Network2, Network 3]\r\n5. Dense layers following the concatenation\r\n6. Output\r\n\r\nExplanation format can be feature importance (for Network 1 input), word importance (for Network 2 input), and word importance (for Network 3 input).\r\nOR\r\nStandard explanation format across all columns+words together.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2609/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2609/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
