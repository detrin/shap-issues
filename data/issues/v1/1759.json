{
  "url": "https://api.github.com/repos/shap/shap/issues/1759",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1759/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1759/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1759/events",
  "html_url": "https://github.com/shap/shap/issues/1759",
  "id": 789289091,
  "node_id": "MDU6SXNzdWU3ODkyODkwOTE=",
  "number": 1759,
  "title": "SHAP with sequences data.",
  "user": {
    "login": "ph0123",
    "id": 11656472,
    "node_id": "MDQ6VXNlcjExNjU2NDcy",
    "avatar_url": "https://avatars.githubusercontent.com/u/11656472?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ph0123",
    "html_url": "https://github.com/ph0123",
    "followers_url": "https://api.github.com/users/ph0123/followers",
    "following_url": "https://api.github.com/users/ph0123/following{/other_user}",
    "gists_url": "https://api.github.com/users/ph0123/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ph0123/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ph0123/subscriptions",
    "organizations_url": "https://api.github.com/users/ph0123/orgs",
    "repos_url": "https://api.github.com/users/ph0123/repos",
    "events_url": "https://api.github.com/users/ph0123/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ph0123/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-01-19T19:16:50Z",
  "updated_at": "2021-01-19T19:16:50Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "regressor = load_model(Model_name)\r\n\r\npred_x = regressor.predict_classes(X_Training)\r\nrandom_ind = np.random.choice(X_Training.shape[0], 1000, replace=False)\r\ndata = X_Training[random_ind[0:500]]\r\nprint(np.shape(data))\r\n#explainer  = shap.DeepExplainer((regressor.layers[0].input, regressor.layers[-1].output),data)\r\nexplainer  = shap.DeepExplainer(regressor,data)\r\ntest1 = X_Training[random_ind[800:1000]]\r\nshap_val = explainer.shap_values(test1) #error here\r\n\r\n`WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'shap_rAnD:0' shape=(1000, 3, 11) dtype=float32>]\r\nConsider rewriting this model with the Functional API.\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-8-e55de83b84ed> in <module>\r\n     21 test1 = X_Training[random_ind[800:1000]]\r\n     22 print(np.shape(test1))\r\n---> 23 shap_val = explainer.shap_values(test1)\r\n     24 shap_val = np.array(shap_val)\r\n     25 shap_val = np.reshape(shap_val,(int(shap_val.shape[1]),int(shap_val.shape[2]),int(shap_val.shape[3])))\r\n\r\n~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)\r\n    122             were chosen as \"top\".\r\n    123         \"\"\"\r\n--> 124         return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)\r\n\r\n~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)\r\n    303                 # run attribution computation graph\r\n    304                 feature_ind = model_output_ranks[j,i]\r\n--> 305                 sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)\r\n    306 \r\n    307                 # assign the attributions to the right part of the output arrays\r\n\r\n~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py in run(self, out, model_inputs, X)\r\n    360 \r\n    361                 return final_out\r\n--> 362             return self.execute_with_overridden_gradients(anon)\r\n    363 \r\n    364     def custom_grad(self, op, *grads):\r\n\r\n~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py in execute_with_overridden_gradients(self, f)\r\n    396         # define the computation graph for the attribution values using a custom gradient-like computation\r\n    397         try:\r\n--> 398             out = f()\r\n    399         finally:\r\n    400             # reinstate the backpropagatable check\r\n\r\n~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py in anon()\r\n    356                     v = tf.constant(data, dtype=self.model_inputs[i].dtype)\r\n    357                     inputs.append(v)\r\n--> 358                 final_out = out(inputs)\r\n    359                 tf_execute.record_gradient = tf_backprop._record_gradient\r\n    360 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nAttributeError: in user code:\r\n\r\n    C:\\Users\\cnp\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:240 grad_graph  *\r\n        out = self.model(shap_rAnD)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__  **\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\r\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\r\n        inputs, training=training, mask=mask)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\r\n        outputs = node.layer(*args, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py:530 __call__\r\n        return super(Bidirectional, self).__call__(inputs, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py:644 call\r\n        initial_state=forward_state, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:663 __call__\r\n        return super(RNN, self).__call__(inputs, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py:1183 call\r\n        runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py:1559 lstm_with_backend_selection\r\n        function.register(defun_gpu_lstm, **params)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py:3241 register\r\n        concrete_func.add_gradient_functions_to_graph()\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py:2063 add_gradient_functions_to_graph\r\n        self._delayed_rewrite_functions.forward_backward())\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py:621 forward_backward\r\n        forward, backward = self._construct_forward_backward(num_doutputs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py:669 _construct_forward_backward\r\n        func_graph=backwards_graph)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py:659 _backprop_function\r\n        src_graph=self._func_graph)\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:669 _GradientsHelper\r\n        lambda: grad_fn(op, *out_grads))\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:336 _MaybeCompile\r\n        return grad_fn()  # Exit early\r\n    C:\\Users\\cnp\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:669 <lambda>\r\n        lambda: grad_fn(op, *out_grads))\r\n    C:\\Users\\cnp\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:368 custom_grad\r\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\r\n    C:\\Users\\cnp\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:657 handler\r\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\r\n    C:\\Users\\cnp\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:664 linearity_with_excluded_handler\r\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\r\n    C:\\Users\\cnp\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:217 _variable_inputs\r\n        out[i] = t.name in self.between_tensors\r\n\r\n    AttributeError: 'TFDeep' object has no attribute 'between_tensors'\r\n\r\n\r\n`",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1759/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1759/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
