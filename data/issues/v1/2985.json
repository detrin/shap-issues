{
  "url": "https://api.github.com/repos/shap/shap/issues/2985",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2985/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2985/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2985/events",
  "html_url": "https://github.com/shap/shap/issues/2985",
  "id": 1752988170,
  "node_id": "I_kwDOBHDcK85ofHoK",
  "number": 2985,
  "title": "MWE for Batch Processing SHAP?",
  "user": {
    "login": "afogarty85",
    "id": 49048309,
    "node_id": "MDQ6VXNlcjQ5MDQ4MzA5",
    "avatar_url": "https://avatars.githubusercontent.com/u/49048309?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/afogarty85",
    "html_url": "https://github.com/afogarty85",
    "followers_url": "https://api.github.com/users/afogarty85/followers",
    "following_url": "https://api.github.com/users/afogarty85/following{/other_user}",
    "gists_url": "https://api.github.com/users/afogarty85/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/afogarty85/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/afogarty85/subscriptions",
    "organizations_url": "https://api.github.com/users/afogarty85/orgs",
    "repos_url": "https://api.github.com/users/afogarty85/repos",
    "events_url": "https://api.github.com/users/afogarty85/events{/privacy}",
    "received_events_url": "https://api.github.com/users/afogarty85/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 5,
  "created_at": "2023-06-12T15:16:22Z",
  "updated_at": "2023-06-15T00:41:44Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I have a roughly high dimensional data set `(10670675, 279)` and I would like to use SHAP to help select features.\r\n\r\nThe work flow is roughly:\r\n\r\n```\r\n# xgb-flavored booster\r\nbst = xgb.train(params=params,\r\n                        dtrain=xg_train,\r\n                        num_boost_round=500,\r\n                        verbose_eval=125,\r\n                        evals=watchlist,\r\n                        evals_result=evals_results, \r\n                        early_stopping_rounds=100\r\n                        )\r\n\r\n# explainer\r\nexplainer = shap.explainers.GPUTree(model=bst,\r\n                                            feature_perturbation='tree_path_dependent'\r\n                                            )\r\n\r\n# batch generate\r\ntotal_shap = []\r\ncol_subsets = np.array_split(col_set, 5)\r\nfor k, col_subset in enumerate(col_subsets):\r\n    print(f\"Now on subset: {k}\")\r\n    shap_values = explainer.shap_values(X=X_train.loc[train_idx, col_subset], check_additivity=False)\r\n    total_shap.append(shap_values)\r\n\r\n# concat\r\ntotal_shaps = np.concatenate(total_shap, axis=1)\r\n```\r\n\r\nIs this a suitable way to prepare / collect my `shap_values` (as I get kernel crashes if I try to run everything at once). The question is particularly guided by suppressing the `check_additivity` warning.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2985/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2985/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
