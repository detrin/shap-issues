{
  "url": "https://api.github.com/repos/shap/shap/issues/687",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/687/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/687/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/687/events",
  "html_url": "https://github.com/shap/shap/issues/687",
  "id": 465770719,
  "node_id": "MDU6SXNzdWU0NjU3NzA3MTk=",
  "number": 687,
  "title": "Issue with shap values in model with merged layers in keras?",
  "user": {
    "login": "amjass12",
    "id": 33659783,
    "node_id": "MDQ6VXNlcjMzNjU5Nzgz",
    "avatar_url": "https://avatars.githubusercontent.com/u/33659783?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/amjass12",
    "html_url": "https://github.com/amjass12",
    "followers_url": "https://api.github.com/users/amjass12/followers",
    "following_url": "https://api.github.com/users/amjass12/following{/other_user}",
    "gists_url": "https://api.github.com/users/amjass12/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/amjass12/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/amjass12/subscriptions",
    "organizations_url": "https://api.github.com/users/amjass12/orgs",
    "repos_url": "https://api.github.com/users/amjass12/repos",
    "events_url": "https://api.github.com/users/amjass12/events{/privacy}",
    "received_events_url": "https://api.github.com/users/amjass12/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2019-07-09T13:07:46Z",
  "updated_at": "2019-07-09T13:07:46Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi all, \r\n\r\nI am a little confused about Shap is dealing with a model i have built in keras that contains a merged layer.\r\n\r\nThe model is built as follows:\r\n\r\n```\r\nleft_branch_input = Input(shape=(5078,), name='Left_input')\r\nleft_branch_output = Dense(64, activation='relu', name=\"middle_layer\")(left_branch_input)\r\nleft_branch_output_2=Dense(32, activation=\"relu\", name=\"second_layer\")(left_branch_output)\r\nleft_branch_output_3=Dense(100, activation=\"relu\", name=\"penultimate_layer\")(left_branch_output_2)\r\n\r\nright_branch_input = Input(shape=(5078,), name='right_input')\r\nright_branch_output = Dense(64, activation='relu', name=\"middle_layerR\")(right_branch_input)\r\nright_branch_output_2=Dense(32, activation=\"relu\", name=\"second_layerR\")(right_branch_output)\r\nright_branch_output_3=Dense(100, activation=\"relu\", name=\"penultimate_layerR\")(right_branch_output_2)\r\n\r\nconcat = concatenate([left_branch_output_3, right_branch_output_3], name='Concatenate')\r\n\r\nfinal_model_output = Dense(24, activation='sigmoid')(concat)\r\nfinal_model = Model(inputs=[left_branch_input, right_branch_input], outputs=final_model_output,\r\n                    name='Final_output' )\r\n\r\n\r\nfinal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\r\n```\r\n\r\nAfter training the model, I would like to interrogate both the final outputs to see how the merged layer is combining two datasets and which features are shared. However, i am gettig odd results when running:\r\n\r\n```\r\nexplainer = shap.DeepExplainer(intermediate_layer_model/**or final_model for last layer**, [X_train.values, X_trainSC.values])\r\nshap_values = explainer.shap_values([X_train.values, X_trainSC.values])\r\n```\r\n\r\nNote X_train and X_trainSC are both input (left and right arm of model).. I cannot specify one as an error is thrown. \r\n\r\nWhen running shap_summary plot as follows: I am getting a very weird plot that is not making sense(screenshot attached):\r\n\r\n<img width=\"771\" alt=\"Screenshot 2019-07-09 at 13 35 14\" src=\"https://user-images.githubusercontent.com/33659783/60888389-97d55480-a24e-11e9-9226-a65b45252a4c.png\">\r\n\r\nFor a normal model I am expecting to see the 'dot plot' with dots to the left (negative influence on the model, or right, positive influence)... I get the bar chart in the screenshot attached and i am unsure as to what class 0 and 1 are, the different input into the left and right branch? (note: there are no red bars when i plot all features, just blue).\r\n\r\nAdditionally, when I build a feature importance table as follows:\r\n\r\n```\r\nshap_sum = np.abs(shap_values[5]).mean(axis=0)\r\nimportance_df = pd.DataFrame([X_trainSC.columns.tolist(), shap_sum.tolist()]).T\r\nimportance_df.columns = ['column_name', 'shap_importance']\r\nimportance_df = importance_df.sort_values('shap_importance', ascending=False)\r\nimportance_df\r\nimportance_df.to_csv(\"SC merged importance class 5 july19.csv\")\r\n```\r\nI am getting results that look very weird and different to the one model shap analysis which gives me a feature name and a shap value in th column next to it. For this, i get a list of shap values on the same row! please see screenshot attached. \r\n\r\n<img width=\"1266\" alt=\"Screenshot 2019-07-09 at 14 06 24\" src=\"https://user-images.githubusercontent.com/33659783/60890220-c6edc500-a252-11e9-975e-0b843ae86bd8.png\">\r\n\r\nIs there a way to fix this and make this look more like the normal shap analysis? I am guessing that this clearly a result of the merge layer within the keras model however, it would super important to see how the merge layer is sharing information between both models and which features are commonly leading to class activations!\r\n\r\nMany thanks!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/687/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/687/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
