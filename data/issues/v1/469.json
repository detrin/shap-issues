{
  "url": "https://api.github.com/repos/shap/shap/issues/469",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/469/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/469/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/469/events",
  "html_url": "https://github.com/shap/shap/issues/469",
  "id": 416019552,
  "node_id": "MDU6SXNzdWU0MTYwMTk1NTI=",
  "number": 469,
  "title": "Most tests do not verify assumptions of the method",
  "user": {
    "login": "jorgecarleitao",
    "id": 2772607,
    "node_id": "MDQ6VXNlcjI3NzI2MDc=",
    "avatar_url": "https://avatars.githubusercontent.com/u/2772607?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jorgecarleitao",
    "html_url": "https://github.com/jorgecarleitao",
    "followers_url": "https://api.github.com/users/jorgecarleitao/followers",
    "following_url": "https://api.github.com/users/jorgecarleitao/following{/other_user}",
    "gists_url": "https://api.github.com/users/jorgecarleitao/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jorgecarleitao/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jorgecarleitao/subscriptions",
    "organizations_url": "https://api.github.com/users/jorgecarleitao/orgs",
    "repos_url": "https://api.github.com/users/jorgecarleitao/repos",
    "events_url": "https://api.github.com/users/jorgecarleitao/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jorgecarleitao/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2019-03-01T09:43:29Z",
  "updated_at": "2019-03-01T17:37:21Z",
  "closed_at": null,
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "A brief look at the tests, e.g. [test_deep](https://github.com/slundberg/shap/blob/fce3f2f4a706c33f7280bb91e8c6c1efb55b5702/tests/explainers/test_deep.py#L87), [test_linear](https://github.com/slundberg/shap/blob/fce3f2f4a706c33f7280bb91e8c6c1efb55b5702/tests/explainers/test_linear.py#L39), [test_tree](https://github.com/slundberg/shap/blob/fce3f2f4a706c33f7280bb91e8c6c1efb55b5702/tests/explainers/test_tree.py#L194), [test_gradient](https://github.com/slundberg/shap/blob/fce3f2f4a706c33f7280bb91e8c6c1efb55b5702/tests/explainers/test_gradient.py#L86), shows that we are either testing that the sum of shap values is the expected value, or that the code runs.\r\n\r\nIn other words, we almost never check that the code actually does what it is supposed to do in terms of the individual shap values. I understand that it is not easy to design tests for this, but it is part of the research and development to find suitable test suits for this problem.\r\n\r\nIn PR #468 I added a test to verify what I understood from the documentation of LinearExplainer. Tests for other explainers are necessary to guarantee that the explanations are correct in controlled data (and thus expected to be correct in uncontrolled data).\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/469/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/469/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
