{
  "url": "https://api.github.com/repos/shap/shap/issues/579",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/579/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/579/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/579/events",
  "html_url": "https://github.com/shap/shap/issues/579",
  "id": 441307837,
  "node_id": "MDU6SXNzdWU0NDEzMDc4Mzc=",
  "number": 579,
  "title": "SHAP tensorflow model deeplab_v3",
  "user": {
    "login": "luistelmocosta",
    "id": 7799750,
    "node_id": "MDQ6VXNlcjc3OTk3NTA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/7799750?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/luistelmocosta",
    "html_url": "https://github.com/luistelmocosta",
    "followers_url": "https://api.github.com/users/luistelmocosta/followers",
    "following_url": "https://api.github.com/users/luistelmocosta/following{/other_user}",
    "gists_url": "https://api.github.com/users/luistelmocosta/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/luistelmocosta/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/luistelmocosta/subscriptions",
    "organizations_url": "https://api.github.com/users/luistelmocosta/orgs",
    "repos_url": "https://api.github.com/users/luistelmocosta/repos",
    "events_url": "https://api.github.com/users/luistelmocosta/events{/privacy}",
    "received_events_url": "https://api.github.com/users/luistelmocosta/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2019-05-07T15:49:40Z",
  "updated_at": "2019-07-31T08:57:58Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello, I'm trying to use SHAP in a native tensorflow model but I'm being unsuccessful. \r\n\r\nI am using the deeplab_v3 model, as presented below:\r\n\r\n```\r\nimport tensorflow as tf\r\nslim = tf.contrib.slim\r\nfrom resnet import resnet_v2, resnet_utils\r\n\r\n# ImageNet mean statistics\r\n_R_MEAN = 123.68\r\n_G_MEAN = 116.78\r\n_B_MEAN = 103.94\r\n\r\n@slim.add_arg_scope\r\ndef atrous_spatial_pyramid_pooling(net, scope, depth=256, reuse=None):\r\n    \"\"\"\r\n    ASPP consists of (a) one 1×1 convolution and three 3×3 convolutions with rates = (6, 12, 18) when output stride = 16\r\n    (all with 256 filters and batch normalization), and (b) the image-level features as described in https://arxiv.org/abs/1706.05587\r\n    :param net: tensor of shape [BATCH_SIZE, WIDTH, HEIGHT, DEPTH]\r\n    :param scope: scope name of the aspp layer\r\n    :return: network layer with aspp applyed to it.\r\n    \"\"\"\r\n\r\n    with tf.variable_scope(scope, reuse=reuse):\r\n        feature_map_size = tf.shape(net)\r\n\r\n        # apply global average pooling\r\n        image_level_features = tf.reduce_mean(net, [1, 2], name='image_level_global_pool', keepdims=True)\r\n        image_level_features = slim.conv2d(image_level_features, depth, [1, 1], scope=\"image_level_conv_1x1\",\r\n                                           activation_fn=None)\r\n        image_level_features = tf.image.resize_bilinear(image_level_features, (feature_map_size[1], feature_map_size[2]))\r\n\r\n        at_pool1x1 = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_0\", activation_fn=None)\r\n\r\n        at_pool3x3_1 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_1\", rate=6, activation_fn=None)\r\n\r\n        at_pool3x3_2 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_2\", rate=12, activation_fn=None)\r\n\r\n        at_pool3x3_3 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_3\", rate=18, activation_fn=None)\r\n\r\n        net = tf.concat((image_level_features, at_pool1x1, at_pool3x3_1, at_pool3x3_2, at_pool3x3_3), axis=3,\r\n                        name=\"concat\")\r\n        net = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_output\", activation_fn=None)\r\n        return net\r\n\r\n\r\ndef deeplab_v3(inputs, args, is_training, reuse, mean_subtraction=True):\r\n\r\n    # mean subtraction normalization\r\n    if mean_subtraction:\r\n        inputs = inputs - [_R_MEAN, _G_MEAN, _B_MEAN]\r\n    \r\n    # inputs has shape - Original: [batch, 513, 513, 3]\r\n    with slim.arg_scope(resnet_utils.resnet_arg_scope(args.l2_regularizer, is_training,\r\n                                                      args.batch_norm_decay,\r\n                                                      args.batch_norm_epsilon)):\r\n        resnet = getattr(resnet_v2, args.resnet_model)\r\n        _, end_points = resnet(inputs,\r\n                               args.number_of_classes,\r\n                               is_training=is_training,\r\n                               global_pool=False,\r\n                               spatial_squeeze=False,\r\n                               output_stride=args.output_stride,\r\n                               reuse=reuse)\r\n\r\n        with tf.variable_scope(\"DeepLab_v3\", reuse=reuse):\r\n\r\n            # get block 4 feature outputs\r\n            net = end_points[args.resnet_model + '/block4']\r\n\r\n            net = atrous_spatial_pyramid_pooling(net, \"ASPP_layer\", depth=256, reuse=reuse)\r\n\r\n            net = slim.conv2d(net, args.number_of_classes, [1, 1], activation_fn=None,\r\n                              normalizer_fn=None, scope='logits')\r\n\r\n            size = tf.shape(inputs)[1:3]\r\n            # resize the output logits to match the labels dimensions\r\n            #net = tf.image.resize_nearest_neighbor(net, size)\r\n            net = tf.image.resize_bilinear(net, size)\r\n            return net\r\n```\r\n\r\nand I'm doing this in my test function:\r\n\r\n\r\n```\r\nwith tf.Session() as sess:\r\n\r\n    # Create a saver.\r\n    sess.run(tf.local_variables_initializer())\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    # Restore variables from disk.\r\n    modelToRestoreFile=\"{}/{}/train/model.ckpt\".format(BEST_MODEL_FOLDER,model_name)\r\n    saver.restore(sess,modelToRestoreFile)\r\n    print(\"Model\", model_name, \"restored.\")\r\n\r\n\r\n    # define placeholders for receiving the input image height and width\r\n    image_height_tensor = tf.placeholder(tf.int32)\r\n    image_width_tensor = tf.placeholder(tf.int32)\r\n\r\n    # placeholder for receiving the serialized input image\r\n    serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\r\n    feature_configs = {'x': tf.FixedLenFeature(shape=[], dtype=tf.float32), }\r\n    tf_example = tf.parse_example(serialized_tf_example, feature_configs)\r\n\r\n    # reshape the input image to its original dimension\r\n    tf_example['x'] = tf.reshape(tf_example['x'], (1, 512, 512, 3))\r\n    input_tensor = tf.identity(tf_example['x'], name='x')  # use tf.identity() to assign name\r\n    #tensor_info_input = tf.saved_model.utils.build_tensor_info(input_tensor)\r\n    # output tensor info\r\n    tensor_info_output = tf.saved_model.utils.build_tensor_info(predictions_tf)\r\n\r\n    # select a set of background examples to take an expectation over\r\n    imageFilename = './test2.png'\r\n    test_input_image=Image.open(imageFilename)\r\n    test_input_image = np.array(test_input_image)\r\n    test_input_array = np.array(test_input_image)\r\n    test_input_image_batch = np.expand_dims(test_input_image, axis=0)\r\n    print(batch_images_tf)\r\n    background = batch_images_tf[0]\r\n\r\n    IN = tf.get_default_graph().get_tensor_by_name('x:0')\r\n    OUT = tf.get_default_graph().get_tensor_by_name('ArgMax:0')\r\n    print(IN)\r\n    print(OUT)\r\n    #print(sess.graph.get_operations())\r\n\r\n\r\n    \r\n\r\n    # explain predictions of the model on three images\r\n    #e = shap.DeepExplainer(session=sess, background)\r\n    # ...or pass tensors directly\r\n    e = shap.DeepExplainer(IN, OUT, test_input_image_batch)\r\n    shap_values = e.shap_values(test_dataset[1:5])\r\n    print(shap_values)  \r\n    shap.image_plot(shap_values, -test_dataset[1:5])\r\n```\r\n\r\nHowever, I'm getting the following error:\r\n\r\n`AssertionError: <class 'tensorflow.python.framework.ops.Tensor'> is not currently a supported model type!`\r\n\r\nI used the approach suggested in the README and passed the input tensor and the output tensor. \r\n\r\n[Here](https://gist.github.com/luistelmocosta/db5d4b343fb1d57935058b5ca74e5e0c) is my model graph. \r\n\r\nAny idea what is going wrong?\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/579/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/579/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
