{
  "url": "https://api.github.com/repos/shap/shap/issues/1900",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1900/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1900/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1900/events",
  "html_url": "https://github.com/shap/shap/issues/1900",
  "id": 840849936,
  "node_id": "MDU6SXNzdWU4NDA4NDk5MzY=",
  "number": 1900,
  "title": "The latent vector explaining the expected value itself",
  "user": {
    "login": "bcaldir",
    "id": 12007973,
    "node_id": "MDQ6VXNlcjEyMDA3OTcz",
    "avatar_url": "https://avatars.githubusercontent.com/u/12007973?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/bcaldir",
    "html_url": "https://github.com/bcaldir",
    "followers_url": "https://api.github.com/users/bcaldir/followers",
    "following_url": "https://api.github.com/users/bcaldir/following{/other_user}",
    "gists_url": "https://api.github.com/users/bcaldir/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/bcaldir/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/bcaldir/subscriptions",
    "organizations_url": "https://api.github.com/users/bcaldir/orgs",
    "repos_url": "https://api.github.com/users/bcaldir/repos",
    "events_url": "https://api.github.com/users/bcaldir/events{/privacy}",
    "received_events_url": "https://api.github.com/users/bcaldir/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-03-25T11:50:00Z",
  "updated_at": "2021-10-09T20:05:35Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hey,\r\n\r\nAs we know, for regression tasks, summing up the shap values of all the features and adding it to the expected value determined by SHAP should yield the predicted value. That's an amazing way of explaining the impacts of the features affecting the calculated expected value. The only thing that remains unexplained seems the latent vector lies behind the expected value as it's conformed some parameters either the used ones or other unknown ones.\r\n\r\nI mean, for a single instance, SHAP explains how each feature affects the predicted value and the base value is taken as the expected value of the predicted values. Each value in the shap values matrix is calculated relative to the expected value. However, the actual impact of each feature per instance should include the latent effect of those features shaping the expected value itself (changing the base value to a hypothetical zero, minimum of the predicted values maybe).\r\n\r\nIs there a way to calculate such a latent vector including the impacts of each feature forming the expected value up?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1900/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1900/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
