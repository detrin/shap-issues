{
  "url": "https://api.github.com/repos/shap/shap/issues/2675",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2675/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2675/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2675/events",
  "html_url": "https://github.com/shap/shap/issues/2675",
  "id": 1367839521,
  "node_id": "I_kwDOBHDcK85Rh5Mh",
  "number": 2675,
  "title": "Why is the output format of shap_value of xgboost and RF different?",
  "user": {
    "login": "zevellong",
    "id": 32690016,
    "node_id": "MDQ6VXNlcjMyNjkwMDE2",
    "avatar_url": "https://avatars.githubusercontent.com/u/32690016?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/zevellong",
    "html_url": "https://github.com/zevellong",
    "followers_url": "https://api.github.com/users/zevellong/followers",
    "following_url": "https://api.github.com/users/zevellong/following{/other_user}",
    "gists_url": "https://api.github.com/users/zevellong/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/zevellong/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/zevellong/subscriptions",
    "organizations_url": "https://api.github.com/users/zevellong/orgs",
    "repos_url": "https://api.github.com/users/zevellong/repos",
    "events_url": "https://api.github.com/users/zevellong/events{/privacy}",
    "received_events_url": "https://api.github.com/users/zevellong/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2022-09-09T13:35:16Z",
  "updated_at": "2022-09-13T09:16:21Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I use the exact same data, y has 2 classes, the output of **lightGBM and RF** are **lists**, and the list contains a two-dimensional matrix with the same dimension as the data, but the output of **xgboost** is **only a two-dimensional matrix**. \r\n, the xgboost plot and beeswam are the same\r\n\r\nThe `summary_plot` is also different, the xgboost plot is the same as `beeswam`.\r\n``` python\r\n# XGBoost: <class 'numpy.ndarray'> (32561, 12)\r\nprint(\"XGBoost:\", type(shap_value), shap_value.shape)\r\n\r\n# lightGBM: <class 'list'> (32561, 12) (32561, 12)\r\nprint(\"lightGBM:\", type(shap_values1), shap_values1[0].shape, shap_values1[1].shape) \r\n\r\n# RF: <class 'list'> (32561, 12) (32561, 12)\r\nprint(\"RF:\", type(shap_values2), shap_values2[0].shape, shap_values2[1].shape)\r\n```\r\n\r\nThe test code is as follows:\r\n``` python\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nimport lightgbm as lgb\r\nimport shap\r\nimport numpy as np\r\nimport pandas as pd\r\nimport xgboost \r\n\r\nX,y = shap.datasets.adult()\r\nX_display,y_display = shap.datasets.adult(display=True)\r\n# create a train/test split\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\r\n\r\n# XGBoost\r\nd_train = xgboost.DMatrix(X_train, label=y_train)\r\nd_test = xgboost.DMatrix(X_test, label=y_test)\r\nparams = {\r\n    \"eta\": 0.01,\r\n    \"objective\": \"binary:logistic\",\r\n    \"subsample\": 0.5,\r\n    \"base_score\": np.mean(y_train),\r\n    \"eval_metric\": \"logloss\"\r\n}\r\nmodel = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)\r\nexplainer = shap.TreeExplainer(model)\r\nshap_values = explainer.shap_values(X)\r\nshap.summary_plot(shap_values, X_display, plot_type=\"bar\")\r\nprint(\"XGBoost:\", type(shap_values), shap_values.shape)\r\n\r\n# lightGBM\r\nl_train = lgb.Dataset(X_train, label=y_train)\r\nl_test = lgb.Dataset(X_test, label=y_test)\r\nparams = {\r\n    \"max_bin\": 512,\r\n    \"learning_rate\": 0.05,\r\n    \"boosting_type\": \"gbdt\",\r\n    \"objective\": \"binary\",\r\n    \"metric\": \"binary_logloss\",\r\n    \"num_leaves\": 10,\r\n    \"verbose\": -1,\r\n    \"min_data\": 100,\r\n    \"boost_from_average\": True\r\n}\r\n\r\nmodel1 = lgb.train(params, l_train, 10000, valid_sets=[l_test], early_stopping_rounds=50, verbose_eval=1000)\r\nexplainer1 = shap.TreeExplainer(model1)\r\nshap_values1 = explainer1.shap_values(X)\r\nshap.summary_plot(shap_values1, X)\r\nprint(\"lightGBM:\", type(shap_values1), shap_values1[0].shape, shap_values1[1].shape) \r\n\r\n# RF\r\nrf = RandomForestClassifier(max_features=6, max_depth=4).fit(X, y)\r\nexplainer2 = shap.TreeExplainer(rf)\r\nshap_values2 = explainer2.shap_values(X)\r\nprint(\"RF:\", type(shap_values2), shap_values2[0].shape, shap_values2[1].shape)\r\n\r\n\r\n\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2675/reactions",
    "total_count": 3,
    "+1": 3,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2675/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
