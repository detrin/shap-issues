{
  "url": "https://api.github.com/repos/shap/shap/issues/2173",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2173/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2173/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2173/events",
  "html_url": "https://github.com/shap/shap/issues/2173",
  "id": 993904880,
  "node_id": "MDU6SXNzdWU5OTM5MDQ4ODA=",
  "number": 2173,
  "title": "Shap Values do not sum up to the models output (are all zero) for LSTM",
  "user": {
    "login": "NikolasMe",
    "id": 37831177,
    "node_id": "MDQ6VXNlcjM3ODMxMTc3",
    "avatar_url": "https://avatars.githubusercontent.com/u/37831177?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/NikolasMe",
    "html_url": "https://github.com/NikolasMe",
    "followers_url": "https://api.github.com/users/NikolasMe/followers",
    "following_url": "https://api.github.com/users/NikolasMe/following{/other_user}",
    "gists_url": "https://api.github.com/users/NikolasMe/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/NikolasMe/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/NikolasMe/subscriptions",
    "organizations_url": "https://api.github.com/users/NikolasMe/orgs",
    "repos_url": "https://api.github.com/users/NikolasMe/repos",
    "events_url": "https://api.github.com/users/NikolasMe/events{/privacy}",
    "received_events_url": "https://api.github.com/users/NikolasMe/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-09-11T18:33:49Z",
  "updated_at": "2021-09-12T07:56:45Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hallo,\r\n\r\nfirst of all great approach to tackle the black box problem, I'm really hyped to use your approach in my thesis. Sadly, there seems to be a problem when calculating the shap_values using the DeepExplainer for my LSTM predicting a Time Series.  I get the error:\r\n\r\n\"AssertionError: The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of 0.050865 is significant compared the scale of your model outputs please post as a github issue, with a reproducable example if possible so we can debug it.\"\r\n\r\nIf I add  check_additivity= False and print the shap_values, they are all zero and in a strange shape.\r\n\r\nI had several issues when using the DeepExplainer (disabling eager execution solved that tho) it seemed to work with the GradientExplainer but the values made no sense.\r\n\r\nReproducible Example: https://colab.research.google.com/drive/14zWFLO8bbGSvANpb9roo-vjWdPO8Ta7s?usp=sharing\r\n\r\nI hope you guys can help me out, thanks in advance!\r\n\r\nGreetings,\r\n\r\nNick",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2173/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2173/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
