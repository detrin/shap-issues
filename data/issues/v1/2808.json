{
  "url": "https://api.github.com/repos/shap/shap/issues/2808",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2808/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2808/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2808/events",
  "html_url": "https://github.com/shap/shap/issues/2808",
  "id": 1503199614,
  "node_id": "I_kwDOBHDcK85ZmQF-",
  "number": 2808,
  "title": "shap.DeepExplainer Error on LSM :  'TFDeep' object has no attribute 'between_tensors' Exception encountered when calling layer \"lstm\" \" ",
  "user": {
    "login": "technqvi",
    "id": 38780060,
    "node_id": "MDQ6VXNlcjM4NzgwMDYw",
    "avatar_url": "https://avatars.githubusercontent.com/u/38780060?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/technqvi",
    "html_url": "https://github.com/technqvi",
    "followers_url": "https://api.github.com/users/technqvi/followers",
    "following_url": "https://api.github.com/users/technqvi/following{/other_user}",
    "gists_url": "https://api.github.com/users/technqvi/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/technqvi/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/technqvi/subscriptions",
    "organizations_url": "https://api.github.com/users/technqvi/orgs",
    "repos_url": "https://api.github.com/users/technqvi/repos",
    "events_url": "https://api.github.com/users/technqvi/events{/privacy}",
    "received_events_url": "https://api.github.com/users/technqvi/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 14,
  "created_at": "2022-12-19T16:04:33Z",
  "updated_at": "2023-06-08T13:10:59Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi\r\n\r\nI use LSTM to  predict  time series but , face error , the last part is my source code\r\n**This is my code to use DeepExplainer Function, it is very simple.**\r\n```\r\nimport shap\r\n# Use the training data for deep explainer => can use fewer instances\r\nexplainer_ = shap.DeepExplainer(model, x_train)\r\nshap_values_ = explainer_.shap_values(x_test)\r\n\r\n```\r\n\r\n**This is given error information.How to fix it?**\r\n\r\n```\r\n`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nInput In [33], in <cell line: 1>()\r\n----> 1 shap_values_ = explainer_.shap_values(x_test)\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:124, in Deep.shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)\r\n     90 def shap_values(self, X, ranked_outputs=None, output_rank_order='max', check_additivity=True):\r\n     91     \"\"\" Return approximate SHAP values for the model applied to the data given by X.\r\n     92 \r\n     93     Parameters\r\n   (...)\r\n    122         were chosen as \"top\".\r\n    123     \"\"\"\r\n--> 124     return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:312, in TFDeep.shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)\r\n    310 # run attribution computation graph\r\n    311 feature_ind = model_output_ranks[j,i]\r\n--> 312 sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)\r\n    314 # assign the attributions to the right part of the output arrays\r\n    315 for l in range(len(X)):\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:372, in TFDeep.run(self, out, model_inputs, X)\r\n    369         tf_execute.record_gradient = tf_backprop.record_gradient\r\n    371     return final_out\r\n--> 372 return self.execute_with_overridden_gradients(anon)\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:408, in TFDeep.execute_with_overridden_gradients(self, f)\r\n    406 # define the computation graph for the attribution values using a custom gradient-like computation\r\n    407 try:\r\n--> 408     out = f()\r\n    409 finally:\r\n    410     # reinstate the backpropagatable check\r\n    411     if hasattr(tf_gradients_impl, \"_IsBackpropagatable\"):\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:365, in TFDeep.run.<locals>.anon()\r\n    363     v = tf.constant(data, dtype=self.model_inputs[i].dtype)\r\n    364     inputs.append(v)\r\n--> 365 final_out = out(inputs)\r\n    366 try:\r\n    367     tf_execute.record_gradient = tf_backprop._record_gradient\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n    151 except Exception as e:\r\n    152   filtered_tb = _process_traceback_frames(e.__traceback__)\r\n--> 153   raise e.with_traceback(filtered_tb) from None\r\n    154 finally:\r\n    155   del filtered_tb\r\n\r\nFile C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2\\__autograph_generated_filer893dmpf.py:16, in outer_factory.<locals>.inner_factory.<locals>.tf__grad_graph(shap_rAnD)\r\n     14 with ag__.ld(tf).GradientTape(watch_accessed_variables=False) as tape:\r\n     15     ag__.converted_call(ag__.ld(tape).watch, (ag__.ld(shap_rAnD),), None, fscope)\r\n---> 16     out = ag__.converted_call(ag__.ld(self).model, (ag__.ld(shap_rAnD),), None, fscope)\r\n     18     def get_state():\r\n     19         return (out,)\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\r\n     68     # To get the full stack trace, call:\r\n     69     # `tf.debugging.disable_traceback_filtering()`\r\n---> 70     raise e.with_traceback(filtered_tb) from None\r\n     71 finally:\r\n     72     del filtered_tb\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:378, in TFDeep.custom_grad(self, op, *grads)\r\n    375 \"\"\" Passes a gradient op creation request to the correct handler.\r\n    376 \"\"\"\r\n    377 type_name = op.type[5:] if op.type.startswith(\"shap_\") else op.type\r\n--> 378 out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\r\n    379 return out\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:667, in linearity_with_excluded.<locals>.handler(explainer, op, *grads)\r\n    666 def handler(explainer, op, *grads):\r\n--> 667     return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:674, in linearity_with_excluded_handler(input_inds, explainer, op, *grads)\r\n    672 for i in range(len(op.inputs)):\r\n    673     if i in input_inds or i - len(op.inputs) in input_inds:\r\n--> 674         assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\r\n    675 if op.type.startswith(\"shap_\"):\r\n    676     op.type = op.type[5:]\r\n\r\nFile D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:224, in TFDeep._variable_inputs(self, op)\r\n    222     out = np.zeros(len(op.inputs), dtype=np.bool)\r\n    223     for i,t in enumerate(op.inputs):\r\n--> 224         out[i] = t.name in self.between_tensors\r\n    225     self._vinputs[op] = out\r\n    226 return self._vinputs[op]\r\n\r\nAttributeError: in user code:\r\n\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 247, in grad_graph  *\r\n        out = self.model(shap_rAnD)\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\r\n        raise e.with_traceback(filtered_tb) from None\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 378, in custom_grad\r\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 667, in handler\r\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 674, in linearity_with_excluded_handler\r\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\r\n    File \"D:\\ProgramData\\Anaconda3\\envs\\ml-ai\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 224, in _variable_inputs\r\n        out[i] = t.name in self.between_tensors\r\n\r\n    AttributeError: Exception encountered when calling layer \"lstm\" \"                 f\"(type LSTM).\r\n    \r\n    'TFDeep' object has no attribute 'between_tensors'\r\n    \r\n    Call arguments received by layer \"lstm\" \"                 f\"(type LSTM):\r\n      • inputs=tf.Tensor(shape=(4184, 44, 4), dtype=float32)\r\n      • mask=None\r\n      • training=False\r\n      • initial_state=None\r\n\r\n\r\n\r\n```\r\n\r\nI have 4 features and price is the target value. and the sequence to look back is 44 \r\nthe below show the shape of both train and test data\r\nx_train.shape, y_train.shape=(2092, 44, 4) (2092,)   and x_test.shape, y_test.shape= (534, 44,4) (534,)\r\n\r\n**_this is model architecture as code below_**\r\n```\r\nmodel = Sequential()\r\n\r\nn_neurons = x_train.shape[1] * x_train.shape[2]\r\nprint(n_neurons, x_train.shape[1], x_train.shape[2])\r\n\r\nmodel.add(LSTM(n_neurons, return_sequences=False, input_shape=(x_train.shape[1], x_train.shape[2])))\r\nmodel.add(Dense(1))\r\n\r\nmodel.compile(optimizer='adam',loss='mean_squared_error')\r\n\r\n\r\nhistory = model.fit(x_train, y_train, \r\n                        batch_size=batch_size, \r\n                        epochs=epochs,shuffle=False,\r\n                        validation_data=(x_test, y_test)\r\n                       )\r\n\r\n```\r\n\r\n<img width=\"405\" alt=\"image\" src=\"https://user-images.githubusercontent.com/38780060/208466227-183a4ce8-45b3-486a-87ef-5c5254ae89ac.png\">\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2808/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2808/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
