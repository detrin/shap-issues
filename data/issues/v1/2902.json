{
  "url": "https://api.github.com/repos/shap/shap/issues/2902",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2902/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2902/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2902/events",
  "html_url": "https://github.com/shap/shap/issues/2902",
  "id": 1665085343,
  "node_id": "I_kwDOBHDcK85jPy-f",
  "number": 2902,
  "title": "Compare True Contribution with SHAP Contribution, using simulated data",
  "user": {
    "login": "Watchung",
    "id": 97060163,
    "node_id": "U_kgDOBckFQw",
    "avatar_url": "https://avatars.githubusercontent.com/u/97060163?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Watchung",
    "html_url": "https://github.com/Watchung",
    "followers_url": "https://api.github.com/users/Watchung/followers",
    "following_url": "https://api.github.com/users/Watchung/following{/other_user}",
    "gists_url": "https://api.github.com/users/Watchung/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Watchung/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Watchung/subscriptions",
    "organizations_url": "https://api.github.com/users/Watchung/orgs",
    "repos_url": "https://api.github.com/users/Watchung/repos",
    "events_url": "https://api.github.com/users/Watchung/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Watchung/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2023-04-12T18:58:37Z",
  "updated_at": "2023-08-26T12:00:50Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I try to compare the true contribution with SHAP Contribution, using simulated data. Because the data is simulated, I have the ground truth contribution of each variable for each observation, which I expected SHAP to give similar contribution. But results are quite different, and I am trying to understand why. Please see details below:\r\n\r\n1. Simulate X: generate 4 random variables (x1,x2,x3 and x4).See code section A.\r\n2. Similate Y: Let log_odds = x1+x2+x3+x4 (setting all coefficient to 1 and intercept to 0). Then convert log_odds to probability, and use probability to generate binary outcome. Since coefficients are 1 and intercept is 0, the x value is the contribution to the log_odds of the observation. See code section B.\r\n3. Fit logistic regression. The estimated coefficients are very close to ones used for simulation. The AUC is 0.92. coef: [0.98761674 1.00301607 1.01310563 0.98102926] Intercept [0.03131222]. See code section C.\r\n4. Get KernelSHAP, and put it side by side with the x table ( the true contribution). See code section D.\r\n\r\nThe intercept in data generation is 0, and the bias term for SHAP (explainer.expected_value[1]) is -0.003, which is also close to 0. Thus, I guess I can compare x value with SHAP value for each variable. Please see results for 10 observations below:\r\n1. The x value and SHAP value are not quite comparable;\r\n2. For each observation, the contribution rank order within 4 x's is not consistent with the rank order in the SHAP value.\r\n3. In data generation, x1 and x2 are all positive numbers, while x3 and x4 are all negative numbers. Thus in SHAP columns, I would expect to see some pattern, however, the pattern in SHAP columns are quite random. \r\n\r\nSo my questions are:\r\nIs there any flaw in my testing design, such that the comparison between x value and SHAP value is totally irrelevant?\r\nIs this the SHAP results I should expect? \r\nWhy SHAP gives contribution that deviate so much for the actual value and rank order?\r\n\r\nThank you very much in advance!\r\n\r\n**My apologies for the look of the table!** I was not able to update pictures, and haven't figure out how to appropriately enter the table.\r\n     x1\t     x2\t       x3\t       x4\tSHAP_x1\tSHAP_x2\tSHAP_x3\tSHAP_x4\tlog_odd_true\tlog_odd_pred\r\n5.180\t0.226\t-4.640\t-4.907\t-0.659\t-2.174\t-2.067\t-2.201\t-7.141\t-7.104\r\n0.130\t1.304\t-4.340\t-3.662\t-2.135\t-1.330\t-1.802\t-1.252\t-6.568\t-6.522\r\n2.748\t4.284\t-4.128\t-1.668\t0.298\t1.199\t-0.899\t0.628\t1.235\t1.223\r\n2.177\t4.232\t-1.250\t-4.920\t-0.135\t1.090\t0.817\t-1.436\t0.239\t0.333\r\n2.102\t1.399\t-1.123\t-3.437\t-0.325\t-0.781\t0.762\t-0.652\t-1.059\t-0.999\r\n1.652\t0.701\t-1.995\t-4.959\t-0.912\t-1.621\t0.018\t-2.003\t-4.602\t-4.521\r\n1.023\t3.419\t-3.822\t-2.583\t-1.071\t0.387\t-1.011\t-0.236\t-1.962\t-1.934\r\n6.096\t1.782\t-1.871\t-1.338\t0.544\t-0.297\t0.565\t0.860\t1.670\t1.669\r\n1.498\t3.050\t-2.662\t-3.460\t-0.732\t0.179\t-0.248\t-0.716\t-1.574\t-1.521\r\n1.334\t2.489\t-2.380\t-1.318\t-0.657\t-0.004\t0.096\t0.709\t0.125\t0.141\r\n\r\n\r\n\r\n\r\n```\r\nimport random\r\nimport numpy as np\r\nimport pandas as pd\r\nimport xgboost as xgb\r\nfrom xgboost import XGBClassifier\r\nfrom xgboost import plot_tree \r\nimport sklearn\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\r\nfrom sklearn.metrics import classification_report\r\nimport matplotlib.pyplot as plt\r\nimport shap\r\nfrom numpy.random import seed\r\nfrom numpy.random import rand\r\nfrom numpy.random import randint\r\n\r\n##Section A: Simulate X\r\nrandom_n=2\r\nrandom.seed(random_n)\r\nseed(random_n)\r\nn=10000\r\nx1=np.array(rand(n))*5 # The larger the *n, the further log_odds is pushed away from 0, the easier data to model.\r\nx2=np.array(rand(n))*5\r\nx3=-np.array(rand(n))*5\r\nx4=-np.array(rand(n))*5\r\ndf=pd.DataFrame({\"x1\":x1,\"x2\":x2,\"x3\":x3,\"x4\":x4})\r\n\r\n## Section B: Simulate Y\r\ndef logistic(z):\r\n    return 1 / (1 + np.exp(-z))\r\nlp=x1+x2+x3+x4\r\nprob = logistic(lp)\r\ny = np.random.binomial(1, prob.flatten())\r\nprint(\"mean of y: \", np.mean(y))\r\nprint(\"log_odds of mean: \",np.log(np.mean(y)/(1-(np.mean(y)))))\r\n\r\n## Section C: Fit logistic regression and make sure AUC is reasonable\r\nfrom sklearn.linear_model import LogisticRegression\r\nLR = LogisticRegression(penalty='none')\r\nLR.fit(df.values,y)\r\nprint(\"coef:      \",LR.coef_, LR.intercept_)\r\nprint(\"AUC:       \",roc_auc_score(y, LR.predict_proba(df)[:,1]))\r\n\r\n## Section D: Get KernelSHAP, and compare with tree contribution (for k observations)\r\nk=10\r\nexplainer = shap.KernelExplainer(LR.predict_proba, df, feature_perturbation=\"interventional\", nsamples=10000, link=\"logit\")\r\nshap_values = explainer.shap_values(df[0:k])\r\n\r\ndf_shap=pd.DataFrame(shap_values[1],columns=(\"SHAP_x1\",\"SHAP_x2\",\"SHAP_x3\",\"SHAP_x4\"))\r\ndf_shap_L=pd.concat([df.iloc[0:k,:], df_shap], axis=1)\r\ndf_shap_L['log_odd_true']=np.log(prob/(1-prob))[0:k]\r\nprob_pred =LR.predict_proba(df)[:,1][0:k] \r\ndf_shap_L['log_odd_pred']=np.log(prob_pred/(1-prob_pred))[0:k]\r\n```\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2902/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2902/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
