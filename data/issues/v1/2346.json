{
  "url": "https://api.github.com/repos/shap/shap/issues/2346",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2346/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2346/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2346/events",
  "html_url": "https://github.com/shap/shap/issues/2346",
  "id": 1095126909,
  "node_id": "I_kwDOBHDcK85BRk99",
  "number": 2346,
  "title": "reshape error in HAN model with multi inputs and timedistributed",
  "user": {
    "login": "lexy0093",
    "id": 10195109,
    "node_id": "MDQ6VXNlcjEwMTk1MTA5",
    "avatar_url": "https://avatars.githubusercontent.com/u/10195109?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/lexy0093",
    "html_url": "https://github.com/lexy0093",
    "followers_url": "https://api.github.com/users/lexy0093/followers",
    "following_url": "https://api.github.com/users/lexy0093/following{/other_user}",
    "gists_url": "https://api.github.com/users/lexy0093/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/lexy0093/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/lexy0093/subscriptions",
    "organizations_url": "https://api.github.com/users/lexy0093/orgs",
    "repos_url": "https://api.github.com/users/lexy0093/repos",
    "events_url": "https://api.github.com/users/lexy0093/events{/privacy}",
    "received_events_url": "https://api.github.com/users/lexy0093/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2022-01-06T09:26:55Z",
  "updated_at": "2023-03-07T04:11:20Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, slundberg,\r\n\r\n**versions：**\r\nkeras 2.2.4\r\ntensorflow 1.12.0\r\npython2.7.18\r\nCPU\r\nshap 0.28.5\r\n\r\n**Code piece：**\r\n```\r\nword_embedding_layer = Embedding(WORD_VOCAB_LEN,\r\n                            WORD_EMBEDDING_DIM,\r\n                            input_length=MAX_SENT_LENGTH,\r\n                            trainable=True)\r\n                            #mask_zero=True)\r\n\r\ntag_embedding_layer = Embedding(TAG_VOCAB_LEN,\r\n                            TAG_EMBEDDING_DIM,\r\n                            input_length=MAX_SENTS,\r\n                            trainable=True)\r\n                            #mask_zero=True)\r\n\r\nclass AttLayer(Layer):\r\n    def __init__(self, attention_dim):\r\n        self.init = initializers.get('normal')\r\n        self.supports_masking = True\r\n        self.attention_dim = attention_dim\r\n        super(AttLayer, self).__init__()\r\n\r\n    def build(self, input_shape):\r\n        assert len(input_shape) == 3\r\n        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)), name='W')\r\n        self.b = K.variable(self.init((self.attention_dim, )), name='b')\r\n        self.u = K.variable(self.init((self.attention_dim, 1)), name='u')\r\n        self.trainable_weights = [self.W, self.b, self.u]\r\n        super(AttLayer, self).build(input_shape)\r\n\r\n    def compute_mask(self, inputs, mask=None):\r\n        return mask\r\n\r\n    def call(self, x, mask=None):\r\n        # size of x :[batch_size, sel_len, attention_dim]\r\n        # size of u :[batch_size, attention_dim]\r\n        # uit = tanh(xW+b)\r\n        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\r\n        ait = K.dot(uit, self.u)\r\n        ait = K.squeeze(ait, -1)\r\n\r\n        ait = K.exp(ait)\r\n\r\n        if mask is not None:\r\n            # Cast the mask to floatX to avoid float64 upcasting in theano\r\n            ait *= K.cast(mask, K.floatx())\r\n        aa = K.sum(ait, axis=1, keepdims=True)\r\n        ait /= K.cast(aa + K.epsilon(), K.floatx())\r\n        ait = K.expand_dims(ait)\r\n        weighted_input = x * ait\r\n        output = K.sum(weighted_input, axis=1)\r\n\r\n        return output\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (input_shape[0], input_shape[-1])\r\n\r\n\r\nsentence_input = Input(shape=(MAX_SENT_LENGTH, ), dtype='int32')\r\ntag_input      = Input(shape=(MAX_SENTS, ), dtype='int32')\r\n\r\nembedded_sequences = word_embedding_layer(sentence_input)\r\nl_lstm = Bidirectional(GRU(128, return_sequences=True))(embedded_sequences)\r\nl_att = AttLayer(128)(l_lstm)\r\nsentEncoder = Model(sentence_input, l_att)\r\n\r\nreview_input     = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\r\nembedded_tags = tag_embedding_layer(tag_input)\r\n\r\nreview_encoder = TimeDistributed(sentEncoder)(review_input)\r\nreview_encoder_tag = concatenate([embedded_tags, review_encoder], axis = -1)\r\nl_lstm_sent = Bidirectional(GRU(128, return_sequences=True))(review_encoder_tag)\r\nl_att_sent = AttLayer(128)(l_lstm_sent)\r\npreds = Dense(1, activation='sigmoid')(l_att_sent)\r\nmodel = Model(inputs=[tag_input, review_input], outputs=preds)\r\n\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\ncheckpoint_path = 'test_model/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\r\ncp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\r\ntbCallBack = keras.callbacks.TensorBoard(log_dir=\"./log\")\r\n\r\nmodel.fit(x = [x1_train, x_train], y = y_train, validation_data=([x1_val, x_val], y_val),\r\n          epochs=1, verbose=1, batch_size=128, callbacks=[cp_callback])\r\n\r\nimport shap\r\nexplainer = shap.DeepExplainer(model, [x1_train[:100], x_train[:100]], session = K.get_session())\r\nshap_values = explainer.shap_values([x1_val[:1], x_val[:1]])\r\n\r\nshap.initjs()\r\n\r\nplot = shap.force_plot(explainer.expected_value[0], np.concatenate([shap_values[0][0], shap_values[0][1]], axis=1)[1])\r\nshap.save_html(\"han.html\", plot)\r\n\r\n```\r\nas follow error\r\n```\r\nTraceback (most recent call last):\r\n  File \"xx.py\", line 170, in <module>\r\n    shap_values = explainer.shap_values([x1_val[:1], x_val[:1]])\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/shap/explainers/deep/__init__.py\", line 119, in shap_values\r\n    return self.explainer.shap_values(X, ranked_outputs, output_rank_order)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/shap/explainers/deep/deep_tf.py\", line 273, in shap_values\r\n    sample_phis = self.run(rr, self.model_inputs, joint_input)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/shap/explainers/deep/deep_tf.py\", line 293, in run\r\n    return self.session.run(out, feed_dict)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_run\r\n    run_metadata)\r\n  File \"xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1347, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 2000000 values, but the requested shape has 40000\r\n\t [[node gradients/time_distributed_1/att_layer_1/Sum_grad/Reshape (defined at xxx/anaconda3/envs/tensorflow_eval/lib/python2.7/site-packages/shap/explainers/deep/deep_tf.py:211)  = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/time_distributed_1/att_layer_1/add_1_grad/Sum, gradients/time_distributed_1/att_layer_1/Sum_grad/DynamicStitch)]]\r\n```\r\n**much appreciate for any reply !!!!**\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2346/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2346/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
