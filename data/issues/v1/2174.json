{
  "url": "https://api.github.com/repos/shap/shap/issues/2174",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2174/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2174/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2174/events",
  "html_url": "https://github.com/shap/shap/issues/2174",
  "id": 994746218,
  "node_id": "MDU6SXNzdWU5OTQ3NDYyMTg=",
  "number": 2174,
  "title": "DeepExplainer maxpooling grad error",
  "user": {
    "login": "xuesongwang",
    "id": 19380806,
    "node_id": "MDQ6VXNlcjE5MzgwODA2",
    "avatar_url": "https://avatars.githubusercontent.com/u/19380806?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/xuesongwang",
    "html_url": "https://github.com/xuesongwang",
    "followers_url": "https://api.github.com/users/xuesongwang/followers",
    "following_url": "https://api.github.com/users/xuesongwang/following{/other_user}",
    "gists_url": "https://api.github.com/users/xuesongwang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/xuesongwang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/xuesongwang/subscriptions",
    "organizations_url": "https://api.github.com/users/xuesongwang/orgs",
    "repos_url": "https://api.github.com/users/xuesongwang/repos",
    "events_url": "https://api.github.com/users/xuesongwang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/xuesongwang/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-09-13T10:57:40Z",
  "updated_at": "2021-11-08T23:11:44Z",
  "closed_at": "2021-11-08T23:11:44Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, \r\n  \r\nI was trying to explain a convolutional network (network structure shown later) but could  not get the gradient using e.shap_values(testset). I turned on the  \"with autograd.detect_anomaly():\" and the error seemed to be on the maxpooling layer:\r\n\r\n\"Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\r\n\r\n[W python_anomaly_mode.cpp:104] Warning: Error detected in MaxPool2DWithIndicesBackward. Traceback of forward call that caused the error:\r\n     ....\r\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) \"\r\n\r\n![image](https://user-images.githubusercontent.com/19380806/133032757-e6b20d24-7354-4695-8649-4c00d7961658.png)\r\n\r\nThe convolutional model is defined here  (nothing really special):\r\n\r\n    class SpatialTemporalCNN(nn.Module):\r\n\r\n    \"\"\"\r\n    def __init__(self, input_dim=1, output_dim=2, use_aux = False):\r\n        super(SpatialTemporalCNN, self).__init__()\r\n        # self.l1 = nn.MaxPool2d((2, 1),1) \r\n        self.l1 = FactorizedConvolution(input_dim, channel_dim=16, bottle_neck=False)\r\n        self.l2 = FactorizedConvolution(16, 32, 8)\r\n        self.l3 = FactorizedConvolution(32,32,8)\r\n        self.l4 = FactorizedConvolution(32,64,16)\r\n        self.l5 = FactorizedConvolution(64,64,16)\r\n        self.maxpool = nn.MaxPool2d(2, 2)\r\n        self.l6 = FactorizedConvolution(64,128,32)\r\n        self.l7 = FactorizedConvolution(128,128,32)\r\n        self.use_aux = use_aux\r\n        hidden_dim = self.l7.output_dim\r\n        if use_aux == False:\r\n            self.final_layer = nn.Linear(hidden_dim, output_dim)\r\n        else:\r\n            aux_dim = 10\r\n            layers = [nn.Linear(hidden_dim+aux_dim, hidden_dim),\r\n                      nn.ReLU(),\r\n                      nn.Linear(hidden_dim, output_dim)]\r\n            self.final_layer = nn.Sequential(*layers)\r\n\r\n\r\n    def forward(self, x, return_avg = False, x_aux=None):\r\n        \"\"\"\r\n        input x: shape (bs, 90, 16)  (batch_size, channel, num_ROI, time_step)\r\n        \"\"\"\r\n        x = x.unsqueeze(1)  #(bs, 1, num_ROI, time_step)\r\n        h1 = self.l1(x)\r\n        pool1 = self.maxpool(h1)\r\n        h2 = self.l2(pool1)\r\n        h3 = self.l3(h2)\r\n        pool2 = self.maxpool(h3)\r\n        h4 = self.l4(pool2)\r\n        h5 = self.l5(h4)\r\n        pool3 = self.maxpool(h5)\r\n        # avg_pool = torch.mean(h5,[2,3])  # (bs, 128)\r\n        h6 = self.l6(pool3)\r\n        h7 = self.l7(h6) # (bs,128, 11,2)\r\n        # print(\"h7 shape\", h7.shape)\r\n        avg_pool = torch.mean(h7, [2, 3])  # (bs, 128)\r\n        # print(\"avg shape\", avg_pool.shape)\r\n        if self.use_aux:\r\n            # when in testing mode, the shape of avg_pool is different from x_aux, need to augment x_aux\r\n            if avg_pool.size(0) != x_aux.size(0):\r\n                aug_rate = avg_pool.size(0) // x_aux.size(0)\r\n                x_aux = x_aux.unsqueeze(1).repeat(1, aug_rate, 1)\r\n                x_aux = x_aux.view(avg_pool.size(0), x_aux.size(-1))\r\n            if len(avg_pool.shape) != len(x_aux.shape):\r\n                x_aux = x_aux[:, 0, :]\r\n            avg_pool_cat = torch.cat([avg_pool, x_aux], dim=-1)\r\n        output = self.final_layer(avg_pool_cat)if self.use_aux else self.final_layer(avg_pool)\r\n        return (output, avg_pool) if (return_avg==True) else output\r\n    \r\n     class FactorizedConvolution(nn.Module):\r\n     def __init__(self, input_dim = 1, output_dim =1, channel_dim = 32, bottle_neck=True):\r\n        super(FactorizedConvolution, self).__init__()\r\n        layers = [nn.Conv2d(input_dim,channel_dim,1,1),\r\n                  nn.ReLU(),\r\n                  nn.Conv2d(channel_dim, channel_dim,kernel_size=(1, 3),stride=1,padding=(0, 1)),# padding = (0, 1) to remain original shape\r\n                  nn.ReLU(),\r\n                  nn.Conv2d(channel_dim, channel_dim,kernel_size=(3, 1),stride=1,padding=(1, 0)),\r\n                  nn.ReLU(),\r\n                  nn.Conv2d(channel_dim, output_dim,1,1)\r\n                  ]\r\n        if bottle_neck == False:\r\n            layers = [nn.Conv2d(input_dim, channel_dim,kernel_size=(1, 3),stride=1,padding=(0, 1)),\r\n                      nn.ReLU(),\r\n                      nn.Conv2d(channel_dim, channel_dim,kernel_size=(3, 1),stride=1,padding=(1, 0))\r\n                      ]\r\n        self.identity_match_layer = nn.Conv2d(input_dim, output_dim, 1, 1)\r\n        self.layers = init_sequential_weights(nn.Sequential(*layers))\r\n        self.relu = nn.ReLU()\r\n        self.input_dim = input_dim\r\n        self.output_dim = output_dim\r\n\r\n    def forward(self, x):\r\n        hidden = self.layers(x)\r\n        if self.input_dim != self.output_dim:\r\n            x = self.identity_match_layer(x)\r\n        x = self.relu(x + hidden) # residual\r\n        return x\r\n\r\n\r\n   `\r\n\r\n\r\n\r\nCan somebody please give any hint?  Thanks :)",
  "closed_by": {
    "login": "xuesongwang",
    "id": 19380806,
    "node_id": "MDQ6VXNlcjE5MzgwODA2",
    "avatar_url": "https://avatars.githubusercontent.com/u/19380806?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/xuesongwang",
    "html_url": "https://github.com/xuesongwang",
    "followers_url": "https://api.github.com/users/xuesongwang/followers",
    "following_url": "https://api.github.com/users/xuesongwang/following{/other_user}",
    "gists_url": "https://api.github.com/users/xuesongwang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/xuesongwang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/xuesongwang/subscriptions",
    "organizations_url": "https://api.github.com/users/xuesongwang/orgs",
    "repos_url": "https://api.github.com/users/xuesongwang/repos",
    "events_url": "https://api.github.com/users/xuesongwang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/xuesongwang/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2174/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2174/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
