{
  "url": "https://api.github.com/repos/shap/shap/issues/2396",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2396/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2396/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2396/events",
  "html_url": "https://github.com/shap/shap/issues/2396",
  "id": 1140658642,
  "node_id": "I_kwDOBHDcK85D_RHS",
  "number": 2396,
  "title": "_PytorchGradient seems to have some shape/loop errors",
  "user": {
    "login": "cfhammill",
    "id": 7467038,
    "node_id": "MDQ6VXNlcjc0NjcwMzg=",
    "avatar_url": "https://avatars.githubusercontent.com/u/7467038?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/cfhammill",
    "html_url": "https://github.com/cfhammill",
    "followers_url": "https://api.github.com/users/cfhammill/followers",
    "following_url": "https://api.github.com/users/cfhammill/following{/other_user}",
    "gists_url": "https://api.github.com/users/cfhammill/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/cfhammill/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/cfhammill/subscriptions",
    "organizations_url": "https://api.github.com/users/cfhammill/orgs",
    "repos_url": "https://api.github.com/users/cfhammill/repos",
    "events_url": "https://api.github.com/users/cfhammill/events{/privacy}",
    "received_events_url": "https://api.github.com/users/cfhammill/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2022-02-16T22:35:30Z",
  "updated_at": "2022-02-16T22:35:30Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi shap maintainers, I'm trying out shap for a project I'm trying to run an example using `GradientExplainer` on `se_resnext50_32x4d`\r\n\r\n```python\r\n# data is a [58, 3, 512, 512] tensor\r\nim = next(enumerate(loader_test))[1][0].cuda() \r\n\r\n# give the first 10 slices as background data\r\nge = shap.GradientExplainer(model, [im[i:i+1] for i in range(0,10)], batch_size = 1)\r\n\r\n# try to compute the shap values for the 24th slice\r\nsvs = ge.shap_values([im[24:25]])\r\n```\r\n\r\nfails with\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 111, in shap_values\r\n    return self.explainer.shap_values(X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 518, in shap_values\r\n    grad = [np.concatenate([g[l] for g in grads], 0) for l in range(len(self.data))]\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 518, in <listcomp>\r\n    grad = [np.concatenate([g[l] for g in grads], 0) for l in range(len(self.data))]\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 518, in <listcomp>\r\n    grad = [np.concatenate([g[l] for g in grads], 0) for l in range(len(self.data))]\r\nIndexError: list index out of range\r\n```\r\n\r\nI think the iteration in the list comprehension should be over the input data `X`, not the background data `self.data` here.\r\n\r\nhttps://github.com/slundberg/shap/blob/master/shap/explainers/_gradient.py#L518\r\n\r\nI notice the length of the input and background data lists are the same in the example document which would avoid this issue.\r\n \r\nSo I changed that, but then I get\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 111, in shap_values\r\n    return self.explainer.shap_values(X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\r\n  File \"/usr/local/lib/python3.6/dist-packages/shap-0.40.0-py3.6-linux-x86_64.egg/shap/explainers/_gradient.py\", line 521, in shap_values\r\n    samples = grad[l] * samples_delta[l]\r\n```\r\n\r\nthis is from the loop starting here:\r\nhttps://github.com/slundberg/shap/blob/master/shap/explainers/_gradient.py#L520\r\n\r\nwhich seems like it should be a double loop, looping over inputs and background data. This would also work for the special case where input and background data are the same length.\r\n\r\nAm I doing something wrong or is this a bug?\r\n\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2396/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2396/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
