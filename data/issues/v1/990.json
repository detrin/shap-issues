{
  "url": "https://api.github.com/repos/shap/shap/issues/990",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/990/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/990/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/990/events",
  "html_url": "https://github.com/shap/shap/issues/990",
  "id": 547156027,
  "node_id": "MDU6SXNzdWU1NDcxNTYwMjc=",
  "number": 990,
  "title": "question please",
  "user": {
    "login": "ahmedabbas81",
    "id": 32098502,
    "node_id": "MDQ6VXNlcjMyMDk4NTAy",
    "avatar_url": "https://avatars.githubusercontent.com/u/32098502?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ahmedabbas81",
    "html_url": "https://github.com/ahmedabbas81",
    "followers_url": "https://api.github.com/users/ahmedabbas81/followers",
    "following_url": "https://api.github.com/users/ahmedabbas81/following{/other_user}",
    "gists_url": "https://api.github.com/users/ahmedabbas81/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ahmedabbas81/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ahmedabbas81/subscriptions",
    "organizations_url": "https://api.github.com/users/ahmedabbas81/orgs",
    "repos_url": "https://api.github.com/users/ahmedabbas81/repos",
    "events_url": "https://api.github.com/users/ahmedabbas81/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ahmedabbas81/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2020-01-08T23:11:34Z",
  "updated_at": "2020-01-31T22:46:40Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "@farh33n @slundberg\r\nMy neural network has two hidden layers and one output layer. The hidden layers have relu activation function and the output layer is sigmoid and it is multi-class classification NN.\r\n\r\nIs using deepshap with that neural network model correct?\r\n\r\nI only use\r\ne = shap.DeepExplainer(model, background)\r\nshap_values = e.shap_values(x_test[1:5])\r\n\r\nas in the example in your github page. Is that correct?\r\nDo I need to perform any processing on the contribution values that I get (I mean shap_values)? Or I can rely on them directly as the contribution values that I want.\r\n\r\nAlso, when I use softmax instead of sigmoid, I get other contribution values that are less reasonable than those I get when using sigmoid (there are important inputs that contribute poorly when using softmax). Is there a reason for that?\r\n\r\nAnd a general question, can I use sigmoid as the activation function in a multi-class classification problem where the classes are mutually exclusive, and take the maximum output as the correct class?\r\n\r\nThanks",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/990/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/990/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
