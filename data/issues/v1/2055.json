{
  "url": "https://api.github.com/repos/shap/shap/issues/2055",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2055/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2055/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2055/events",
  "html_url": "https://github.com/shap/shap/issues/2055",
  "id": 929413076,
  "node_id": "MDU6SXNzdWU5Mjk0MTMwNzY=",
  "number": 2055,
  "title": "Using Training data with SHAP",
  "user": {
    "login": "qdickinson",
    "id": 6887090,
    "node_id": "MDQ6VXNlcjY4ODcwOTA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6887090?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/qdickinson",
    "html_url": "https://github.com/qdickinson",
    "followers_url": "https://api.github.com/users/qdickinson/followers",
    "following_url": "https://api.github.com/users/qdickinson/following{/other_user}",
    "gists_url": "https://api.github.com/users/qdickinson/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/qdickinson/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/qdickinson/subscriptions",
    "organizations_url": "https://api.github.com/users/qdickinson/orgs",
    "repos_url": "https://api.github.com/users/qdickinson/repos",
    "events_url": "https://api.github.com/users/qdickinson/events{/privacy}",
    "received_events_url": "https://api.github.com/users/qdickinson/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-06-24T16:33:41Z",
  "updated_at": "2021-06-24T16:38:11Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello,\r\n\r\nI am looking to analyze SHAP values to better understand the models I have trained. The issues I am running into is the sample size of the test dataset. While I get good explanations for the test set, I cannot make statistically significant claims. In order to increase the statistical power of my analysis, I thought I may be able to use the training set to get model explanations. But I am not sure if there is something potentially wrong with this approach. From the data I have analyzed so far, the patterns seem consistent between the test and the training data. However, all uses of SHAP I have seen only use the test data to get explanations. Is it acceptable to use training data in this manner?\r\n\r\nI saw a similar question in a previous [issue](https://github.com/slundberg/shap/issues/833) as well.\r\n\r\nThank you.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2055/reactions",
    "total_count": 6,
    "+1": 6,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2055/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
