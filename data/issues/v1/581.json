{
  "url": "https://api.github.com/repos/shap/shap/issues/581",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/581/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/581/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/581/events",
  "html_url": "https://github.com/shap/shap/issues/581",
  "id": 442348628,
  "node_id": "MDU6SXNzdWU0NDIzNDg2Mjg=",
  "number": 581,
  "title": "Error using K.softmax in DeepExplainer",
  "user": {
    "login": "menajosep",
    "id": 26794975,
    "node_id": "MDQ6VXNlcjI2Nzk0OTc1",
    "avatar_url": "https://avatars.githubusercontent.com/u/26794975?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/menajosep",
    "html_url": "https://github.com/menajosep",
    "followers_url": "https://api.github.com/users/menajosep/followers",
    "following_url": "https://api.github.com/users/menajosep/following{/other_user}",
    "gists_url": "https://api.github.com/users/menajosep/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/menajosep/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/menajosep/subscriptions",
    "organizations_url": "https://api.github.com/users/menajosep/orgs",
    "repos_url": "https://api.github.com/users/menajosep/repos",
    "events_url": "https://api.github.com/users/menajosep/events{/privacy}",
    "received_events_url": "https://api.github.com/users/menajosep/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2019-05-09T17:29:47Z",
  "updated_at": "2023-08-26T09:18:17Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi all,\r\nI'm having an error when using DeepExplainer with my Keras model. The issue comes when I try to use my custom layer:\r\n```\r\nclass PredictiveEntropyLayer(Layer):\r\n\r\n    def __init__(self, **kwargs):\r\n        self.output_dim = 1\r\n        super(PredictiveEntropyLayer, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        assert isinstance(input_shape, list)\r\n        super(PredictiveEntropyLayer, self).build(input_shape)  # Be sure to call this at the end\r\n\r\n    def call(self, x):\r\n        assert isinstance(x, list)\r\n        logits_mu, logits_sigma = x\r\n        noise = K.random_normal((lambda shape: (NUM_PREDICTION_SAMPLES, shape[0], shape[1]))(K.shape(logits_sigma)))\r\n        tiled_logits_mu = K.reshape(K.tile(logits_mu, [NUM_PREDICTION_SAMPLES, 1]), \r\n                              (lambda shape: (NUM_PREDICTION_SAMPLES, shape[0], shape[1]))(K.shape(logits_mu)))\r\n        tiled_logits_sigma = K.reshape(K.tile(logits_sigma, [NUM_PREDICTION_SAMPLES, 1]), \r\n                                 (lambda shape: (NUM_PREDICTION_SAMPLES, shape[0], shape[1]))(K.shape(logits_sigma)))\r\n        z = tiled_logits_mu + noise * tiled_logits_sigma\r\n        z_mean = K.mean(z, axis=0)\r\n        print(z_mean)\r\n        sample_probs = K.softmax(z_mean, axis=-1)\r\n        log_probs = K.log(sample_probs+epsilon)\r\n        entropy = K.sum(-sample_probs*log_probs, axis=-1)\r\n        return [tf.reshape(entropy, (lambda shape: (shape[0], self.output_dim))(tf.shape(logits_sigma)))]\r\n      \r\n    def compute_output_shape(self, input_shape):\r\n        assert isinstance(input_shape, list)\r\n        return [input_shape[0]]\r\n```\r\n\r\nas the output of the model.\r\nAs far as I saw, the error comes from the K.softmax:\r\n```\r\nInvalidArgumentError (see above for traceback): Inputs to operation gradients_25/predictive_entropy_layer_27/Softmax_grad/gradients/gradients_25/predictive_entropy_layer_27/Softmax_grad/truediv_grad/Select_1 of type Select must have the same size and shape.  Input 0: [2000,1] != input 1: [2000,2]\r\n\t [[node gradients_25/predictive_entropy_layer_27/Softmax_grad/gradients/gradients_25/predictive_entropy_layer_27/Softmax_grad/truediv_grad/Select_1 (defined at /usr/local/lib/python3.6/dist-packages/shap/explainers/deep/deep_tf.py:480) ]]\r\n\t [[node gradients_25/embeddings_28/embedding_lookup_grad/Select (defined at /usr/local/lib/python3.6/dist-packages/shap/explainers/deep/deep_tf.py:396) ]]\r\n```\r\nI have even implemented the softmax function by myself, but the error in the true division is the same. Isn't it possible to use the tensorflow softmax with DeepExplainer?\r\n\r\nThanks and best,\r\n\r\nJose Mena.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/581/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/581/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
