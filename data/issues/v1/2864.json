{
  "url": "https://api.github.com/repos/shap/shap/issues/2864",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2864/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2864/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2864/events",
  "html_url": "https://github.com/shap/shap/issues/2864",
  "id": 1597142504,
  "node_id": "I_kwDOBHDcK85fMnXo",
  "number": 2864,
  "title": "Ensemble Model interpretability",
  "user": {
    "login": "rafaloz",
    "id": 19437794,
    "node_id": "MDQ6VXNlcjE5NDM3Nzk0",
    "avatar_url": "https://avatars.githubusercontent.com/u/19437794?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/rafaloz",
    "html_url": "https://github.com/rafaloz",
    "followers_url": "https://api.github.com/users/rafaloz/followers",
    "following_url": "https://api.github.com/users/rafaloz/following{/other_user}",
    "gists_url": "https://api.github.com/users/rafaloz/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/rafaloz/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/rafaloz/subscriptions",
    "organizations_url": "https://api.github.com/users/rafaloz/orgs",
    "repos_url": "https://api.github.com/users/rafaloz/repos",
    "events_url": "https://api.github.com/users/rafaloz/events{/privacy}",
    "received_events_url": "https://api.github.com/users/rafaloz/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2023-02-23T16:12:17Z",
  "updated_at": "2023-02-23T16:12:17Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello, \r\n\r\nI have a doubt regarding the use of SHAP for an ensemble model. \r\n\r\nI trained a model on 10-fold cross-validation and I am using the stack of trained models as an ensemble for my target. I use MLPs as the base model. For each fold, I perform standardization of my features and feature selection selecting a subset of 40 features with which I train the fold's MLP. Therefore, at the end of the training, I would have an ensemble model with 400 input features (40 features x10 MLPs). Even though among these features some are repeated (I have checked it and at the end of the day I have around 100 different features) due to the standardization step within the 10-fold cv, a different training set is used on every fold, there is a bit of variability among the features.  \r\n\r\nTo interpret the whole model (ensemble 10 MLPs) I thought about obtaining the explainer of each MLP using its own training set and then obtaining the SHAP values for each of the MLPs of my test set. Then I would sum up the SHAP values of the repeated features, even though these are not exactly the same due to the standardization and I would use as the expected value the average of the sum of the expected values of each MLP. Since for building the ensemble I am just averaging the final results of the MLPs and the SHAP explainer model is linear, I think I am not violating any mathematical conditions. \r\n\r\nWould this be rigorous? are the SHAP values of an ensemble model (average) the average of the SHAP values of each model of which it is composed? \r\n\r\nI am obtaining the SHAP values using Kernel SHAP. \r\n\r\nThanks for the library and your patience!\r\n\r\n\r\n ",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2864/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2864/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
