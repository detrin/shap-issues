{
  "url": "https://api.github.com/repos/shap/shap/issues/2690",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2690/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2690/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2690/events",
  "html_url": "https://github.com/shap/shap/issues/2690",
  "id": 1377372083,
  "node_id": "I_kwDOBHDcK85SGQez",
  "number": 2690,
  "title": "KeyError: 'label'",
  "user": {
    "login": "shamsa-abid",
    "id": 3810409,
    "node_id": "MDQ6VXNlcjM4MTA0MDk=",
    "avatar_url": "https://avatars.githubusercontent.com/u/3810409?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/shamsa-abid",
    "html_url": "https://github.com/shamsa-abid",
    "followers_url": "https://api.github.com/users/shamsa-abid/followers",
    "following_url": "https://api.github.com/users/shamsa-abid/following{/other_user}",
    "gists_url": "https://api.github.com/users/shamsa-abid/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/shamsa-abid/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/shamsa-abid/subscriptions",
    "organizations_url": "https://api.github.com/users/shamsa-abid/orgs",
    "repos_url": "https://api.github.com/users/shamsa-abid/repos",
    "events_url": "https://api.github.com/users/shamsa-abid/events{/privacy}",
    "received_events_url": "https://api.github.com/users/shamsa-abid/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2022-09-19T04:14:56Z",
  "updated_at": "2022-09-19T04:18:41Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I am trying to get the shap values for the masked language modeling task using transformer. I get the error KeyError: 'label' for the code where I input a single data sample to get the explanation. My complete code and error trace are as follows:\r\n\r\n```\r\nimport transformers\r\nimport shap\r\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline\r\nimport torch\r\nmodel = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base-mlm')\r\ntokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base-mlm')\r\ncode_example = \"if (x <mask> 10)\"\r\nfill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\r\nexplainer = shap.Explainer(fill_mask)\r\nshap_values = explainer(['x {tokenizer.mask_token} 10'])\r\n\r\n````\r\n\r\nFollowing is the error trace\r\n\r\n```\r\nKeyError                                  Traceback (most recent call last)\r\n[<ipython-input-12-bb3832d1772d>](https://localhost:8080/#) in <module>\r\n      6 # explain the model on two sample inputs\r\n      7 explainer = shap.Explainer(fill_mask)\r\n----> 8 shap_values = explainer(['x {tokenizer.mask_token} 10'])\r\n      9 print(shap_values)\r\n     10 # visualize the first prediction's explanation for the POSITIVE output class\r\n\r\n5 frames\r\n[/usr/local/lib/python3.7/dist-packages/shap/explainers/_partition.py](https://localhost:8080/#) in __call__(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\r\n    136         return super().__call__(\r\n    137             *args, max_evals=max_evals, fixed_context=fixed_context, main_effects=main_effects, error_bounds=error_bounds, batch_size=batch_size,\r\n--> 138             outputs=outputs, silent=silent\r\n    139         )\r\n    140 \r\n\r\n[/usr/local/lib/python3.7/dist-packages/shap/explainers/_explainer.py](https://localhost:8080/#) in __call__(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\r\n    266             row_result = self.explain_row(\r\n    267                 *row_args, max_evals=max_evals, main_effects=main_effects, error_bounds=error_bounds,\r\n--> 268                 batch_size=batch_size, outputs=outputs, silent=silent, **kwargs\r\n    269             )\r\n    270             values.append(row_result.get(\"values\", None))\r\n\r\n[/usr/local/lib/python3.7/dist-packages/shap/explainers/_partition.py](https://localhost:8080/#) in explain_row(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\r\n    159         # if not fixed background or no base value assigned then compute base value for a row\r\n    160         if self._curr_base_value is None or not getattr(self.masker, \"fixed_background\", False):\r\n--> 161             self._curr_base_value = fm(m00.reshape(1, -1), zero_index=0)[0] # the zero index param tells the masked model what the baseline is\r\n    162         f11 = fm(~m00.reshape(1, -1))[0]\r\n    163 \r\n\r\n[/usr/local/lib/python3.7/dist-packages/shap/utils/_masked_model.py](https://localhost:8080/#) in __call__(self, masks, zero_index, batch_size)\r\n     65 \r\n     66         else:\r\n---> 67             return self._full_masking_call(masks, batch_size=batch_size)\r\n     68 \r\n     69     def _full_masking_call(self, masks, zero_index=None, batch_size=None):\r\n\r\n[/usr/local/lib/python3.7/dist-packages/shap/utils/_masked_model.py](https://localhost:8080/#) in _full_masking_call(self, masks, zero_index, batch_size)\r\n    142 \r\n    143             joined_masked_inputs = tuple([np.concatenate(v) for v in all_masked_inputs])\r\n--> 144             outputs = self.model(*joined_masked_inputs)\r\n    145             _assert_output_input_match(joined_masked_inputs, outputs)\r\n    146             all_outputs.append(outputs)\r\n\r\n[/usr/local/lib/python3.7/dist-packages/shap/models/_transformers_pipeline.py](https://localhost:8080/#) in __call__(self, strings)\r\n     33                 val = [val]\r\n     34             for obj in val:\r\n---> 35                 output[i, self.label2id[obj[\"label\"]]] = sp.special.logit(obj[\"score\"]) if self.rescale_to_logits else obj[\"score\"]\r\n     36         return output\r\n\r\nKeyError: 'label'\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2690/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2690/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
