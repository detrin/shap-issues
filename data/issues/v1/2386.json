{
  "url": "https://api.github.com/repos/shap/shap/issues/2386",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2386/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2386/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2386/events",
  "html_url": "https://github.com/shap/shap/issues/2386",
  "id": 1128612935,
  "node_id": "I_kwDOBHDcK85DRURH",
  "number": 2386,
  "title": "retracing warning with DeepExplainer",
  "user": {
    "login": "Yo-B",
    "id": 25036280,
    "node_id": "MDQ6VXNlcjI1MDM2Mjgw",
    "avatar_url": "https://avatars.githubusercontent.com/u/25036280?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Yo-B",
    "html_url": "https://github.com/Yo-B",
    "followers_url": "https://api.github.com/users/Yo-B/followers",
    "following_url": "https://api.github.com/users/Yo-B/following{/other_user}",
    "gists_url": "https://api.github.com/users/Yo-B/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Yo-B/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Yo-B/subscriptions",
    "organizations_url": "https://api.github.com/users/Yo-B/orgs",
    "repos_url": "https://api.github.com/users/Yo-B/repos",
    "events_url": "https://api.github.com/users/Yo-B/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Yo-B/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2022-02-09T14:27:56Z",
  "updated_at": "2022-02-26T20:18:40Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I have a series of warnings that seem to relate to the very slow run I'm having with the DeepExplainer. The model has no custom layer, but a quite wide multi-output (n = 500), which makes it difficult to use more than a dozen samples as background and to explain. The warnings suggest that retracing is occurring and is costly. I'll try to build up a minimal working example, but I thought I could first ask for a wild guess from someone here. So does anyone know what could trigger those retracing warnings and how to address to hopefully speed things up? Using tf 2.8 and python 3.10, but I had the same with tf 2.5 and python 3.9. Also, I'm using this build https://github.com/slundberg/shap/pull/2355 to work with tf 2.8, but as I said, I was having the same error with tf 2.5 and the the release build shap 0.40.\r\nMany thanks !\r\n\r\n`explainer = shap.DeepExplainer(model, background)`\r\n\r\n```\r\nkeras is no longer supported, please use tf.keras instead.\r\nYour TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\r\n```\r\n\r\n\r\n`shap_values = explainer.shap_values(to_explain[:,0,intercept_indx])`\r\n\r\n```\r\n`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\nWARNING:tensorflow:5 out of the last 5 calls to <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002F1F64C9750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\nWARNING:tensorflow:6 out of the last 6 calls to <function TFDeep.phi_symbolic.<locals>.grad_graph at 0x000002F1C821F130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n```\r\n      \r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2386/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2386/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
