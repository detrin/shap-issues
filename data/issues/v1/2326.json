{
  "url": "https://api.github.com/repos/shap/shap/issues/2326",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2326/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2326/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2326/events",
  "html_url": "https://github.com/shap/shap/issues/2326",
  "id": 1082740883,
  "node_id": "I_kwDOBHDcK85AiVCT",
  "number": 2326,
  "title": "shap_values summary_plot change dramatically",
  "user": {
    "login": "sentinel3",
    "id": 48333411,
    "node_id": "MDQ6VXNlcjQ4MzMzNDEx",
    "avatar_url": "https://avatars.githubusercontent.com/u/48333411?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/sentinel3",
    "html_url": "https://github.com/sentinel3",
    "followers_url": "https://api.github.com/users/sentinel3/followers",
    "following_url": "https://api.github.com/users/sentinel3/following{/other_user}",
    "gists_url": "https://api.github.com/users/sentinel3/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/sentinel3/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/sentinel3/subscriptions",
    "organizations_url": "https://api.github.com/users/sentinel3/orgs",
    "repos_url": "https://api.github.com/users/sentinel3/repos",
    "events_url": "https://api.github.com/users/sentinel3/events{/privacy}",
    "received_events_url": "https://api.github.com/users/sentinel3/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-12-16T23:54:10Z",
  "updated_at": "2021-12-16T23:54:10Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello, I try to evaluate the importance of the input nodes of a simple NN model. According the [example](https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/deep_explainer/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.html) I use a script block to achieve this: \r\n```\r\n#---train a tensorflow sequential model: 14x64x64x3----\r\nimport shap\r\nshap.initjs()\r\ni=0\r\nexplainer = shap.DeepExplainer(model, x_train[::1000]) \r\nshap_values = explainer.shap_values(x_test[i:(500+i)]) ##different figures below change i\r\nshap.summary_plot(shap_values, sort=False)\r\n```\r\nThe following are `summary_plot` of `shap_values` when changing **i** in the above script (i=**0**, i=**3000**, i=**6000**). \r\nWhy the mean absolute importance values for each input node changes so dramatically?  I assume they should be almost identical?\r\nthx,\r\n\r\n![image](https://user-images.githubusercontent.com/48333411/146464455-52b28223-e307-48ab-a6a3-7d166eeaf52c.png)\r\n![image](https://user-images.githubusercontent.com/48333411/146464882-6c182ff0-4cc1-4d14-838d-45687ef0fca5.png)\r\n![image](https://user-images.githubusercontent.com/48333411/146465028-af3c98d2-5676-4fc3-9e97-165e77c3ddd2.png)",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2326/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2326/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
