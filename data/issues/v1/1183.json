{
  "url": "https://api.github.com/repos/shap/shap/issues/1183",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1183/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1183/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1183/events",
  "html_url": "https://github.com/shap/shap/issues/1183",
  "id": 607901415,
  "node_id": "MDU6SXNzdWU2MDc5MDE0MTU=",
  "number": 1183,
  "title": "Interpreting a single prediction in case of imbalanced dataset",
  "user": {
    "login": "pranut",
    "id": 16946743,
    "node_id": "MDQ6VXNlcjE2OTQ2NzQz",
    "avatar_url": "https://avatars.githubusercontent.com/u/16946743?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/pranut",
    "html_url": "https://github.com/pranut",
    "followers_url": "https://api.github.com/users/pranut/followers",
    "following_url": "https://api.github.com/users/pranut/following{/other_user}",
    "gists_url": "https://api.github.com/users/pranut/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/pranut/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/pranut/subscriptions",
    "organizations_url": "https://api.github.com/users/pranut/orgs",
    "repos_url": "https://api.github.com/users/pranut/repos",
    "events_url": "https://api.github.com/users/pranut/events{/privacy}",
    "received_events_url": "https://api.github.com/users/pranut/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2020-04-27T22:42:30Z",
  "updated_at": "2020-10-28T18:29:01Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "@slundberg Great work on SHAP!\r\n\r\nBuilding off on this issue:\r\nhttps://github.com/slundberg/shap/issues/946\r\n\r\nI am working on a binary classification problem and wanted to see if the following scenario could exist. Suppose, I am using XGBoost for training, in case of a highly imbalanced dataset, the average expected or base value for probability is 0.3 i.e., the dataset has much more 0s than 1s.\r\n\r\nNow suppose, XGBoost returns the probability for a prediction as 0.4 and I am thresholding the probability at 0.5, so the prediction is still a 0.\r\n\r\nWould this affect interpretation of SHAP values to explain the 0 prediction compared to the case when the base value is 0.5 in a balanced dataset and the model output probability is 0.4 again resulting in the prediction of 0 (i.e., <0.5)?\r\n\r\nThanks!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1183/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1183/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
