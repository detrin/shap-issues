{
  "url": "https://api.github.com/repos/shap/shap/issues/2049",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2049/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2049/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2049/events",
  "html_url": "https://github.com/shap/shap/issues/2049",
  "id": 925674715,
  "node_id": "MDU6SXNzdWU5MjU2NzQ3MTU=",
  "number": 2049,
  "title": "Shap value for LSTM model",
  "user": {
    "login": "MariamDundua",
    "id": 62190716,
    "node_id": "MDQ6VXNlcjYyMTkwNzE2",
    "avatar_url": "https://avatars.githubusercontent.com/u/62190716?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/MariamDundua",
    "html_url": "https://github.com/MariamDundua",
    "followers_url": "https://api.github.com/users/MariamDundua/followers",
    "following_url": "https://api.github.com/users/MariamDundua/following{/other_user}",
    "gists_url": "https://api.github.com/users/MariamDundua/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/MariamDundua/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/MariamDundua/subscriptions",
    "organizations_url": "https://api.github.com/users/MariamDundua/orgs",
    "repos_url": "https://api.github.com/users/MariamDundua/repos",
    "events_url": "https://api.github.com/users/MariamDundua/events{/privacy}",
    "received_events_url": "https://api.github.com/users/MariamDundua/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-06-20T20:20:50Z",
  "updated_at": "2021-12-11T14:02:46Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I have lstm model named `lstm_model` and I am using shap value to explain model. have tabular data.\r\n\r\n ```\r\n   import shap\r\n    explainer = shap.DeepExplainer(lstm_model, X_train)\r\n   shap_values = explainer.shap_values(X_test)\r\n```\r\n\r\nFrom My knowledge in order to calculate the shap value, It uses a 2^(number of features) model. I am interesting what is kind of algorithm it uses for each individual model. \r\nThis question comes from the following fact:\r\n\r\nWhen I  am plotting  of effect `x` feature on output, this effect is linear(increasing or decreasing). For example when `x` increasing the effect increasing(decreasing). What is the reason behind this?\r\n\r\nOne additional question:\r\nIs it possible to use shap to plot partial dependence plot for LSTM model?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2049/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2049/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
