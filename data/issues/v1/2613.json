{
  "url": "https://api.github.com/repos/shap/shap/issues/2613",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2613/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2613/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2613/events",
  "html_url": "https://github.com/shap/shap/issues/2613",
  "id": 1298878934,
  "node_id": "I_kwDOBHDcK85Na1HW",
  "number": 2613,
  "title": "Shap importances of explainers.Tree and explainers.Sampling for XGBoost are vastly different",
  "user": {
    "login": "manu675",
    "id": 58952659,
    "node_id": "MDQ6VXNlcjU4OTUyNjU5",
    "avatar_url": "https://avatars.githubusercontent.com/u/58952659?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/manu675",
    "html_url": "https://github.com/manu675",
    "followers_url": "https://api.github.com/users/manu675/followers",
    "following_url": "https://api.github.com/users/manu675/following{/other_user}",
    "gists_url": "https://api.github.com/users/manu675/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/manu675/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/manu675/subscriptions",
    "organizations_url": "https://api.github.com/users/manu675/orgs",
    "repos_url": "https://api.github.com/users/manu675/repos",
    "events_url": "https://api.github.com/users/manu675/events{/privacy}",
    "received_events_url": "https://api.github.com/users/manu675/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 5,
  "created_at": "2022-07-08T11:15:32Z",
  "updated_at": "2022-07-20T09:41:35Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, I am trying to do some XAI evaluation experiments using classifiers and various Shap explainer algorithms. \r\nI am using a breast_cancer binary classification toy data set in order to verify that the my odd results that I get with my own data also occur here. \r\n\r\n![Screen Shot 2022-07-08 at 1 09 08 PM](https://user-images.githubusercontent.com/58952659/177981505-422b341b-2d62-4743-b250-ace6ef890ddb.png)\r\n\r\n![Screen Shot 2022-07-08 at 1 07 14 PM](https://user-images.githubusercontent.com/58952659/177982179-52fd0d02-df8b-48b1-a387-3afa3b830374.png)\r\n\r\n![Screen Shot 2022-07-08 at 1 07 37 PM](https://user-images.githubusercontent.com/58952659/177981600-095aa87f-b83c-4f69-91c4-53b9e0fa52a7.png)\r\n\r\nAs you can see in the 3 attached screenshots the order of the shap feature importances that I can extract varies greatly from Tree to Sampling even though I have used 100,000 samples for evaluating each model prediction. \r\nIs there anything that I have done incorrectly or is it normal that the attributions are so vastly different?\r\nThank you very much in advance.\r\n\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2613/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2613/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
