{
  "url": "https://api.github.com/repos/shap/shap/issues/2058",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2058/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2058/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2058/events",
  "html_url": "https://github.com/shap/shap/issues/2058",
  "id": 929840979,
  "node_id": "MDU6SXNzdWU5Mjk4NDA5Nzk=",
  "number": 2058,
  "title": "Jupyter notebook kernel keep restarting when loading huge dataset from BigQuery when shap was introduced",
  "user": {
    "login": "stevenzhang-support",
    "id": 85593401,
    "node_id": "MDQ6VXNlcjg1NTkzNDAx",
    "avatar_url": "https://avatars.githubusercontent.com/u/85593401?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/stevenzhang-support",
    "html_url": "https://github.com/stevenzhang-support",
    "followers_url": "https://api.github.com/users/stevenzhang-support/followers",
    "following_url": "https://api.github.com/users/stevenzhang-support/following{/other_user}",
    "gists_url": "https://api.github.com/users/stevenzhang-support/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/stevenzhang-support/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/stevenzhang-support/subscriptions",
    "organizations_url": "https://api.github.com/users/stevenzhang-support/orgs",
    "repos_url": "https://api.github.com/users/stevenzhang-support/repos",
    "events_url": "https://api.github.com/users/stevenzhang-support/events{/privacy}",
    "received_events_url": "https://api.github.com/users/stevenzhang-support/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2021-06-25T05:25:04Z",
  "updated_at": "2021-09-08T23:30:41Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "**Type**: Customer issue or a bug\r\n\r\n**Issue**: When using shap==0.39.0 in Jupyter notebook hosted on AI platform in Google Cloud. Jupyter notebook kernel keep restarting when loading huge dataset from BigQuery. The experiment found the issue only occurred with shap lib ==0.39.0 introduced, see cell1, cell2 and cell3 , only cell2 failed to execute.\r\n\r\n====cell1=====\r\n```\r\n# BQ script can be ran smoothly if limited to 3 libraries as shown below:\r\nfrom google.cloud.bigquery import Client\r\nimport pandas as pd\r\nimport time\r\n\r\nclient = Client(project='XXX')\r\nsql = “Select…..,\r\ndf = (\\n\",\r\nclient.query(sql)\\n\",\r\n.to_dataframe(create_bqstorage_client=True)\\n\",\r\n),\r\nprint(f'BQ Read Time: {round(time.time()-start, 1)}')\r\n```\r\n\r\n\r\n===cell2=====\r\n```\r\nfrom google.cloud.bigquery import Client\r\nimport pandas as pd\r\nimport shap #===>test if shap will block the reading data from BQ\r\nimport time\r\n\r\nclient = Client(project='XXX')\r\nsql = \\\"\\\"\\\"\r\nsql = “Select…..,\r\nstart = time.time()\\n\",\r\ndf = (\\n\",\r\nclient.query(sql)\\n\",\r\n.to_dataframe(create_bqstorage_client=True)\\n\",\r\n),\r\nprint(f'BQ Read Time: {round(time.time()-start, 1)}')\r\n```\r\n===cell3======\r\n```\r\nfrom google.cloud.bigquery import Client\r\nimport pandas as pd\r\nimport xgboost as xgb\r\nfrom xgboost import XGBClassifier #====>test Xgboost\r\nimport time\r\n\r\nclient = Client(project='XXX')\r\nsql = \\\"\\\"\\\"\r\nsql = “Select…..,\r\nstart = time.time()\\n\",\r\ndf = (\\n\",\r\nclient.query(sql)\\n\",\r\n.to_dataframe(create_bqstorage_client=True)\\n\",\r\n),\r\nprint(f'BQ Read Time: {round(time.time()-start, 1)}')\r\n```\r\n\r\n**My theory**:\r\nI think this is related to A Python \"segfault\" as per similar issue [1-4] which can happen when some underlying 'C' Python code extension has a bug in it and attempts to access/point to a memory address beyond reach (e.g C will segfault if attempting to access the second element of an 'array[1]' if it only has one element in it 'array[0]'). In this case it is the fault of the specific C code being run, and no addition of memory or hardware will resolve it. Therefore, I report this issue to Sharp eng in their GitHub repository.\r\n\r\n[1] https://github.com/slundberg/shap/issues/452\r\n[2] https://github.com/slundberg/shap/issues/1495\r\n[3] https://github.com/slundberg/shap/issues/1053\r\n[4] https://github.com/slundberg/shap/issues/955",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2058/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2058/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
