{
  "url": "https://api.github.com/repos/shap/shap/issues/1242",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1242/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1242/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1242/events",
  "html_url": "https://github.com/shap/shap/issues/1242",
  "id": 627821100,
  "node_id": "MDU6SXNzdWU2Mjc4MjExMDA=",
  "number": 1242,
  "title": "SHAP with multi-class classification",
  "user": {
    "login": "remyels",
    "id": 38399341,
    "node_id": "MDQ6VXNlcjM4Mzk5MzQx",
    "avatar_url": "https://avatars.githubusercontent.com/u/38399341?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/remyels",
    "html_url": "https://github.com/remyels",
    "followers_url": "https://api.github.com/users/remyels/followers",
    "following_url": "https://api.github.com/users/remyels/following{/other_user}",
    "gists_url": "https://api.github.com/users/remyels/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/remyels/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/remyels/subscriptions",
    "organizations_url": "https://api.github.com/users/remyels/orgs",
    "repos_url": "https://api.github.com/users/remyels/repos",
    "events_url": "https://api.github.com/users/remyels/events{/privacy}",
    "received_events_url": "https://api.github.com/users/remyels/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2020-05-30T21:03:48Z",
  "updated_at": "2021-02-02T00:39:20Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi there,\r\n\r\nI'm working on using SHAP with multi-class classification. More specifically, I'm using one-vs-all via neural networks that I have trained myself.\r\n\r\nIs there a way to limit the explanations of any given observation to its respective classifier?\r\n\r\nMy model function, which I have passed to `shap.KernelExplainer`, returns an array of probabilities, and each of those probabilities corresponds to the output of one classifier. Isn't SHAP supposed to know which of those labels is of interest, i.e. which corresponds to the class of interest, as is the case for LIME? I couldn't find anything in the documentation regarding this, which is why I have decided to ask...\r\n\r\nThank you!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1242/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1242/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
