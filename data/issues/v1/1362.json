{
  "url": "https://api.github.com/repos/shap/shap/issues/1362",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1362/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1362/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1362/events",
  "html_url": "https://github.com/shap/shap/issues/1362",
  "id": 678425355,
  "node_id": "MDU6SXNzdWU2Nzg0MjUzNTU=",
  "number": 1362,
  "title": "KernelExplainer: sklearn predictor trained with DataFrame with column names fails",
  "user": {
    "login": "JoElfner",
    "id": 38665102,
    "node_id": "MDQ6VXNlcjM4NjY1MTAy",
    "avatar_url": "https://avatars.githubusercontent.com/u/38665102?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/JoElfner",
    "html_url": "https://github.com/JoElfner",
    "followers_url": "https://api.github.com/users/JoElfner/followers",
    "following_url": "https://api.github.com/users/JoElfner/following{/other_user}",
    "gists_url": "https://api.github.com/users/JoElfner/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/JoElfner/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/JoElfner/subscriptions",
    "organizations_url": "https://api.github.com/users/JoElfner/orgs",
    "repos_url": "https://api.github.com/users/JoElfner/repos",
    "events_url": "https://api.github.com/users/JoElfner/events{/privacy}",
    "received_events_url": "https://api.github.com/users/JoElfner/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2020-08-13T13:11:00Z",
  "updated_at": "2021-08-14T11:44:30Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "First of all many thanks for providing such a great tool!\r\n\r\nI plan to use shap to evaluate prediction models created in `sklearn`, mainly regression with `ElasticNetCV`.\r\nI generally use `pandas` `DataFrame`s as inputs to my models for a vast set of advantages. Unluckily using the `KernelExplainer` with models trained with `DataFrame`s fails with the following error:\r\n> `ValueError: Specifying the columns using strings is only supported for pandas DataFrames`\r\n\r\nA quick \"hack\" to circumvent this problem is to define the model prediction function passed to shap including a re-conversion to a DataFrame, f.i.:\r\n```\r\nf = lambda x: pred_mdl.predict(\r\n    pd.DataFrame(x, columns=X_train.columns)\r\n)\r\n\r\nexplainer = shap.KernelExplainer(f, X_train)\r\n```\r\nThe, in my opinion, better way is to use the implemented `keep_index=True` (and probably also `keep_index_ordered=True`) options. But these options **are hidden in the kwargs and not shown in the class docstring**. The only way to find out that these options exist, is to delve into the shap module and examine the `KernelExplainer` class.\r\n\r\nThus I'd vote to include these kwargs as named args in the class init, f.i.:\r\n```\r\nclass KernelExplainer(Explainer):\r\n    \"\"\"\r\n    ...\r\n    \"\"\"\r\n\r\n    def __init__(self, model, data, link=IdentityLink(), keep_index=False, keep_index_ordered=False, **kwargs):\r\n        # ...\r\n```\r\nand to implement them in the docstring  \r\n**or**  \r\nimplement raising a warning in `common.convert_to_data` when `str(type(val)).endswith(\"'pandas.core.frame.DataFrame'>\")` yields `True` and `keep_index` is `False`.\r\n\r\nAny objections or remarks? I could make a pull request if you wish.\r\nWhile I'm at it, I could also change the lines like `str(type(val)).endswith(\"'pandas.core.frame.DataFrame'>\")` to `isinstance(val, pd.DataFrame)`, if desired.\r\n\r\n---\r\nSomething completely independent of the issue:\r\nWhen calculating the shap values, I tend to use the full test data, f.i.:\r\n```\r\nexplainer = shap.KernelExplainer(f, X_train)\r\nshap_values = explainer.shap_values(X_test)\r\n```\r\nsince calculation time does not matter for me and I want to have the highest precision. Is it a valid assumption, that raw data yields the highest precision? Or are there any reasons to use `explainer.shap_values(shap.kmeans(X_test, K))`, `explainer.shap_values(shap.sample(X_test, K))` or even  `explainer.shap_values(X_test.median().reshape(1, -1))` as in some examples? Thanks in advance!",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1362/reactions",
    "total_count": 3,
    "+1": 3,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1362/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
