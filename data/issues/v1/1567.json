{
  "url": "https://api.github.com/repos/shap/shap/issues/1567",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1567/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1567/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1567/events",
  "html_url": "https://github.com/shap/shap/issues/1567",
  "id": 737193883,
  "node_id": "MDU6SXNzdWU3MzcxOTM4ODM=",
  "number": 1567,
  "title": "Issue with shap, slicer==0.0.3 and Databricks",
  "user": {
    "login": "alexandrateste",
    "id": 10590948,
    "node_id": "MDQ6VXNlcjEwNTkwOTQ4",
    "avatar_url": "https://avatars.githubusercontent.com/u/10590948?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/alexandrateste",
    "html_url": "https://github.com/alexandrateste",
    "followers_url": "https://api.github.com/users/alexandrateste/followers",
    "following_url": "https://api.github.com/users/alexandrateste/following{/other_user}",
    "gists_url": "https://api.github.com/users/alexandrateste/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/alexandrateste/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/alexandrateste/subscriptions",
    "organizations_url": "https://api.github.com/users/alexandrateste/orgs",
    "repos_url": "https://api.github.com/users/alexandrateste/repos",
    "events_url": "https://api.github.com/users/alexandrateste/events{/privacy}",
    "received_events_url": "https://api.github.com/users/alexandrateste/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2020-11-05T19:09:38Z",
  "updated_at": "2022-08-09T09:17:14Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello,\r\nI have a process in which I programmatically spin up a Databricks Spark job, from an Airflow job.\r\nThe Airflow settings are as follows:\r\n`databricks_operator_json = {\r\n\r\n    'new_cluster': {\r\n\r\n        'spark_version': '6.4.x-cpu-ml-scala2.11',\r\n        'node_type_id': 'm4.large',\r\n        'aws_attributes': {\r\n\r\n            \"availability\": \"ON_DEMAND\",\r\n            \"ebs_volume_type\": \"GENERAL_PURPOSE_SSD\",\r\n            \"ebs_volume_count\": 1,\r\n            \"ebs_volume_size\": 100,\r\n            \"instance_profile_arn\": \"<arn_info>\"\r\n        },\r\n\r\n        'spark_env_vars': {\r\n            'PYSPARK_PYTHON': '/databricks/python3/bin/python3',\r\n        },\r\n        'spark_conf': {\"spark.hadoop.fs.s3a.credentialsType\": \"AssumeRole\",\r\n                       \"spark.hadoop.fs.s3a.stsAssumeRole.arn\":\r\n                           \"arn:aws:iam::{}\".format(assume_role)},\r\n        'num_workers': 1\r\n    },\r\n    \"timeout_seconds\": 3600,\r\n    \"libraries\": [{\r\n        \"pypi\": {\r\n            \"package\": \"sklearn_pandas>=2.0.1\",\r\n            \"repo\": \"https://pypi.org/project\"\r\n        },\r\n    },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"sklearn==0.0\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n            },\r\n        },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"joblib\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n            },\r\n        },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"numpy>1.18.0\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n            },\r\n        },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"scikit-learn>=0.23\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n                # Changed because of n_features_in_\r\n            },\r\n        },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"slicer\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n            },\r\n        },\r\n        {\r\n            \"pypi\": {\r\n                \"package\": \"shap\",\r\n                \"repo\": \"https://pypi.org/project\"\r\n            },\r\n        },\r\n    ],\r\n    \"spark_python_task\": {\r\n        \"python_file\": <file_path>,\r\n        \"parameters\": [<list_of_variable>]\r\n    }\r\n}`\r\n\r\nWhen I run this, I get the following error on the Databricks side:\r\n`'Library installation failed for library due to user error for pypi {\\n  package: \"slicer==0.0.3\"\\n  repo: \"https://pypi.org/project\"\\n}\\n. Error messages:\\njava.lang.RuntimeException: ManagedLibraryInstallFailed: org.apache.spark.SparkException: Process List(/databricks/python/bin/pip, install, slicer==0.0.3, --index-url, https://pypi.org/project, --disable-pip-version-check) exited with code 1.   Could not find a version that satisfies the requirement slicer==0.0.3 (from versions: 0.0.5)\\nNo matching distribution found for slicer==0.0.3\\n for library:PythonPyPiPkgId(slicer,Some(0.0.3),Some(https://pypi.org/project),List())`\r\n\r\nWhen I checked this morning, I noticed that slicer is now at version 0.0.5 and shap at version 0.37.0. Both were released yesterday (2020-11-04).\r\nSo, I tried the above again, but with `slicer==0.03` and `shap==0.36.0`, but got the same error. I also noticed [here](https://github.com/slundberg/shap/blob/master/setup.py#L116), that shap requires slicer==0.0.3, but that version doesn't seem to be found on pypi by Databricks.\r\n\r\nSo, could you please help me figure out what to change to allow for the shap library to get programmatically properly installed in Databricks clusters?\r\n\r\nNote that this whole process was working just fine until this morning, i.e. right after the new versions of slicer and shap were released.\r\n\r\nThank you for your help.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1567/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1567/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
