{
  "url": "https://api.github.com/repos/shap/shap/issues/1587",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1587/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1587/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1587/events",
  "html_url": "https://github.com/shap/shap/issues/1587",
  "id": 743097629,
  "node_id": "MDU6SXNzdWU3NDMwOTc2Mjk=",
  "number": 1587,
  "title": "Docu: Linear Regression SHAP motivation example wrong (notebook general/Explainable AI with SHAP values)",
  "user": {
    "login": "dbartz",
    "id": 8957660,
    "node_id": "MDQ6VXNlcjg5NTc2NjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/8957660?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/dbartz",
    "html_url": "https://github.com/dbartz",
    "followers_url": "https://api.github.com/users/dbartz/followers",
    "following_url": "https://api.github.com/users/dbartz/following{/other_user}",
    "gists_url": "https://api.github.com/users/dbartz/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/dbartz/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dbartz/subscriptions",
    "organizations_url": "https://api.github.com/users/dbartz/orgs",
    "repos_url": "https://api.github.com/users/dbartz/repos",
    "events_url": "https://api.github.com/users/dbartz/events{/privacy}",
    "received_events_url": "https://api.github.com/users/dbartz/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-11-14T22:45:31Z",
  "updated_at": "2020-11-14T22:45:31Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "The motivation for SHAP as an alternative feature importance measure to coeffiecents  is  totally sound:\r\n> While coefficients are great for telling us what will happen when we change the value of an input feature, by themselves, they are not a great way to measure the overall importance of a feature. This is because the value of each coefficient depends on the scale of the input features.\r\n\r\nImho there are two mistakes in the example:\r\n> If for example we were to measure the age of a home in minutes instead of years, then the coefficients for the AGE feature would become 0.0007∗365∗24∗60=367.92. Clearly the number of minutes since a house was built is not more important than the number of years, yet its coefficient value is much larger. This means that the magnitude of a coefficient is not necessarily a good measure of a feature’s importance in a linear model.\r\n\r\n1. The AGE variable in the boston housing data set is a proportion of houses older than a threshold and _not_ measured in years\r\n2. scaling a feature results in a inversely scaled coefficient. Hence, switching from years to minutes would result in a coefficient value 0.0007/(365∗24∗60)=1.3e-9.\r\n\r\nOne could make the example about NOX, the largest absolute coefficient:\r\nmaking NOX unit parts per million instead of parts per 10 million\r\n* makes NOX feature values 10x larger\r\n* makes the NOX linear regression coefficienct 10x smaller\r\n\r\n(The motivation igrores the possiblity of applying Standardization, but that is a different topic)",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1587/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1587/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
