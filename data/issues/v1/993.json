{
  "url": "https://api.github.com/repos/shap/shap/issues/993",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/993/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/993/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/993/events",
  "html_url": "https://github.com/shap/shap/issues/993",
  "id": 548050267,
  "node_id": "MDU6SXNzdWU1NDgwNTAyNjc=",
  "number": 993,
  "title": "Does mean represent the absence of feature value?",
  "user": {
    "login": "farh33n",
    "id": 13518407,
    "node_id": "MDQ6VXNlcjEzNTE4NDA3",
    "avatar_url": "https://avatars.githubusercontent.com/u/13518407?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/farh33n",
    "html_url": "https://github.com/farh33n",
    "followers_url": "https://api.github.com/users/farh33n/followers",
    "following_url": "https://api.github.com/users/farh33n/following{/other_user}",
    "gists_url": "https://api.github.com/users/farh33n/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/farh33n/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/farh33n/subscriptions",
    "organizations_url": "https://api.github.com/users/farh33n/orgs",
    "repos_url": "https://api.github.com/users/farh33n/repos",
    "events_url": "https://api.github.com/users/farh33n/events{/privacy}",
    "received_events_url": "https://api.github.com/users/farh33n/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-01-10T12:21:26Z",
  "updated_at": "2020-01-10T12:21:42Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, I have a query about calculating SHAP values of a sequence passed to an LSTM. We are using DeepExplainer in our code and our input is of size k * m, where k is the number of sequences and m is the length of the feature vector. To simulate the absence of all features, we compute the mean of our all input sequences and pass it as input to the explainer; which is of size k * m. As per my understanding, the SHAP values should be zero for the mean, but we are not getting these results. In fact, the sum of the SHAP values turns out to be a large number. Is there something that is missing in my understanding or is there a limitation in the current implementation when applied on an LSTM? Can you please shed some light on it?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/993/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/993/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
