{
  "url": "https://api.github.com/repos/shap/shap/issues/1506",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1506/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1506/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1506/events",
  "html_url": "https://github.com/shap/shap/issues/1506",
  "id": 716603619,
  "node_id": "MDU6SXNzdWU3MTY2MDM2MTk=",
  "number": 1506,
  "title": "DeepExplainer+softmax no correlation between input and output (with reproducible code)",
  "user": {
    "login": "ydib",
    "id": 15943664,
    "node_id": "MDQ6VXNlcjE1OTQzNjY0",
    "avatar_url": "https://avatars.githubusercontent.com/u/15943664?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ydib",
    "html_url": "https://github.com/ydib",
    "followers_url": "https://api.github.com/users/ydib/followers",
    "following_url": "https://api.github.com/users/ydib/following{/other_user}",
    "gists_url": "https://api.github.com/users/ydib/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ydib/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ydib/subscriptions",
    "organizations_url": "https://api.github.com/users/ydib/orgs",
    "repos_url": "https://api.github.com/users/ydib/repos",
    "events_url": "https://api.github.com/users/ydib/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ydib/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-10-07T14:53:01Z",
  "updated_at": "2020-10-07T14:56:03Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "TLDR: I couldn't make DeepExplainer show the correlation between input and output when using a softmax, the plots are below, the code is [here](https://github.com/ydib/shap_softmax_problem/blob/main/softmax_problem.py).\r\n\r\n\r\n### Introduction\r\n\r\nFirst of all, well done and thank you for shap. I have been using it extensively for my master thesis about feature explanation in AI for medicine.\r\n\r\nI have come across an issue I would like to share with you, maybe you have some insight about what the problem is. You can find the code which generates all the plots below [here](https://github.com/ydib/shap_softmax_problem/blob/main/softmax_problem.py).\r\n\r\nThe packages used are:\r\n> `numpy==1.18.5`\r\n> `matplotlib==3.2.1`\r\n> `tensorflow==2.2.0`\r\n> `shap==0.37.0`\r\n\r\n\r\n### Experiment\r\n\r\nThe goal in this toy example is to use the different explainers provided by shap to compute the shapley values for a model fitted to a very simple dataset. The model takes as input two real numbers (x0,x1) and outputs (y0,y1).\r\n- (x0,x1) are generated using a normal distribution (mean = 100, std = 50).\r\n- y0=1 if x0>=100, and 0 otherwise.\r\n- y1=1 if x0<100, and 0 otherwise. Hence y1=-y0.\r\n- x1 doesn't influence y0 and y1.\r\nSo y0(x0) is a step function centered at 100.\r\n\r\nTo fit this dataset I use two simple models with the same architecture:\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 32)                96        \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 16)                528       \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 2)                 34        \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\nOne of them has a sigmoid activation function at the dense_2 layer, and the other one a softmax. After training, both models have an accuracy of more than 0.9.\r\n\r\nI then use DeepExplainer, GradientExplainer and KernelExplainer to compute the shap values, and use the summary_plot for the y0 output. Below are the 6 plots.\r\n\r\n### Discussion\r\nWhat we can observe is for all combinations of explainer/activation function there is a clear correlation between x0 and y0, except for the DeepExplainer with the softmax. Even after reading the papers cited in the project, I couldn't explain why that was the case.\r\n\r\n\r\n### Question\r\nDoes anyone have an explanation for why DeepExplainer doesn't show a correlation between x0 and y0 when using a softmax ?\r\n\r\n\r\n\r\n\r\n![DeepExplainer, sigmoid, y0](https://user-images.githubusercontent.com/15943664/95344230-b72bb900-08b9-11eb-8132-d1d320b16575.png)\r\n![DeepExplainer, softmax, y0](https://user-images.githubusercontent.com/15943664/95344256-be52c700-08b9-11eb-85af-ee0adfdc8cfd.png)\r\n![GradientExplainer, sigmoid, y0](https://user-images.githubusercontent.com/15943664/95344262-c01c8a80-08b9-11eb-8ae4-7effaf1ae329.png)\r\n![GradientExplainer, softmax, y0](https://user-images.githubusercontent.com/15943664/95344269-c1e64e00-08b9-11eb-8931-3cd2fd10041d.png)\r\n![KernelExplainer, sigmoid, y0](https://user-images.githubusercontent.com/15943664/95344272-c3177b00-08b9-11eb-988c-e3798638e993.png)\r\n![KernelExplainer, softmax, y0](https://user-images.githubusercontent.com/15943664/95344281-c448a800-08b9-11eb-8651-b0a1a858e182.png)\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1506/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1506/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
