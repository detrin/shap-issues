{
  "url": "https://api.github.com/repos/shap/shap/issues/1111",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1111/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1111/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1111/events",
  "html_url": "https://github.com/shap/shap/issues/1111",
  "id": 584562338,
  "node_id": "MDU6SXNzdWU1ODQ1NjIzMzg=",
  "number": 1111,
  "title": "DeepExplainer on CUDA raises hook 'deeplift_grad' error",
  "user": {
    "login": "florianst",
    "id": 31484094,
    "node_id": "MDQ6VXNlcjMxNDg0MDk0",
    "avatar_url": "https://avatars.githubusercontent.com/u/31484094?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/florianst",
    "html_url": "https://github.com/florianst",
    "followers_url": "https://api.github.com/users/florianst/followers",
    "following_url": "https://api.github.com/users/florianst/following{/other_user}",
    "gists_url": "https://api.github.com/users/florianst/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/florianst/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/florianst/subscriptions",
    "organizations_url": "https://api.github.com/users/florianst/orgs",
    "repos_url": "https://api.github.com/users/florianst/repos",
    "events_url": "https://api.github.com/users/florianst/events{/privacy}",
    "received_events_url": "https://api.github.com/users/florianst/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2020-03-19T17:03:15Z",
  "updated_at": "2023-05-24T16:10:29Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I am trying to apply DeepExplainer to a torch model. It works fine with tensors and model all on CPU, but I'd like to do it all on GPU for speed reasons. That raises the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"model.py\", line 1333, in <module>\r\n    dataPortions(dbPath, home, mode)\r\n  File \"model.py\", line 1314, in dataPortions\r\n    trainResult.SHAPexplain()\r\n  File \"model.py\", line 837, in SHAPexplain\r\n    shap_values = explainer.shap_values(to_explain)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/shap/explainers/deep/__init__.py\", line 119, in shap_values\r\n    return self.explainer.shap_values(X, ranked_outputs, output_rank_order)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/shap/explainers/deep/deep_pytorch.py\", line 186, in shap_values\r\n    sample_phis = self.gradient(feature_ind, joint_x)\r\n  File \"/home/user/.local/lib/python3.5/site-packages/shap/explainers/deep/deep_pytorch.py\", line 124, in gradient\r\n    allow_unused=True)[0]\r\n  File \"/data/coml-crispr/user/torch-env/lib/python3.5/site-packages/torch/autograd/__init__.py\", line 157, in grad\r\n    inputs, allow_unused)\r\nRuntimeError: hook 'deeplift_grad' has changed the type of value (was torch.cuda.FloatTensor got torch.FloatTensor)\r\n```\r\nI specifically verified that `to_explain` is a CUDA tensor, and `model `is on CUDA and returns CUDA tensors. I am running Python 3.5.6, PyTorch 1.4.0 and SHAP 0.31.0. Any ideas how to fix this?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1111/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1111/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
