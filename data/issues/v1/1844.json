{
  "url": "https://api.github.com/repos/shap/shap/issues/1844",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1844/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1844/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1844/events",
  "html_url": "https://github.com/shap/shap/issues/1844",
  "id": 818904529,
  "node_id": "MDU6SXNzdWU4MTg5MDQ1Mjk=",
  "number": 1844,
  "title": "Python3: shap tree explainer: Exception ignored in: 'array_dealloc'",
  "user": {
    "login": "hhg7",
    "id": 17788973,
    "node_id": "MDQ6VXNlcjE3Nzg4OTcz",
    "avatar_url": "https://avatars.githubusercontent.com/u/17788973?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/hhg7",
    "html_url": "https://github.com/hhg7",
    "followers_url": "https://api.github.com/users/hhg7/followers",
    "following_url": "https://api.github.com/users/hhg7/following{/other_user}",
    "gists_url": "https://api.github.com/users/hhg7/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/hhg7/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/hhg7/subscriptions",
    "organizations_url": "https://api.github.com/users/hhg7/orgs",
    "repos_url": "https://api.github.com/users/hhg7/repos",
    "events_url": "https://api.github.com/users/hhg7/events{/privacy}",
    "received_events_url": "https://api.github.com/users/hhg7/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-03-01T14:11:34Z",
  "updated_at": "2021-03-01T14:11:34Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "this is a similar post to https://stackoverflow.com/questions/66376784/python3-shap-tree-explainer-exception-ignored-in-array-dealloc but I'm not getting answers there\r\n\r\nI'm running xgboost for machine learning, and after successful completion of my machine learning using `XGBClassifier`, I want to make plots of the results.\r\n\r\nA minimal working example of my input data in JSON format: \r\n\r\n> [{\"age\":58,\"Deceased\":\"False\",\"sex\":\"False\"},{\"Deceased\":\"False\",\"age\":59,\"sex\":\"False\"},{\"sex\":\"False\",\"age\":\"68\",\"Deceased\":\"False\"},{\"Deceased\":\"False\",\"age\":\"26\",\"sex\":\"False\"},{\"Deceased\":\"False\",\"age\":87,\"sex\":\"False\"},{\"sex\":\"True\",\"age\":31,\"Deceased\":\"False\"},{\"Deceased\":\"False\",\"age\":\"35\",\"sex\":\"False\"},{\"sex\":\"False\",\"Deceased\":\"False\",\"age\":41},{\"age\":\"78\",\"Deceased\":\"False\",\"sex\":\"True\"},{\"Deceased\":\"False\",\"age\":\"45\",\"sex\":\"True\"},{\"sex\":\"False\",\"age\":56,\"Deceased\":\"False\"},{\"sex\":\"False\",\"Deceased\":\"False\",\"age\":\"26\"},{\"sex\":\"True\",\"age\":\"64\",\"Deceased\":\"False\"},{\"sex\":\"False\",\"age\":\"37\",\"Deceased\":\"False\"},{\"age\":\"86\",\"Deceased\":\"True\",\"sex\":\"False\"},{\"age\":76,\"Deceased\":\"True\",\"sex\":\"True\"},{\"Deceased\":\"True\",\"age\":69,\"sex\":\"False\"},{\"Deceased\":\"True\",\"age\":79,\"sex\":\"True\"}]\r\n\r\nFollowing advice from https://evgenypogorelov.com/multiclass-xgb-shap.html\r\n\r\nmy script:\r\n\r\n    import mlflow\r\n    import sys\r\n    import json\r\n    import mlflow.sklearn\r\n    import pandas as pd\r\n    import matplotlib.pyplot as plt\r\n    import numpy as np\r\n    from sklearn.model_selection import train_test_split, KFold, cross_val_score\r\n    import xgboost\r\n    import shap\r\n    from sklearn.metrics import accuracy_score, precision_score, plot_roc_curve\r\n    \r\n    def ref_to_json_file(data, filename):\r\n    \tjson1=json.dumps(data)\r\n    \tf = open(filename,\"w+\")\r\n    \tprint(json1,file=f)\r\n    \r\n    class xgb_machine_learn: # like a struct in C\r\n      def __init__(self, accuracy, precision_score, feature_importances, results, roc, xg_clf, X, Y):\r\n        self.accuracy = accuracy\r\n        self.precision_score = precision_score\r\n        self.feature_importances = feature_importances\r\n        self.results = results\r\n        self.roc = roc\r\n        self.xg_clf = xg_clf\r\n        self.X = X\r\n        self.Y = Y\r\n\r\n    def xgbclassifier_wrapper( json_file, dependent_var, output_stem):\r\n      #https://xgboost.readthedocs.io/en/latest/parameter.html\r\n      pandasDF = pd.read_json(json_file)\r\n      bool_cols = [\"Deceased\", \"sex\"]#, 'Hospitalized', 'Respiratory_Support', 'sex']\r\n      for col in bool_cols:\r\n        pandasDF[col] = pandasDF[col]=='True'\r\n      Y = pandasDF[dependent_var]\r\n      X = pandasDF.drop([dependent_var], axis=1)\r\n      \r\n      X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\r\n      mlflow.sklearn.autolog()\r\n    \r\n      # With autolog() enabled, all model parameters, a model score, and the fitted model are automatically logged.  \r\n      with mlflow.start_run():\r\n        # Set the model parameters. \r\n        n_estimators = 200\r\n        colsample_bytree = 0.3\r\n        learning_rate = 0.05\r\n        max_depth = 6# default 6; max. depth of a tree. Increasing this value will make the model more complex and more likely to overfit. 0 is only accepted in lossguided growing policy when tree_method is set as hist or gpu_hist and it indicates no limit on depth. Beware that XGBoost aggressively consumes memory when training a deep tree.\r\n        #min_child_rate = 0\r\n        gamma = 0 # default = 0; Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\r\n    \r\n        # Create and train model.\r\n        xg_clf = xgboost.XGBClassifier( n_estimators=n_estimators, colsample_bytree=colsample_bytree, learning_rate=learning_rate, max_depth=max_depth)\r\n        xg_clf.fit(X_train, y_train)\r\n        # Use the model to make predictions on the test dataset.\r\n        predictions = xg_clf.predict(X_test)\r\n      accuracy = accuracy_score(y_test, predictions)\r\n      pre_score  = precision_score(y_test, predictions)\r\n      feature_importances = pd.DataFrame(xg_clf.feature_importances_, index=X.columns, columns=['importance'])\r\n      feature_importances.to_json(\"data/\" + output_stem + '.feature_importances.json')\r\n      kfold = KFold(n_splits=10)\r\n      results = cross_val_score(xg_clf, X, Y, cv=kfold)\r\n      accuracy = results.mean() * 100\r\n      roc = plot_roc_curve(xg_clf, X_test, y_test, name = dependent_var)\r\n      return_object = xgb_machine_learn(accuracy, pre_score, feature_importances, results, roc, xg_clf, X, Y)\r\n      return return_object\r\n \r\n    json_file = 'debug.json'#\"/home/con/covid_study2065/data/pat.data.array.json\"\r\n    if not os.path.isfile(json_file):\r\n    \tsys.exit(\"json file doesn't exist.\")\r\n    deceased = xgbclassifier_wrapper(json_file, \"Deceased\", 'debug')\r\n    explainer = shap.TreeExplainer(deceased.xg_clf, model_output = \"raw\", feature_perturbation=\"interventional\", data = deceased.X)\r\n\r\n    explainer = shap.TreeExplainer(deceased.xg_clf, model_output = \"probability\", feature_perturbation=\"interventional\", data = deceased.X)\r\n\r\ngives an error:\r\n\r\n    Exception ignored in: 'array_dealloc'\r\n    Traceback (most recent call last):\r\n      File \"/usr/local/lib/python3.8/dist-packages/shap/explainers/_tree.py\", line 1353, in __init__\r\n        _cext.dense_tree_update_weights(\r\n    SystemError: <class 'DeprecationWarning'> returned a result with an error set\r\n    Found a NULL input array in _cext_dense_tree_update_weights!\r\n    Traceback (most recent call last):\r\n      File \"debug.py\", line 97, in <module>\r\n        explainer = shap.TreeExplainer(deceased.xg_clf, model_output = \"probability\", feature_perturbation=\"interventional\", data = deceased.X)\r\n      File \"/usr/local/lib/python3.8/dist-packages/shap/explainers/_tree.py\", line 147, in __init__\r\n        self.model = TreeEnsemble(model, self.data, self.data_missing, model_output)\r\n      File \"/usr/local/lib/python3.8/dist-packages/shap/explainers/_tree.py\", line 827, in __init__\r\n        self.trees = xgb_loader.get_trees(data=data, data_missing=data_missing)\r\n      File \"/usr/local/lib/python3.8/dist-packages/shap/explainers/_tree.py\", line 1522, in get_trees\r\n        trees.append(SingleTree({\r\n      File \"/usr/local/lib/python3.8/dist-packages/shap/explainers/_tree.py\", line 1353, in __init__\r\n        _cext.dense_tree_update_weights(\r\n    SystemError: <built-in function dense_tree_update_weights> returned NULL without setting an error\r\n\r\nI have literally no idea what's causing this error, and this message isn't helpful: I never did anything like `array_alloc`, which I thought was a C-level thing to do.\r\n\r\nI'm running Python 3.8.0 on Ubuntu 18.04 on a VM, using `shap 0.38.1`\r\n\r\nI tried updating to Python 3.8.8, but that made the situation even worse, because one of the dependencies of `shap` isn't compatible with that version:\r\n\r\n    Collecting slicer==0.0.7 (from shap)\r\n      Could not find a version that satisfies the requirement slicer==0.0.7 (from shap) (from versions: )\r\n    No matching distribution found for slicer==0.0.7 (from shap)\r\n\r\nHow can I run the `shap` library?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1844/reactions",
    "total_count": 2,
    "+1": 2,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1844/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
