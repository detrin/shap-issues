{
  "url": "https://api.github.com/repos/shap/shap/issues/2617",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2617/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2617/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2617/events",
  "html_url": "https://github.com/shap/shap/issues/2617",
  "id": 1303060080,
  "node_id": "I_kwDOBHDcK85Nqx5w",
  "number": 2617,
  "title": "Explainer Index out of range",
  "user": {
    "login": "LukasFides",
    "id": 101324546,
    "node_id": "U_kgDOBgoXAg",
    "avatar_url": "https://avatars.githubusercontent.com/u/101324546?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/LukasFides",
    "html_url": "https://github.com/LukasFides",
    "followers_url": "https://api.github.com/users/LukasFides/followers",
    "following_url": "https://api.github.com/users/LukasFides/following{/other_user}",
    "gists_url": "https://api.github.com/users/LukasFides/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/LukasFides/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/LukasFides/subscriptions",
    "organizations_url": "https://api.github.com/users/LukasFides/orgs",
    "repos_url": "https://api.github.com/users/LukasFides/repos",
    "events_url": "https://api.github.com/users/LukasFides/events{/privacy}",
    "received_events_url": "https://api.github.com/users/LukasFides/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 22,
  "created_at": "2022-07-13T08:03:20Z",
  "updated_at": "2022-09-07T10:59:49Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi, I am trying out this great framework with a self trained GPT-2.\r\n\r\nI wanted to use a custom trained model and the base model as tokenizer.\r\n\r\nNo matter if I use this approach or solely the base model (\"dbmdz/german-gpt2\") I receive the following error:\r\n\r\n```\r\n[/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py](https://dbhohk3q2ad-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20220711-060047-RC00_460172213#) in embedding(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\r\n   2197         # remove once script supports set_grad_enabled\r\n   2198         _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\r\n-> 2199     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\n   2200 \r\n   2201 \r\n\r\nIndexError: index out of range in self\r\n```\r\n\r\n\r\nHere is my code:\r\n\r\n\r\n```\r\nimport numpy as np\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\r\nimport shap\r\nimport torch\r\n\r\nmodel_name = \"dbmdz/german-gpt2\"\r\nmodel_n = \"dbmdz/german-gpt2\"\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\r\nmodel = AutoModelForCausalLM.from_pretrained(\"/content/gdrive/MyDrive/Models/gpt2-contract_40epoch\") \r\n#or model = AutoModelForCausalLM.from_pretrained(model_name) \r\n\r\n set model decoder to true\r\nmodel.config.is_decoder=True\r\n#set text-generation params under task_specific_params\r\nmodel.config.task_specific_params[\"text-generation\"] = {\r\n    \"do_sample\": True,\r\n    \"max_length\": 50,\r\n    \"temperature\": 0.7,\r\n    \"top_k\": 50,\r\n    \"no_repeat_ngram_size\": 2\r\n}\r\n\r\n#sample for generation\r\n\r\ns = ['I enjoy walking with my cute dog']\r\nexplainer = shap.Explainer(model, tokenizer)\r\nshap_values = explainer(s)\r\n\r\nshap.plots.text(shap_values)\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2617/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2617/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
