{
  "url": "https://api.github.com/repos/shap/shap/issues/868",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/868/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/868/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/868/events",
  "html_url": "https://github.com/shap/shap/issues/868",
  "id": 513000513,
  "node_id": "MDU6SXNzdWU1MTMwMDA1MTM=",
  "number": 868,
  "title": "Only analyze features included in model (predcontrib,predinteraction) ",
  "user": {
    "login": "palVJ",
    "id": 32021533,
    "node_id": "MDQ6VXNlcjMyMDIxNTMz",
    "avatar_url": "https://avatars.githubusercontent.com/u/32021533?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/palVJ",
    "html_url": "https://github.com/palVJ",
    "followers_url": "https://api.github.com/users/palVJ/followers",
    "following_url": "https://api.github.com/users/palVJ/following{/other_user}",
    "gists_url": "https://api.github.com/users/palVJ/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/palVJ/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/palVJ/subscriptions",
    "organizations_url": "https://api.github.com/users/palVJ/orgs",
    "repos_url": "https://api.github.com/users/palVJ/repos",
    "events_url": "https://api.github.com/users/palVJ/events{/privacy}",
    "received_events_url": "https://api.github.com/users/palVJ/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2019-10-27T18:07:06Z",
  "updated_at": "2019-11-04T19:41:58Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Having a large data set (in my case 350k x 450k), an ensemble method such as XGBoost may include after training only a small subset of features in the trees. At least when using R, using predict.xgb.Booster() with either predcontrib = TRUE or predinteractions = TRUE will return a matrix/array with all features from original training data (thereby consisting of a huge amount of zeros), but I only want to analyze those features included in the trees. \r\n\r\nI have looked at the source code (XGBoosterPredict_R -> XGBoosterPredict -> Predict -> PredictContribution/PredictInteractionContributions), but unfortunately extremely unexperienced with C++, and so not sure what should be done. Is there a quick fix? If someone would want to help me with this, I would deeply appreciate it. Simply setting model$feature_names = \"FeaturesOfInterest\" and making sure newdata/validation data only consists of \"FeaturesOfInterest\" in the R-function predict() does not work, where model is a xgb.Booster-object returned after training. It returns something very strange. I do think something needs to be done in source code. \r\nAlso tried to use xgb.attr() or xgb.parameters<- with no success, but I think these are the ones that need to be used since it seems to change the variables within C++ environment.\r\n\r\nIn addition, as far as I have understood, the array when computing interactions may be very sparse. An idea would be to return an array something like a DelayedArray perhaps. See [https://github.com/Bioconductor/DelayedArray](url)\r\n\r\nRelated to #786 \r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/868/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/868/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
