{
  "url": "https://api.github.com/repos/shap/shap/issues/2350",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2350/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2350/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2350/events",
  "html_url": "https://github.com/shap/shap/issues/2350",
  "id": 1098113785,
  "node_id": "I_kwDOBHDcK85Bc-L5",
  "number": 2350,
  "title": "[contributions_matrix] How to convert logodds explanations to probabilities?",
  "user": {
    "login": "IamAmar",
    "id": 22263158,
    "node_id": "MDQ6VXNlcjIyMjYzMTU4",
    "avatar_url": "https://avatars.githubusercontent.com/u/22263158?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/IamAmar",
    "html_url": "https://github.com/IamAmar",
    "followers_url": "https://api.github.com/users/IamAmar/followers",
    "following_url": "https://api.github.com/users/IamAmar/following{/other_user}",
    "gists_url": "https://api.github.com/users/IamAmar/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/IamAmar/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/IamAmar/subscriptions",
    "organizations_url": "https://api.github.com/users/IamAmar/orgs",
    "repos_url": "https://api.github.com/users/IamAmar/repos",
    "events_url": "https://api.github.com/users/IamAmar/events{/privacy}",
    "received_events_url": "https://api.github.com/users/IamAmar/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2022-01-10T16:38:01Z",
  "updated_at": "2022-01-10T16:38:01Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Since I have build H2O model using h2o.aml, I am not doing one-hot encoding; I am bound to use contributions_matrix to find the shapley values.\r\n\r\nI am trying to see how each variable contributes to the probability and since the shapley value for an observation is sum(shapley of all variables), when I applied below formula to get the probability from shapley value of the observation, I end up getting probability which is different from actual probability prediction:\r\n\r\n> p=e^x/(1 + e^x)\r\n\r\nI am looking for an alternative for below step when using h2o.aml model\r\n\r\n`shap.TreeExplainer(xgb_model,data = shap.sample(df, 100),model_output='probability')`\r\n\r\n\r\nNote: When I use above approach with h2o.aml model, I got below error:\r\n\r\n`Exception: Model type not yet supported by TreeExplainer: <class 'h2o.estimators.generic.H2OGenericEstimator'>`\r\n\r\nAny help would be much appreciated.\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2350/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2350/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
