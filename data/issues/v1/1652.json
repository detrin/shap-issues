{
  "url": "https://api.github.com/repos/shap/shap/issues/1652",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1652/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1652/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1652/events",
  "html_url": "https://github.com/shap/shap/issues/1652",
  "id": 766708925,
  "node_id": "MDU6SXNzdWU3NjY3MDg5MjU=",
  "number": 1652,
  "title": "KernelShap class problem (binary)",
  "user": {
    "login": "Atnamass",
    "id": 49812933,
    "node_id": "MDQ6VXNlcjQ5ODEyOTMz",
    "avatar_url": "https://avatars.githubusercontent.com/u/49812933?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Atnamass",
    "html_url": "https://github.com/Atnamass",
    "followers_url": "https://api.github.com/users/Atnamass/followers",
    "following_url": "https://api.github.com/users/Atnamass/following{/other_user}",
    "gists_url": "https://api.github.com/users/Atnamass/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Atnamass/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Atnamass/subscriptions",
    "organizations_url": "https://api.github.com/users/Atnamass/orgs",
    "repos_url": "https://api.github.com/users/Atnamass/repos",
    "events_url": "https://api.github.com/users/Atnamass/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Atnamass/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-12-14T16:46:43Z",
  "updated_at": "2020-12-14T17:54:24Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hello,\r\n\r\nI have been using ShapKernel explainer in order to generate explanations for my own image data set.\r\nI have also implemented another model (CNN) and included it into the code instead of the VGG16 one.\r\n\r\nIn the case VGG16  the image net dataset is used (999 classes) and everytime explanation is generated the results show the prediction for the top 3 classes.\r\nIn my case I only have 2 classes and when the results are displayed the prediction is shown only for the top class. What I would like is to have the prediction for both classes shown - so that it is easier to understand the contribution to each of the class on the image/ or why there is a higher probability of that class for each image.\r\nThe same as it is shown in the ImageNet example: https://slundberg.github.io/shap/notebooks/ImageNet%20VGG16%20Model%20with%20Keras.html\r\n\r\n**Current SHAP code:**\r\nI have been trying to make changes by doing some modifications to this last part:\r\n\r\ndef f(z):\r\n       return model.predict(preprocess_input(mask_image(z, segments_slic, images_bleeding_val_sample, 255)))\r\n\r\nFor example:\r\n\r\ndef f(z):\r\n       return model.predict_proba(preprocess_input(mask_image(z, segments_slic, images_bleeding_val_sample, 255)))\r\n\r\nHas anybody run in a similar issue using their own model?\r\nThe other option I thought of doing was to make changes in the CNN model code already - and train it again, in order for it to produce two outputs for each class.\r\n\r\n**Example of the explanation:**\r\n\r\n![pastedImage1](https://user-images.githubusercontent.com/49812933/102109341-9b560d80-3e3c-11eb-941a-59e75b0671d2.png)\r\n\r\n![pastedImage2](https://user-images.githubusercontent.com/49812933/102109369-a14bee80-3e3c-11eb-8274-a1f997afc17a.png)\r\n\r\nWhat I would like to generate (but with the two classes I have):\r\n\r\n![pastedImage](https://user-images.githubusercontent.com/49812933/102109388-a7da6600-3e3c-11eb-9fcc-55e0adc1461e.png)\r\n\r\nCNN model, training part of the code:\r\n\r\n# Training\r\n\r\nNow, we save the model and save it to disk. For this, we use this Keras code as the blue print: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d.\r\n\r\n[4]:\r\n#dimensions of our images.\r\nimg_width, img_height = 150, 150\r\n​\r\nnb_train_samples = training_data_length\r\nnb_validation_samples = validation_data_length\r\nepochs = 50\r\nbatch_size = 16\r\n​\r\nif K.image_data_format() == 'channels_first':\r\n    input_shape = (3, img_width, img_height)\r\nelse:\r\n    input_shape = (img_width, img_height, 3)\r\n​\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n​\r\nmodel.add(Conv2D(32, (3, 3)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n​\r\nmodel.add(Conv2D(64, (3, 3)))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\n​\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(1))\r\nmodel.add(Activation('sigmoid'))\r\n​\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='rmsprop',\r\n              metrics=['accuracy'])\r\n​\r\n#this is the augmentation configuration we will use for training\r\ntrain_datagen = ImageDataGenerator(\r\n    rescale=1. / 255,\r\n    shear_range=0.2,\r\n    zoom_range=0.2,\r\n    horizontal_flip=True)\r\n​\r\n#this is the augmentation configuration we will use for testing:\r\n#only rescaling\r\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\r\n​\r\ntrain_generator = train_datagen.flow_from_directory(\r\n    training_path,\r\n    target_size=(img_width, img_height),\r\n    batch_size=batch_size,\r\n    class_mode='binary')\r\n​\r\nvalidation_generator = test_datagen.flow_from_directory(\r\n    validation_path,\r\n    target_size=(img_width, img_height),\r\n    batch_size=batch_size,\r\n    class_mode='binary')\r\n​\r\nmodel.fit_generator(\r\n    train_generator,\r\n    steps_per_epoch=nb_train_samples // batch_size,\r\n    epochs=epochs,\r\n    validation_data=validation_generator,\r\n    validation_steps=nb_validation_samples // batch_size)\r\n​\r\nmodel.save_weights('model.h5')\r\n\r\nmodel.save('model_full.h5')\r\n\r\nWhat I have also tried is using the softmax activation function instead of the sigmoid one and using 'categorical_crossentropy' instead of the binary_crossentropy loss function in the training of the model.\r\n\r\nAny help would be appreciated!\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1652/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1652/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
