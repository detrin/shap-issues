{
  "url": "https://api.github.com/repos/shap/shap/issues/837",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/837/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/837/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/837/events",
  "html_url": "https://github.com/shap/shap/issues/837",
  "id": 499926006,
  "node_id": "MDU6SXNzdWU0OTk5MjYwMDY=",
  "number": 837,
  "title": "TreeExplainer on binary LightGBM model produces shap values for multi-class",
  "user": {
    "login": "eghamtech",
    "id": 19264180,
    "node_id": "MDQ6VXNlcjE5MjY0MTgw",
    "avatar_url": "https://avatars.githubusercontent.com/u/19264180?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/eghamtech",
    "html_url": "https://github.com/eghamtech",
    "followers_url": "https://api.github.com/users/eghamtech/followers",
    "following_url": "https://api.github.com/users/eghamtech/following{/other_user}",
    "gists_url": "https://api.github.com/users/eghamtech/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/eghamtech/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/eghamtech/subscriptions",
    "organizations_url": "https://api.github.com/users/eghamtech/orgs",
    "repos_url": "https://api.github.com/users/eghamtech/repos",
    "events_url": "https://api.github.com/users/eghamtech/events{/privacy}",
    "received_events_url": "https://api.github.com/users/eghamtech/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 9,
  "created_at": "2019-09-29T14:34:51Z",
  "updated_at": "2020-04-01T04:32:21Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I have come across a number of models on different data sets whereby LightGBM model clearly trained on binary data and configured to produce just a single output value between 0 and 1, however, when explained using SHAP TreeExplainer it produces SHAP values as if it is a multi-output model. When trying to do summary plot with type='dot' it then produces error:\r\n\r\nAssertionError: Only plot_type = 'bar' is supported for multi-output explanations!\r\n\r\nSo in such cases I can only produce a bar chart but it makes little sense since the data doesn't have multiple classes and yet, in some cases TreeExplainer thinks data has 6 classes, in some cases 2 classes, which is definitely not true.\r\n\r\nThis doesn't happen always, so on most other data I worked with using same code everything works fine, shap values and dot/violin plots produced as expected, but occasionally I get data where this fails as described and I cannot see what it is so special about such data.\r\n\r\nAre you able to assist with what may be happening here?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/837/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 1,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/837/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
