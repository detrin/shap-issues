{
  "url": "https://api.github.com/repos/shap/shap/issues/1609",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1609/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1609/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1609/events",
  "html_url": "https://github.com/shap/shap/issues/1609",
  "id": 751746326,
  "node_id": "MDU6SXNzdWU3NTE3NDYzMjY=",
  "number": 1609,
  "title": "AttributeError: 'Text' object has no attribute '_tokenized_s'",
  "user": {
    "login": "robinvanschaik",
    "id": 46967558,
    "node_id": "MDQ6VXNlcjQ2OTY3NTU4",
    "avatar_url": "https://avatars.githubusercontent.com/u/46967558?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/robinvanschaik",
    "html_url": "https://github.com/robinvanschaik",
    "followers_url": "https://api.github.com/users/robinvanschaik/followers",
    "following_url": "https://api.github.com/users/robinvanschaik/following{/other_user}",
    "gists_url": "https://api.github.com/users/robinvanschaik/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/robinvanschaik/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/robinvanschaik/subscriptions",
    "organizations_url": "https://api.github.com/users/robinvanschaik/orgs",
    "repos_url": "https://api.github.com/users/robinvanschaik/repos",
    "events_url": "https://api.github.com/users/robinvanschaik/events{/privacy}",
    "received_events_url": "https://api.github.com/users/robinvanschaik/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-11-26T17:27:15Z",
  "updated_at": "2020-11-26T23:02:24Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "After trying out Pytorch Captum for explaining my trained text classifier, as described [here](https://github.com/robinvanschaik/interpret-flair), I am looking into of doing the same with SHAP as in [this branch](https://github.com/robinvanschaik/interpret-flair/tree/shap-interpretation). \r\n\r\nI read [this tutorial](\r\nhttps://shap.readthedocs.io/en/latest/example_notebooks/partition_explainer/Emotion%20Data%20Multiclass%20Text%20Explanation%20Demo.html), but I am running into some issues. \r\n\r\nThis is the stack trace:\r\n```---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-23-eda1d2a70059> in <module>\r\n----> 1 shap_values = explainer(sentence)\r\n\r\n~/.conda/envs/python38/lib/python3.8/site-packages/shap/explainers/_explainer.py in __call__(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\r\n    194             feature_names = [[] for _ in range(len(args))]\r\n    195         for row_args in show_progress(zip(*args), num_rows, self.__class__.__name__+\" explainer\", silent):\r\n--> 196             row_result = self.explain_row(\r\n    197                 *row_args, max_evals=max_evals, main_effects=main_effects, error_bounds=error_bounds,\r\n    198                 batch_size=batch_size, silent=silent, **kwargs\r\n\r\n~/.conda/envs/python38/lib/python3.8/site-packages/shap/explainers/_partition.py in explain_row(self, max_evals, main_effects, error_bounds, batch_size, silent, *row_args)\r\n    430 \r\n    431         # build a masked version of the model for the current input sample\r\n--> 432         fm = MaskedModel(self.model, self.masker, self.link, *row_args)\r\n    433 \r\n    434         if max_evals == \"auto\":\r\n\r\n~/.conda/envs/python38/lib/python3.8/site-packages/shap/utils/_masked_model.py in __init__(self, model, masker, link, *args)\r\n     23         # if the masker supports it, save what positions vary from the background\r\n     24         if callable(getattr(self.masker, \"invariants\", None)):\r\n---> 25             self._variants = ~self.masker.invariants(*args)\r\n     26             self._variants_column_sums = self._variants.sum(0)\r\n     27             self._variants_row_inds = [\r\n\r\n~/.conda/envs/python38/lib/python3.8/site-packages/shap/maskers/_text.py in invariants(self, s)\r\n    154         self._update_s_cache(s)\r\n    155 \r\n--> 156         invariants = np.zeros(len(self._tokenized_s), dtype=np.bool)\r\n    157         if self.keep_prefix > 0:\r\n    158             invariants[:self.keep_prefix] = True\r\n\r\nAttributeError: 'Text' object has no attribute '_tokenized_s'\r\n```\r\n\r\nAny pointers on what is going wrong?\r\n\r\nMy first indication is that this regards the  transformers-based tokenizer that I use. ",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1609/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1609/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
