{
  "url": "https://api.github.com/repos/shap/shap/issues/2791",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2791/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2791/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2791/events",
  "html_url": "https://github.com/shap/shap/issues/2791",
  "id": 1487622403,
  "node_id": "I_kwDOBHDcK85Yq1ED",
  "number": 2791,
  "title": "Comparing SHAP values across models and re-trained models",
  "user": {
    "login": "alanzablocki",
    "id": 10878444,
    "node_id": "MDQ6VXNlcjEwODc4NDQ0",
    "avatar_url": "https://avatars.githubusercontent.com/u/10878444?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/alanzablocki",
    "html_url": "https://github.com/alanzablocki",
    "followers_url": "https://api.github.com/users/alanzablocki/followers",
    "following_url": "https://api.github.com/users/alanzablocki/following{/other_user}",
    "gists_url": "https://api.github.com/users/alanzablocki/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/alanzablocki/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/alanzablocki/subscriptions",
    "organizations_url": "https://api.github.com/users/alanzablocki/orgs",
    "repos_url": "https://api.github.com/users/alanzablocki/repos",
    "events_url": "https://api.github.com/users/alanzablocki/events{/privacy}",
    "received_events_url": "https://api.github.com/users/alanzablocki/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": true,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2022-12-09T23:30:37Z",
  "updated_at": "2023-06-04T00:10:11Z",
  "closed_at": "2023-06-04T00:10:11Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "**Can we compare SHAP values (feature importance and attribution) across different tree based models?** \r\n\r\nThe idea would be to have different models trained with same data to understand what the model is learning both overall and for each training instance? I feel like this is being done in this post https://medium.com/towards-data-science/interpretable-machine-learning-with-xgboost-9ec80d148d27 to show inconsistency? To what extent can you compare feature attributions across models?\r\n\r\n**Can we compare or subtract SHAP values between an old and a model re-trained on the most recent data (trained model last month, re-trained this month)?**\r\nIn this example, we have the same model type, same features, but now the new data picks up on something that happened in the real world and so the feature attribution might change. The person examining the prediction attribution would be able to say that for the prediction this month feature X1 is more important overall vs feature X2 ( which was most important last month) because something drastic happened in the real world that affects feature X1. Would taking the differences between the mean SHAP value be the correct thing to do, to show the extent of how much that feature now adds to the prediction? I feel like this is bordering on causality, so I am curious if this is something that SHAP can answer, or if SHAP should not be used to answer.\r\n\r\nThank you.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2791/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2791/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
