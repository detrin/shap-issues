{
  "url": "https://api.github.com/repos/shap/shap/issues/190",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/190/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/190/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/190/events",
  "html_url": "https://github.com/shap/shap/issues/190",
  "id": 345748556,
  "node_id": "MDU6SXNzdWUzNDU3NDg1NTY=",
  "number": 190,
  "title": "heuristic for displaying the most important features in the explanation to the user?",
  "user": {
    "login": "ihadanny",
    "id": 953357,
    "node_id": "MDQ6VXNlcjk1MzM1Nw==",
    "avatar_url": "https://avatars.githubusercontent.com/u/953357?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ihadanny",
    "html_url": "https://github.com/ihadanny",
    "followers_url": "https://api.github.com/users/ihadanny/followers",
    "following_url": "https://api.github.com/users/ihadanny/following{/other_user}",
    "gists_url": "https://api.github.com/users/ihadanny/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ihadanny/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ihadanny/subscriptions",
    "organizations_url": "https://api.github.com/users/ihadanny/orgs",
    "repos_url": "https://api.github.com/users/ihadanny/repos",
    "events_url": "https://api.github.com/users/ihadanny/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ihadanny/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2018-07-30T13:03:40Z",
  "updated_at": "2018-07-30T17:23:53Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hey,\r\nI'm using SHAP and getting a vector of contributions per feature as an explanation to a single instance. Now I would like to show to the user only the most important features that contributed to the positive direction (drove the score up). I thought about the following heuristics:\r\n\r\n1. Sum all positive contribs, display the features that contributed more than x% of the total sum (e.g. more than 10%).\r\n2. Find the largest positive contrib, display it and all other features that are at least x% of it.\r\n3. Compare the contribs to the bias, display positive features that are at least x% of the bias\r\n\r\nWhich would be more reasonable? Note that I would like the method to be generic, it should easily migrate between explanation models with ~50 features and other explanation models with ~10 features.\r\n\r\nthanks! ",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/190/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/190/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
