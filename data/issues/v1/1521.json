{
  "url": "https://api.github.com/repos/shap/shap/issues/1521",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1521/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1521/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1521/events",
  "html_url": "https://github.com/shap/shap/issues/1521",
  "id": 720736664,
  "node_id": "MDU6SXNzdWU3MjA3MzY2NjQ=",
  "number": 1521,
  "title": "Top N features that are responsible for the local SHAP value",
  "user": {
    "login": "derigod",
    "id": 34924403,
    "node_id": "MDQ6VXNlcjM0OTI0NDAz",
    "avatar_url": "https://avatars.githubusercontent.com/u/34924403?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/derigod",
    "html_url": "https://github.com/derigod",
    "followers_url": "https://api.github.com/users/derigod/followers",
    "following_url": "https://api.github.com/users/derigod/following{/other_user}",
    "gists_url": "https://api.github.com/users/derigod/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/derigod/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/derigod/subscriptions",
    "organizations_url": "https://api.github.com/users/derigod/orgs",
    "repos_url": "https://api.github.com/users/derigod/repos",
    "events_url": "https://api.github.com/users/derigod/events{/privacy}",
    "received_events_url": "https://api.github.com/users/derigod/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2020-10-13T19:41:33Z",
  "updated_at": "2020-10-14T14:57:23Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I've been trying to use SHAP values in my ML to help understand the contribution of each feature on the local outcome. I understand that SHAP values of all features sum up to explain why the prediction was different from the baseline value. This allows us to decompose a prediction in a graph.\r\n\r\nMy output will need rank the features in terms of contribution to the local value in positive and negative contribution. While I am able to get this graphically using the force plot, I need a way to get the top 3 features in an array or DataFrame. Is there an easy way to do this.\r\n\r\nFor example ;\r\nI was wondering if there was a way to get the top 3 features that contribute positively and negatively (Higher and lower) )to the SHAP value in my example\r\n\r\nplot the SHAP values for the 0th observation\r\n![image](https://user-images.githubusercontent.com/34924403/95908117-90163100-0d6a-11eb-9dfa-ce059db1b4e1.png)\r\n\r\nSCodR_D' helps push the value to the right\r\nSCfL_M, ZofC_H ,No_transactions push in the other direction\r\nI need these features as an array or a dataframe so I can preform further operations on them",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1521/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1521/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
