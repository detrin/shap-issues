{
  "url": "https://api.github.com/repos/shap/shap/issues/431",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/431/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/431/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/431/events",
  "html_url": "https://github.com/shap/shap/issues/431",
  "id": 407076603,
  "node_id": "MDU6SXNzdWU0MDcwNzY2MDM=",
  "number": 431,
  "title": "Shap for CNN-RNN Architecture",
  "user": {
    "login": "jlevy44",
    "id": 19698023,
    "node_id": "MDQ6VXNlcjE5Njk4MDIz",
    "avatar_url": "https://avatars.githubusercontent.com/u/19698023?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jlevy44",
    "html_url": "https://github.com/jlevy44",
    "followers_url": "https://api.github.com/users/jlevy44/followers",
    "following_url": "https://api.github.com/users/jlevy44/following{/other_user}",
    "gists_url": "https://api.github.com/users/jlevy44/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jlevy44/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jlevy44/subscriptions",
    "organizations_url": "https://api.github.com/users/jlevy44/orgs",
    "repos_url": "https://api.github.com/users/jlevy44/repos",
    "events_url": "https://api.github.com/users/jlevy44/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jlevy44/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2019-02-06T04:28:27Z",
  "updated_at": "2019-02-13T01:06:12Z",
  "closed_at": "2019-02-13T01:06:12Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Is it possible to use DeepSHAP on a video, sequence of images, and extract a saliency map for a particular image or at least across all of the images?\r\n\r\nInput is dimensions [#samples (can remove this dimension), # images, width, height, RGB], and the final RNN output is the predicted value.\r\n\r\nThe CNN extracts the features for each image, and the RNN aggregates them, and I want to map the aggregated prediction back to this 3-4D 1 sample data structure.",
  "closed_by": {
    "login": "jlevy44",
    "id": 19698023,
    "node_id": "MDQ6VXNlcjE5Njk4MDIz",
    "avatar_url": "https://avatars.githubusercontent.com/u/19698023?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jlevy44",
    "html_url": "https://github.com/jlevy44",
    "followers_url": "https://api.github.com/users/jlevy44/followers",
    "following_url": "https://api.github.com/users/jlevy44/following{/other_user}",
    "gists_url": "https://api.github.com/users/jlevy44/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jlevy44/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jlevy44/subscriptions",
    "organizations_url": "https://api.github.com/users/jlevy44/orgs",
    "repos_url": "https://api.github.com/users/jlevy44/repos",
    "events_url": "https://api.github.com/users/jlevy44/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jlevy44/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/431/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/431/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
