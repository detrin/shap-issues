{
  "url": "https://api.github.com/repos/shap/shap/issues/1860",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1860/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1860/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1860/events",
  "html_url": "https://github.com/shap/shap/issues/1860",
  "id": 823054280,
  "node_id": "MDU6SXNzdWU4MjMwNTQyODA=",
  "number": 1860,
  "title": "Masking Layer results in additivity check failing",
  "user": {
    "login": "Zahlii",
    "id": 218582,
    "node_id": "MDQ6VXNlcjIxODU4Mg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/218582?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Zahlii",
    "html_url": "https://github.com/Zahlii",
    "followers_url": "https://api.github.com/users/Zahlii/followers",
    "following_url": "https://api.github.com/users/Zahlii/following{/other_user}",
    "gists_url": "https://api.github.com/users/Zahlii/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Zahlii/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Zahlii/subscriptions",
    "organizations_url": "https://api.github.com/users/Zahlii/orgs",
    "repos_url": "https://api.github.com/users/Zahlii/repos",
    "events_url": "https://api.github.com/users/Zahlii/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Zahlii/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2021-03-05T12:48:57Z",
  "updated_at": "2021-03-05T14:28:42Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "```python\r\nimport tensorflow as tf\r\ntf.__version__\r\n```\r\n\r\n\r\n\r\n\r\n    '2.4.1'\r\n\r\n\r\n\r\n\r\n```python\r\nimport shap\r\nshap.__version__\r\n```\r\n\r\n\r\n\r\n\r\n    '0.39.0'\r\n\r\n\r\n\r\n\r\n```python\r\nimport numpy as np\r\n\r\nC = 99\r\n\r\nx = np.random.random((20, 30, 3))\r\ny = x.sum(axis=-1, keepdims=True)\r\nprint(x.shape, y.shape)\r\n\r\n# first 4 samples are truncated after step 25\r\nx[0:4, 25:, :] = C\r\n\r\nwith tf.device(\"CPU:0\"):\r\n    class MaskedConv1D(tf.keras.layers.Conv1D):\r\n        def compute_mask(self, input, mask=None):\r\n            return mask\r\n\r\n    i = tf.keras.layers.Input(shape=(30, 3))\r\n    # m = tf.keras.layers.Masking(C)(i) # if you enable this line and remove the next, additivity fails\r\n    m = i\r\n    o = MaskedConv1D(use_bias=False, kernel_size=1, filters=1, kernel_initializer=\"ones\")(m)\r\n    \r\n    model = tf.keras.models.Model(i, o)\r\n    model.summary()\r\n    model.compile(loss=\"MSE\", optimizer=\"Adam\")\r\n    model.evaluate(x, y)\r\n    \r\n    fixed_out = tf.reduce_sum(o, axis=-1)\r\n    s_model = tf.keras.models.Model(i, fixed_out)\r\n    \r\n    exp = shap.DeepExplainer(s_model, x)\r\n    s = exp.shap_values(x) # this fails\r\n\r\n    exp = shap.DeepExplainer(s_model, x[4:]) # excluding them from data AND from the explanations will work\r\n    s = exp.shap_values(x[4:])\r\n```\r\n\r\n    (20, 30, 3) (20, 30, 1)\r\n    Model: \"model_11\"\r\n    _________________________________________________________________\r\n    Layer (type)                 Output Shape              Param #   \r\n    =================================================================\r\n    input_9 (InputLayer)         [(None, 30, 3)]           0         \r\n    _________________________________________________________________\r\n    masked_conv1d_7 (MaskedConv1 (None, 30, 1)             3         \r\n    =================================================================\r\n    Total params: 3\r\n    Trainable params: 3\r\n    Non-trainable params: 0\r\n    _________________________________________________________________\r\n    1/1 [==============================] - 0s 84ms/step - loss: 2910.9321\r\n\r\nNote that we can circumvent the problem by building the same model WITHOUT the mask layer, and then simply adding our custom masking and loading the weights from the existing model.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1860/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1860/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
