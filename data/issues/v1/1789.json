{
  "url": "https://api.github.com/repos/shap/shap/issues/1789",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1789/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1789/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1789/events",
  "html_url": "https://github.com/shap/shap/pull/1789",
  "id": 795614587,
  "node_id": "MDExOlB1bGxSZXF1ZXN0NTYyOTMzMzc1",
  "number": 1789,
  "title": "Add support for textual entailment",
  "user": {
    "login": "jsu27",
    "id": 23248462,
    "node_id": "MDQ6VXNlcjIzMjQ4NDYy",
    "avatar_url": "https://avatars.githubusercontent.com/u/23248462?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jsu27",
    "html_url": "https://github.com/jsu27",
    "followers_url": "https://api.github.com/users/jsu27/followers",
    "following_url": "https://api.github.com/users/jsu27/following{/other_user}",
    "gists_url": "https://api.github.com/users/jsu27/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jsu27/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jsu27/subscriptions",
    "organizations_url": "https://api.github.com/users/jsu27/orgs",
    "repos_url": "https://api.github.com/users/jsu27/repos",
    "events_url": "https://api.github.com/users/jsu27/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jsu27/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2021-01-28T02:37:27Z",
  "updated_at": "2021-02-09T21:19:10Z",
  "closed_at": "2021-02-09T21:19:05Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/shap/shap/pulls/1789",
    "html_url": "https://github.com/shap/shap/pull/1789",
    "diff_url": "https://github.com/shap/shap/pull/1789.diff",
    "patch_url": "https://github.com/shap/shap/pull/1789.patch",
    "merged_at": "2021-02-09T21:19:05Z"
  },
  "body": "Textual entailment: given a premise sentence and hypothesis sentence, does the premise imply the hypothesis\r\n\r\nUltimately, we want to pass the input in as 1 argument. The task requires 2 arguments, a premise and hypothesis. To process these, we use the tokenizer to encode the premise and hypothesis then decode the result. This gives the premise and hypothesis concatenated by separator token(s), a single string.\r\n\r\n**Code changes:** \r\n- added logic for preventing the masking of sep tokens (because we want masked sentences to always maintain sep tokens to inform the tokenizer that these represent 2 sentences)\r\n- added logic in group merging function (`merge_score`) to take in optional special tokens (in our case, sep tokens), and ensure that groups with adjacent special tokens are merged last. For this task, this ensures the partition tree's 1st subtree is the 1st sentence and 2nd subtree is the 2nd sentence. The motivation is that we want to explore interaction between tokens within each sentence, though future experimentation can explore interactions between both sentences.\r\n- added demo notebook demonstrating how to run SHAP for a textual entailment model. Preprocessing of the input and model is involved.\r\n\r\n**Potential Issues** \r\n- _Inconsistent Encoding of Masked Sentences:_ Given an original sentence, and given a masked version of the sentence where certain tokens are replaced by masks, it would be ideal to see that their tokenizer encodings have the same shape and that encoded tokens correspond to each other.\r\n\r\nWe observed that the tokenizer, when encoding then decoding certain unusual masked sentences, adds 1 or more token(s) than the original sentence's encoding shape.\r\n\r\nExample:\r\n ```\r\noriginal_sentence = 'A boy is jumping on skateboard in the middle of a red bridge.</s></s>The boy skates down the sidewalk.'\r\n# len 27\r\noriginal_tokens = ['<s>', 'A', ' boy', ' is', ' jumping', ' on', ' skate', 'board', ' in', ' the', ' middle', ' of', ' a', ' red', ' bridge', '.', '</s>', '</s>', 'The', ' boy', ' sk', 'ates', ' down', ' the', ' sidewalk', '.', '</s>']\r\n```\r\n- Bad masked sentence 1\r\n```\r\nmasked_sentence1 = 'A boy is jumping on skateboard in the middle of a red bridge.</s></s><mask> <mask> <mask> ates down the sidewalk.' \r\n# len 28\r\nmasked_tokens1 = ['<s>', 'A', ' boy', ' is', ' jumping', ' on', ' skate', 'board', ' in', ' the', ' middle', ' of', ' a', ' red', ' bridge', '.', '</s>', '</s>', '<mask>', '<mask>', '<mask>', ' at', 'es', ' down', ' the', ' sidewalk', '.', '</s>'] \r\n```\r\nThe **'ates'** in the masked sentence was tokenized into 2 parts, 'at' and 'es'. We would expect 'ates' to remain the same. \r\n\r\n- Bad masked sentence 2: \r\n```\r\nmasked_sentence2 =  '<mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> </s></s>The boy skates down the sidewalk.\r\n'\r\n# len 28\r\nmasked_tokens2 = ['<s>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', '<mask>', ' ', '</s>', '</s>', 'The', ' boy', ' sk', 'ates', ' down', ' the', ' sidewalk', '.', '</s>']\r\n```\r\nThere is an unnecessary space ' ' token added after the masks and before the separator.\r\n\r\nWe avoid the issue in our demo notebook by running model evaluations on masked sentences individually instead of passing masked sentences in batches, potentially losing efficiency. Note that this is a tokenizer issue that varies by tokenizer, though we have seen this behavior in at least 2.\r\n\r\n**Further comments: Potential Future Work** \r\n- _Improving Clustering Method:_ Currently, the clustering method to build the partition tree (specifically `merge_score` in `_text.py`) uses heuristics to make decisions about when to combine groups. It would be great to determine if there are more well-founded and better-performing methods.\r\n- _Exploring Interaction Effects between words in both sentences:_ We currently split the partition tree so that the 1st sentence is 1 subtree and 2nd sentence is another so that words in both don't interact with each other. It would be helpful to see if allowing words of both sentences to interact with each other, as they do for humans to understand connections between 2 sentences, improves results.\r\n- _Supporting More Models:_ We used Facebook's BART model trained on mnli in our example, but it would be useful to test and/or extend support for other textual entailment models, such as BERT. Since different tokenizers use different special tokens and tokenizing schemes (such as BERT's [CLS] token), there may be issues at first.\r\n",
  "closed_by": {
    "login": "slundberg",
    "id": 3740613,
    "node_id": "MDQ6VXNlcjM3NDA2MTM=",
    "avatar_url": "https://avatars.githubusercontent.com/u/3740613?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/slundberg",
    "html_url": "https://github.com/slundberg",
    "followers_url": "https://api.github.com/users/slundberg/followers",
    "following_url": "https://api.github.com/users/slundberg/following{/other_user}",
    "gists_url": "https://api.github.com/users/slundberg/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/slundberg/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/slundberg/subscriptions",
    "organizations_url": "https://api.github.com/users/slundberg/orgs",
    "repos_url": "https://api.github.com/users/slundberg/repos",
    "events_url": "https://api.github.com/users/slundberg/events{/privacy}",
    "received_events_url": "https://api.github.com/users/slundberg/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1789/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 1,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1789/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
