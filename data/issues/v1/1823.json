{
  "url": "https://api.github.com/repos/shap/shap/issues/1823",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1823/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1823/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1823/events",
  "html_url": "https://github.com/shap/shap/issues/1823",
  "id": 809862735,
  "node_id": "MDU6SXNzdWU4MDk4NjI3MzU=",
  "number": 1823,
  "title": "explaining force_plot when feature=0",
  "user": {
    "login": "ironv",
    "id": 4298134,
    "node_id": "MDQ6VXNlcjQyOTgxMzQ=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4298134?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ironv",
    "html_url": "https://github.com/ironv",
    "followers_url": "https://api.github.com/users/ironv/followers",
    "following_url": "https://api.github.com/users/ironv/following{/other_user}",
    "gists_url": "https://api.github.com/users/ironv/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ironv/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ironv/subscriptions",
    "organizations_url": "https://api.github.com/users/ironv/orgs",
    "repos_url": "https://api.github.com/users/ironv/repos",
    "events_url": "https://api.github.com/users/ironv/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ironv/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2021-02-17T05:18:36Z",
  "updated_at": "2021-02-17T05:18:36Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "My binary classification model was created using `lightgbm` and 120k observations in the training dataset (1's & 0's ~1:1).   The model has an average precision of ~91% and the features make sense.  The summary plot is shown below.\r\n![image](https://user-images.githubusercontent.com/4298134/108158065-290adf00-70b2-11eb-9b25-926c11a84292.png)\r\n\r\nThe force plot for an observation with `label=1` and very low score is shown (trying to look at observations which will likely be FNs)\r\n![image](https://user-images.githubusercontent.com/4298134/108158279-99b1fb80-70b2-11eb-979a-6d9ba54a1618.png)\r\n\r\nMy question is regarding the features which have a value of 0 in the input matrix `X` and yet have a shapley value contribution (features 746, 777, 1587, etc. in the above picture).  [This](https://christophm.github.io/interpretable-ml-book/shap.html) source suggests that it can happen when these features are correlated with other feature(s) (with non-zero value in `X`) which influence the prediction.\r\n1. is there a reference to this in any of the published work on `TreeShap`?  Is there any other explanation for those non-zero shap values?\r\n2. is there a function or any other support in `shap` to identify those features (correlated and in `X`)\r\n3. if not, the way I am thinking of adding insight is - (i) for the above observation, identify features which are non-zero in `X`.  (ii) Compute correlation between all those features and feature 746 (iii) repeat for others.  I am hoping there is a better way.\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1823/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1823/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
