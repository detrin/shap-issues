{
  "url": "https://api.github.com/repos/shap/shap/issues/2929",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2929/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2929/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2929/events",
  "html_url": "https://github.com/shap/shap/issues/2929",
  "id": 1717947879,
  "node_id": "I_kwDOBHDcK85mZc3n",
  "number": 2929,
  "title": "GradientExplainer only works on copies of models?",
  "user": {
    "login": "delacylab",
    "id": 93732324,
    "node_id": "U_kgDOBZY95A",
    "avatar_url": "https://avatars.githubusercontent.com/u/93732324?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/delacylab",
    "html_url": "https://github.com/delacylab",
    "followers_url": "https://api.github.com/users/delacylab/followers",
    "following_url": "https://api.github.com/users/delacylab/following{/other_user}",
    "gists_url": "https://api.github.com/users/delacylab/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/delacylab/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/delacylab/subscriptions",
    "organizations_url": "https://api.github.com/users/delacylab/orgs",
    "repos_url": "https://api.github.com/users/delacylab/repos",
    "events_url": "https://api.github.com/users/delacylab/events{/privacy}",
    "received_events_url": "https://api.github.com/users/delacylab/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2023-05-20T00:00:08Z",
  "updated_at": "2023-05-20T00:03:51Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I am trying to use shap with an LSTM and data with 4 time periods so my datasets typically look like (num_rows,4,num_features). Because DeepExplainer is not compatible with Tensorflow 2.x, I have been using GradientExplainer but ran into this bizarre problem where calling the Explainer with my model gives me a warning but calling it on a copy of the model works properly.\r\n_clf = Sequential()\r\nclf.add(Bidirectional(LSTM(layer_size, activation='tanh', return_sequences=True))) \r\nclf.add(Bidirectional(LSTM(layer_size, activation='tanh')))\r\nclf.add(Dense(2, activation = 'softmax'))\r\nclf.compile(loss=\"categorical_crossentropy\", optimizer = tfa.optimizers.AdamW(weight_decay=.01), metrics=['accuracy'])\r\ny_cat = tf.keras.utils.to_categorical(y, num_classes=2) \r\nearly_stopping_monitor = EarlyStopping(min_delta = 0.01, monitor='loss',patience=10)\r\nclf.fit(X,y_cat, epochs=200, callbacks=[early_stopping_monitor])\r\ne = shap.GradientExplainer(clf, X)_\r\n\r\nIf I then later call:\r\n_shap_values, shap_indexes = e.shap_values(rep)_ \r\nI get this warning:\r\nWARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(138, 4, 187)...\r\n\r\nI do not get the warning if I change the final line in the first code segment to:\r\n_e = shap.GradientExplainer(copy.deepcopy(clf), X)_\r\nHas anyone else run into this? Is shap thread-safe or is there something else going on? This is the only way I have got GradientExplainer to work without warnings that worry me,\r\n\r\n\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2929/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2929/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
