{
  "url": "https://api.github.com/repos/shap/shap/issues/2012",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/2012/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/2012/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/2012/events",
  "html_url": "https://github.com/shap/shap/issues/2012",
  "id": 900653274,
  "node_id": "MDU6SXNzdWU5MDA2NTMyNzQ=",
  "number": 2012,
  "title": "Speeding up the Partition Explainer by 20%",
  "user": {
    "login": "GillesVandewiele",
    "id": 5750603,
    "node_id": "MDQ6VXNlcjU3NTA2MDM=",
    "avatar_url": "https://avatars.githubusercontent.com/u/5750603?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/GillesVandewiele",
    "html_url": "https://github.com/GillesVandewiele",
    "followers_url": "https://api.github.com/users/GillesVandewiele/followers",
    "following_url": "https://api.github.com/users/GillesVandewiele/following{/other_user}",
    "gists_url": "https://api.github.com/users/GillesVandewiele/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/GillesVandewiele/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/GillesVandewiele/subscriptions",
    "organizations_url": "https://api.github.com/users/GillesVandewiele/orgs",
    "repos_url": "https://api.github.com/users/GillesVandewiele/repos",
    "events_url": "https://api.github.com/users/GillesVandewiele/events{/privacy}",
    "received_events_url": "https://api.github.com/users/GillesVandewiele/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-05-25T11:07:53Z",
  "updated_at": "2021-05-27T07:09:31Z",
  "closed_at": "2021-05-27T07:09:31Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Hi @slundberg,\r\n\r\nI have been experimenting a bit with the Partition Explainer (which is really fast, so thanks!). However, there are still some bottlenecks that can be improved. The largest bottleneck is the `owen` calculation, but this I will need to further inspect.\r\n\r\nHowever, by making some changes to `partition_tree` and `merge_score`, I managed to speed up the code with about 20%.\r\n\r\nThe changes can be summarised as follows:\r\n1. avoid redundant calls of `merge_score()` within `partition_tree`. In every iteration of `partition_tree`, `merge_score` is called on every token group. However, only 2 token groups actually changed since last iteration, so all of these calculations are redundant.\r\n2. Add lru_cache to `merge_score`. This seems to already speed up the code significantly. This does require the token groups to be converted to tuples instead of list. Possibly an even better improvement can be achieved by not passing group1 and group2 as arguments but rather the limited amount of information that is used from those 2 variables within that function (`group1[0].s`, `group1[-1].s`, `len(group1)`, ...)\r\n\r\n\r\nHere are the patches I did:\r\n```python\r\nfrom functools import lru_cache\r\n\r\nopeners = {\r\n    \"(\": \")\"\r\n}\r\nclosers = {\r\n    \")\": \"(\"\r\n}\r\nenders = [\".\", \",\"]\r\nconnectors = [\"but\", \"and\", \"or\"]\r\n\r\ndef partition_tree(decoded_tokens, special_tokens=None):\r\n    \"\"\" Build a heriarchial clustering of tokens that align with sentence structure.\r\n    Note that this is fast and heuristic right now.\r\n    TODO: Build this using a real constituency parser.\r\n    \"\"\"\r\n    token_groups = [shap.maskers._text.TokenGroup([shap.maskers._text.Token(t)], i) \r\n                    for i, t in enumerate(decoded_tokens)]\r\n    M = len(decoded_tokens)\r\n    new_index = M\r\n    clustm = np.zeros((M-1, 4))\r\n    scores = [merge_score(tuple(token_groups[i]), \r\n                          tuple(token_groups[i+1]), \r\n                          tuple(special_tokens)) for i in range(len(token_groups)-1)]\r\n    N = len(token_groups) - 1\r\n    for i in range(N):\r\n        ind = np.argmax(scores)\r\n        \r\n        lind = token_groups[ind].index\r\n        rind = token_groups[ind+1].index\r\n        clustm[new_index-M, 0] = token_groups[ind].index\r\n        clustm[new_index-M, 1] = token_groups[ind+1].index\r\n        clustm[new_index-M, 2] = -scores[ind]\r\n        clustm[new_index-M, 3] = (clustm[lind-M, 3] if lind >= M else 1) + (clustm[rind-M, 3] if rind >= M else 1)\r\n\r\n        token_groups[ind] = token_groups[ind] + token_groups[ind+1]\r\n        token_groups[ind].index = new_index\r\n\r\n        # track balancing of openers/closers\r\n        if token_groups[ind][0].s in openers and token_groups[ind+1][-1].s == openers[token_groups[ind][0].s]:\r\n            token_groups[ind][0].balanced = True\r\n            token_groups[ind+1][-1].balanced = True\r\n        \r\n        token_groups.pop(ind+1)\r\n        new_index += 1\r\n        \r\n        if len(scores) > 3:\r\n            score1 = merge_score(tuple(token_groups[ind - 1]), \r\n                                 tuple(token_groups[ind]), \r\n                                 tuple(special_tokens))        \r\n            score2 = merge_score(tuple(token_groups[ind]), \r\n                                 tuple(token_groups[ind + 1]), \r\n                                 tuple(special_tokens))\r\n            scores = scores[:ind - 1] + [score1, score2] + scores[ind + 2:]\r\n        else:\r\n            scores = [merge_score(tuple(token_groups[i]), \r\n                                  tuple(token_groups[i+1]), \r\n                                  tuple(special_tokens)) for i in range(len(token_groups)-1)]\r\n\r\n    # negative means we should never split a group, so we add 10 to ensure these are very tight groups\r\n    # (such as parts of the same word)\r\n    clustm[:, 2] = clustm[:, 2] + 10\r\n    return clustm\r\n\r\n@lru_cache(maxsize=5000)\r\ndef merge_score(group1, group2, special_tokens=None):\r\n    \"\"\" Compute the score of merging two token groups.\r\n    special_tokens: tokens (such as separator tokens) that should be grouped last\r\n    \"\"\"\r\n    score = 0\r\n    # ensures special tokens are combined last, so 1st subtree is 1st sentence and 2nd subtree is 2nd sentence\r\n    if special_tokens is not None:\r\n        if group1[-1].s in special_tokens and group2[0].s in special_tokens:\r\n            score -= math.inf # subtracting infinity to create lowest score and ensure combining these groups last\r\n\r\n    # merge broken-up parts of words first\r\n    if group2[0].s.startswith(\"##\"):\r\n        score += 20\r\n\r\n    # merge apostrophe endings next\r\n    if group2[0].s == \"'\" and (len(group2) == 1 or (len(group2) == 2 and group2[1].s in [\"t\", \"s\"])):\r\n        score += 15\r\n    if group1[-1].s == \"'\" and group2[0].s in [\"t\", \"s\"]:\r\n        score += 15\r\n\r\n    start_ctrl = group1[0].s.startswith(\"[\") and group1[0].s.endswith(\"]\")\r\n    end_ctrl = group2[-1].s.startswith(\"[\") and group2[-1].s.endswith(\"]\")\r\n\r\n    if (start_ctrl and not end_ctrl) or (end_ctrl and not start_ctrl):\r\n        score -= 1000\r\n    if group2[0].s in openers and not group2[0].balanced:\r\n        score -= 100\r\n    if group1[-1].s in closers and not group1[-1].balanced:\r\n        score -= 100\r\n\r\n    # attach surrounding an openers and closers a bit later\r\n    if group1[0].s in openers and not group2[-1] in closers:\r\n        score -= 2\r\n\r\n    # reach across connectors later\r\n    if group1[-1].s in connectors or group2[0].s in connectors:\r\n        score -= 2\r\n\r\n    # reach across commas later\r\n    if group1[-1].s == \",\":\r\n        score -= 10\r\n    if group2[0].s == \",\":\r\n        if len(group2) > 1: # reach across\r\n            score -= 10\r\n        else:\r\n            score -= 1\r\n\r\n    # reach across sentence endings later\r\n    if group1[-1].s in [\".\", \"?\", \"!\"]:\r\n        score -= 20\r\n    if group2[0].s in [\".\", \"?\", \"!\"]:\r\n        if len(group2) > 1: # reach across\r\n            score -= 20\r\n        else:\r\n            score -= 1\r\n\r\n    score -= len(group1) + len(group2)\r\n    #print(group1, group2, score)\r\n    return score\r\n```\r\n\r\nThen I patch & call the code as follows:\r\n```python\r\nshap.maskers._text.partition_tree = partition_tree\r\nshap.explainers._partition.Partition.owen = owen\r\nmasker = shap.maskers.Text(tokenizer, output_type=\"string\")\r\nexplainer = shap.Explainer(f, masker, algorithm='partition')\r\nshap_values = explainer(\r\n    ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc maximus nisi nisi, vehicula pulvinar justo placerat sed. In id laoreet erat. Nam volutpat dignissim tincidunt. Sed lacinia ipsum in ipsum rhoncus, et ultricies ipsum vehicula. Etiam tellus urna, pharetra nec lectus quis, semper lobortis purus. Sed luctus diam eget finibus mollis. Suspendisse laoreet lacinia nunc quis rhoncus. Aliquam ut ligula malesuada ligula convallis congue sed id justo. Suspendisse sem tellus, finibus sit amet sagittis ut, faucibus quis justo. Aliquam in ornare eros, in fringilla erat. Ut non eros vehicula, auctor tellus a, eleifend velit. Fusce eu pellentesque velit. Donec magna erat, viverra et pharetra ac, ultrices a nisi. Praesent molestie orci erat. Curabitur sit amet tincidunt neque. Fusce a erat enim. Mauris non tortor congue, viverra elit vel, porttitor lectus. Curabitur maximus maximus nisl at sollicitudin. Nunc ligula massa, mattis non porta sit amet, feugiat nec libero. Maecenas suscipit libero ac ligula suscipit maximus. Fusce venenatis dolor arcu, in dapibus eros pharetra at. Nunc ultricies sit amet orci nec venenatis. Duis cursus, magna vel lobortis tristique, metus lorem congue ipsum, ut venenatis urna ligula sed ligula. Quisque felis urna, cursus vitae convallis eu, congue non nibh. Pellentesque semper mi nisi, at placerat turpis tempus quis.'], \r\n    max_evals=100, fixed_context=1)\r\n```\r\n\r\nWhich results in a 20% runtime improvement.",
  "closed_by": {
    "login": "GillesVandewiele",
    "id": 5750603,
    "node_id": "MDQ6VXNlcjU3NTA2MDM=",
    "avatar_url": "https://avatars.githubusercontent.com/u/5750603?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/GillesVandewiele",
    "html_url": "https://github.com/GillesVandewiele",
    "followers_url": "https://api.github.com/users/GillesVandewiele/followers",
    "following_url": "https://api.github.com/users/GillesVandewiele/following{/other_user}",
    "gists_url": "https://api.github.com/users/GillesVandewiele/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/GillesVandewiele/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/GillesVandewiele/subscriptions",
    "organizations_url": "https://api.github.com/users/GillesVandewiele/orgs",
    "repos_url": "https://api.github.com/users/GillesVandewiele/repos",
    "events_url": "https://api.github.com/users/GillesVandewiele/events{/privacy}",
    "received_events_url": "https://api.github.com/users/GillesVandewiele/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/2012/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/2012/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
