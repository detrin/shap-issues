{
  "url": "https://api.github.com/repos/shap/shap/issues/1066",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1066/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1066/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1066/events",
  "html_url": "https://github.com/shap/shap/issues/1066",
  "id": 571128706,
  "node_id": "MDU6SXNzdWU1NzExMjg3MDY=",
  "number": 1066,
  "title": "pytest doesn't produce consistent results",
  "user": {
    "login": "rightx2",
    "id": 10606994,
    "node_id": "MDQ6VXNlcjEwNjA2OTk0",
    "avatar_url": "https://avatars.githubusercontent.com/u/10606994?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/rightx2",
    "html_url": "https://github.com/rightx2",
    "followers_url": "https://api.github.com/users/rightx2/followers",
    "following_url": "https://api.github.com/users/rightx2/following{/other_user}",
    "gists_url": "https://api.github.com/users/rightx2/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/rightx2/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/rightx2/subscriptions",
    "organizations_url": "https://api.github.com/users/rightx2/orgs",
    "repos_url": "https://api.github.com/users/rightx2/repos",
    "events_url": "https://api.github.com/users/rightx2/events{/privacy}",
    "received_events_url": "https://api.github.com/users/rightx2/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2020-02-26T07:41:57Z",
  "updated_at": "2020-02-26T11:22:17Z",
  "closed_at": "2020-02-26T11:22:17Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "I run `pytest -k test_deep -s`  3 times in a row, but passed 2 times only ...\r\n\r\nNeed to fix seed or something. I will send pull request soon.\r\n\r\nBelow is history\r\n\r\n```\r\n(base) Chois@mycomputer:~/shap$ pytest -k test_deep -s\r\n======================================= test session starts =======================================\r\nplatform linux -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\r\nrootdir: /home/Chois/shap\r\ncollected 88 items / 82 deselected / 6 selected\r\n\r\ntests/explainers/test_deep.py sssDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\r\n9920512it [00:05, 1944327.79it/s]\r\nExtracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\r\n32768it [00:00, 49176.81it/s]\r\nExtracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\r\n1654784it [00:02, 703473.99it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\r\n8192it [00:00, 19138.31it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nProcessing...\r\nDone!\r\nRunning test on interim layer\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.090099\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.090328\r\nRunning test on whole model\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.091516\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.090683\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 503.008514\r\nTrain Epoch: 1 [256/506 (50%)]  Loss: 766.144958\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 1628.259766\r\nTrain Epoch: 1 [1012/506 (50%)] Loss: 4810.717773\r\nTrain Epoch: 1 [0/506 (0%)] Loss: 3396.286133\r\nTrain Epoch: 1 [1012/506 (50%)] Loss: 2523.672607\r\n.\r\n\r\n======================================== warnings summary =========================================\r\n/home/Chois/miniconda3/lib/python3.7/site-packages/nose/importer.py:12\r\n  the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n\r\ntests/explainers/test_deep.py::test_pytorch_mnist_cnn\r\n  Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n==================== 3 passed, 3 skipped, 82 deselected, 2 warnings in 13.18s =====================\r\n(base) Chois@mycomputer:~/shap$ pytest -k test_deep -s\r\n======================================= test session starts =======================================\r\nplatform linux -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\r\nrootdir: /home/Chois/shap\r\ncollected 88 items / 82 deselected / 6 selected\r\n\r\ntests/explainers/test_deep.py sssDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\r\n9920512it [00:07, 1394949.83it/s]\r\nExtracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\r\n32768it [00:00, 50425.19it/s]\r\nExtracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\r\n1654784it [00:03, 529012.61it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\r\n8192it [00:00, 18314.63it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nProcessing...\r\nDone!\r\nRunning test on interim layer\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.091646\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.091288\r\nRunning test on whole model\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.091562\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.091164\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 491.191467\r\nTrain Epoch: 1 [256/506 (50%)]  Loss: 752.134277\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 15223.615234\r\nTrain Epoch: 1 [1012/506 (50%)] Loss: 13968.725586\r\nTrain Epoch: 1 [0/506 (0%)] Loss: 2479.997314\r\nTrain Epoch: 1 [1012/506 (50%)] Loss: 4829.720215\r\n.\r\n\r\n======================================== warnings summary =========================================\r\n/home/Chois/miniconda3/lib/python3.7/site-packages/nose/importer.py:12\r\n  the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n\r\ntests/explainers/test_deep.py::test_pytorch_mnist_cnn\r\n  Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n==================== 3 passed, 3 skipped, 82 deselected, 2 warnings in 16.05s =====================\r\n(base) Chois@mycomputer:~/shap$ pytest -k test_deep -s\r\n======================================= test session starts =======================================\r\nplatform linux -- Python 3.7.4, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\r\nrootdir: /home/Chois/shap\r\ncollected 88 items / 82 deselected / 6 selected\r\n\r\ntests/explainers/test_deep.py sssDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\r\n9920512it [00:06, 1526654.11it/s]\r\nExtracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\r\n32768it [00:00, 52031.63it/s]\r\nExtracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\r\n1654784it [00:08, 191662.68it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\r\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\r\n8192it [00:00, 17809.51it/s]\r\nExtracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\r\nProcessing...\r\nDone!\r\nRunning test on interim layer\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.092349\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.091887\r\nRunning test on whole model\r\nTrain Epoch: 1 [0/60000 (0%)]   Loss: 0.089468\r\nTrain Epoch: 1 [1280/60000 (2%)]    Loss: 0.089875\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 487.916534\r\nTrain Epoch: 1 [256/506 (50%)]  Loss: 747.277283\r\n.Train Epoch: 1 [0/506 (0%)]    Loss: 505.373444\r\nTrain Epoch: 1 [1012/506 (50%)] Loss: 768.959778\r\nF\r\n\r\n============================================ FAILURES =============================================\r\n__________________________________ test_pytorch_multiple_inputs ___________________________________\r\n\r\n    def test_pytorch_multiple_inputs():\r\n        _skip_if_no_pytorch()\r\n\r\n        def _run_pytorch_multiple_inputs_test(disconnected):\r\n            \"\"\"Testing multiple inputs\r\n            \"\"\"\r\n            import torch\r\n            from torch import nn\r\n            from torch.nn import functional as F\r\n            from torch.utils.data import TensorDataset, DataLoader\r\n            from sklearn.datasets import load_boston\r\n            import shap\r\n\r\n            X, y = load_boston(return_X_y=True)\r\n            num_features = X.shape[1]\r\n            x1 = X[:, num_features // 2:]\r\n            x2 = X[:, :num_features // 2]\r\n            data = TensorDataset(torch.tensor(x1).float(),\r\n                                 torch.tensor(x2).float(),\r\n                                 torch.tensor(y).float())\r\n            loader = DataLoader(data, batch_size=128)\r\n\r\n            class Net(nn.Module):\r\n                def __init__(self, num_features, disconnected):\r\n                    super(Net, self).__init__()\r\n                    self.disconnected = disconnected\r\n                    if disconnected:\r\n                        num_features = num_features // 2 + 1\r\n                    self.linear = nn.Linear(num_features, 2)\r\n                    self.output = nn.Sequential(\r\n                        nn.MaxPool1d(2),\r\n                        nn.ReLU()\r\n                    )\r\n\r\n                def forward(self, x1, x2):\r\n                    if self.disconnected:\r\n                        x = self.linear(x1).unsqueeze(1)\r\n                    else:\r\n                        x = self.linear(torch.cat((x1, x2), dim=-1)).unsqueeze(1)\r\n                    return self.output(x).squeeze(1)\r\n\r\n            model = Net(num_features, disconnected)\r\n            optimizer = torch.optim.Adam(model.parameters())\r\n\r\n            def train(model, device, train_loader, optimizer, epoch):\r\n                model.train()\r\n                num_examples = 0\r\n                for batch_idx, (data1, data2, target) in enumerate(train_loader):\r\n                    num_examples += target.shape[0]\r\n                    data1, data2, target = data1.to(device), data2.to(device), target.to(device)\r\n                    optimizer.zero_grad()\r\n                    output = model(data1, data2)\r\n                    loss = F.mse_loss(output.squeeze(1), target)\r\n                    loss.backward()\r\n                    optimizer.step()\r\n                    if batch_idx % 2 == 0:\r\n                        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n                            epoch, batch_idx * len(data), len(train_loader.dataset),\r\n                                   100. * batch_idx / len(train_loader), loss.item()))\r\n\r\n            device = torch.device('cpu')\r\n            train(model, device, loader, optimizer, 1)\r\n\r\n            next_x1, next_x2, next_y = next(iter(loader))\r\n            np.random.seed(0)\r\n            inds = np.random.choice(next_x1.shape[0], 20, replace=False)\r\n            background = [next_x1[inds, :], next_x2[inds, :]]\r\n            e = shap.DeepExplainer(model, background)\r\n            test_x1, test_x2, test_y = next(iter(loader))\r\n            shap_x1, shap_x2 = e.shap_values([test_x1[:1], test_x2[:1]])\r\n\r\n            model.eval()\r\n            model.zero_grad()\r\n            with torch.no_grad():\r\n                diff = (model(test_x1[:1], test_x2[:1]) - model(*background)).detach().numpy().mean(0)\r\n            sums = np.array([shap_x1[i].sum() + shap_x2[i].sum() for i in range(len(shap_x1))])\r\n            d = np.abs(sums - diff).sum()\r\n            assert d / np.abs(diff).sum() < 0.001, \"Sum of SHAP values does not match difference! %f\" % (\r\n                    d / np.abs(diff).sum())\r\n\r\n>       _run_pytorch_multiple_inputs_test(disconnected=True)\r\n\r\ntests/explainers/test_deep.py:465:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\ndisconnected = True\r\n\r\n    def _run_pytorch_multiple_inputs_test(disconnected):\r\n        \"\"\"Testing multiple inputs\r\n        \"\"\"\r\n        import torch\r\n        from torch import nn\r\n        from torch.nn import functional as F\r\n        from torch.utils.data import TensorDataset, DataLoader\r\n        from sklearn.datasets import load_boston\r\n        import shap\r\n\r\n        X, y = load_boston(return_X_y=True)\r\n        num_features = X.shape[1]\r\n        x1 = X[:, num_features // 2:]\r\n        x2 = X[:, :num_features // 2]\r\n        data = TensorDataset(torch.tensor(x1).float(),\r\n                             torch.tensor(x2).float(),\r\n                             torch.tensor(y).float())\r\n        loader = DataLoader(data, batch_size=128)\r\n\r\n        class Net(nn.Module):\r\n            def __init__(self, num_features, disconnected):\r\n                super(Net, self).__init__()\r\n                self.disconnected = disconnected\r\n                if disconnected:\r\n                    num_features = num_features // 2 + 1\r\n                self.linear = nn.Linear(num_features, 2)\r\n                self.output = nn.Sequential(\r\n                    nn.MaxPool1d(2),\r\n                    nn.ReLU()\r\n                )\r\n\r\n            def forward(self, x1, x2):\r\n                if self.disconnected:\r\n                    x = self.linear(x1).unsqueeze(1)\r\n                else:\r\n                    x = self.linear(torch.cat((x1, x2), dim=-1)).unsqueeze(1)\r\n                return self.output(x).squeeze(1)\r\n\r\n        model = Net(num_features, disconnected)\r\n        optimizer = torch.optim.Adam(model.parameters())\r\n\r\n        def train(model, device, train_loader, optimizer, epoch):\r\n            model.train()\r\n            num_examples = 0\r\n            for batch_idx, (data1, data2, target) in enumerate(train_loader):\r\n                num_examples += target.shape[0]\r\n                data1, data2, target = data1.to(device), data2.to(device), target.to(device)\r\n                optimizer.zero_grad()\r\n                output = model(data1, data2)\r\n                loss = F.mse_loss(output.squeeze(1), target)\r\n                loss.backward()\r\n                optimizer.step()\r\n                if batch_idx % 2 == 0:\r\n                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n                        epoch, batch_idx * len(data), len(train_loader.dataset),\r\n                               100. * batch_idx / len(train_loader), loss.item()))\r\n\r\n        device = torch.device('cpu')\r\n        train(model, device, loader, optimizer, 1)\r\n\r\n        next_x1, next_x2, next_y = next(iter(loader))\r\n        np.random.seed(0)\r\n        inds = np.random.choice(next_x1.shape[0], 20, replace=False)\r\n        background = [next_x1[inds, :], next_x2[inds, :]]\r\n        e = shap.DeepExplainer(model, background)\r\n        test_x1, test_x2, test_y = next(iter(loader))\r\n        shap_x1, shap_x2 = e.shap_values([test_x1[:1], test_x2[:1]])\r\n\r\n        model.eval()\r\n        model.zero_grad()\r\n        with torch.no_grad():\r\n            diff = (model(test_x1[:1], test_x2[:1]) - model(*background)).detach().numpy().mean(0)\r\n        sums = np.array([shap_x1[i].sum() + shap_x2[i].sum() for i in range(len(shap_x1))])\r\n        d = np.abs(sums - diff).sum()\r\n>       assert d / np.abs(diff).sum() < 0.001, \"Sum of SHAP values does not match difference! %f\" % (\r\n                d / np.abs(diff).sum())\r\nE       AssertionError: Sum of SHAP values does not match difference! nan\r\nE       assert (0.0 / 0.0) < 0.001\r\nE        +  where 0.0 = <built-in method sum of numpy.ndarray object at 0x7f16f8c3a4e0>()\r\nE        +    where <built-in method sum of numpy.ndarray object at 0x7f16f8c3a4e0> = array([0.], dtype=float32).sum\r\nE        +      where array([0.], dtype=float32) = <ufunc 'absolute'>(array([0.], dtype=float32))\r\nE        +        where <ufunc 'absolute'> = np.abs\r\n\r\ntests/explainers/test_deep.py:462: AssertionError\r\n======================================== warnings summary =========================================\r\n/home/Chois/miniconda3/lib/python3.7/site-packages/nose/importer.py:12\r\n  the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n\r\ntests/explainers/test_deep.py::test_pytorch_mnist_cnn\r\n  Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n\r\ntests/explainers/test_deep.py::test_pytorch_multiple_inputs\r\n  invalid value encountered in double_scalars\r\n\r\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\r\n```",
  "closed_by": {
    "login": "rightx2",
    "id": 10606994,
    "node_id": "MDQ6VXNlcjEwNjA2OTk0",
    "avatar_url": "https://avatars.githubusercontent.com/u/10606994?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/rightx2",
    "html_url": "https://github.com/rightx2",
    "followers_url": "https://api.github.com/users/rightx2/followers",
    "following_url": "https://api.github.com/users/rightx2/following{/other_user}",
    "gists_url": "https://api.github.com/users/rightx2/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/rightx2/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/rightx2/subscriptions",
    "organizations_url": "https://api.github.com/users/rightx2/orgs",
    "repos_url": "https://api.github.com/users/rightx2/repos",
    "events_url": "https://api.github.com/users/rightx2/events{/privacy}",
    "received_events_url": "https://api.github.com/users/rightx2/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1066/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1066/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
