{
  "url": "https://api.github.com/repos/shap/shap/issues/1431",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/1431/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/1431/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/1431/events",
  "html_url": "https://github.com/shap/shap/issues/1431",
  "id": 701782693,
  "node_id": "MDU6SXNzdWU3MDE3ODI2OTM=",
  "number": 1431,
  "title": "Solved, I think, an issue with _clustering.py, was not able to make a pull request",
  "user": {
    "login": "launis",
    "id": 62068629,
    "node_id": "MDQ6VXNlcjYyMDY4NjI5",
    "avatar_url": "https://avatars.githubusercontent.com/u/62068629?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/launis",
    "html_url": "https://github.com/launis",
    "followers_url": "https://api.github.com/users/launis/followers",
    "following_url": "https://api.github.com/users/launis/following{/other_user}",
    "gists_url": "https://api.github.com/users/launis/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/launis/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/launis/subscriptions",
    "organizations_url": "https://api.github.com/users/launis/orgs",
    "repos_url": "https://api.github.com/users/launis/repos",
    "events_url": "https://api.github.com/users/launis/events{/privacy}",
    "received_events_url": "https://api.github.com/users/launis/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2020-09-15T09:48:02Z",
  "updated_at": "2020-09-15T09:48:33Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I do not know, how this affects in the whole but I noticed that in utils/_clustering.py '.iloc':s are missing from pandas dataframes\r\n\r\n_clustering.py rows 111-113 and  134-135\r\n```\r\n    for i in range(X.shape[1]):\r\n        model = xgboost.XGBRegressor(subsample=subsample, n_estimators=max_estimators, learning_rate=learning_rate, max_depth=1)\r\n        #Set Pandas dataframes with iloc to point right, left numpy arrays (ie. the predictions) without iloc\r\n        model.fit(X_train.iloc[:,i:i+1], y_train, eval_set=[(X_test.iloc[:,i:i+1], y_test)], early_stopping_rounds=early_stopping_rounds, verbose=False)\r\n        train_preds.append(model.predict(X_train.iloc[:,i:i+1]))\r\n        test_preds.append(model.predict(X_test.iloc[:,i:i+1]))\r\n    train_preds = np.vstack(train_preds).T\r\n    test_preds = np.vstack(test_preds).T\r\n\r\n    # fit XGBoost models to predict the outputs of other XGBoost models to see how redundant features are\r\n    dist = np.zeros((X.shape[1], X.shape[1]))\r\n    for i in show_progress(range(X.shape[1]), total=X.shape[1]):\r\n        for j in range(X.shape[1]):\r\n            if i == j:\r\n                dist[i,j] = 0\r\n                continue\r\n            \r\n            # skip features that have not variance in their predictions (likely because the feature is a constant)\r\n            preds_var = np.var(test_preds[:,i])\r\n            if preds_var < 1e-4:\r\n                warnings.warn(f\"No/low signal found from feature {i} (this is typically caused by constant or near-constant features)! Cluster distances can't be computed for it (so setting all distances to 1).\")\r\n                r2 = 0\r\n            \r\n            # fit the model\r\n            else:\r\n                model = xgboost.XGBRegressor(subsample=subsample, n_estimators=max_estimators, learning_rate=learning_rate, max_depth=1)\r\n                #Set Pandas dataframes with iloc to point right, left numpy arrays (ie. the predictions) without iloc\r\n                model.fit(X_train.iloc[:,j:j+1], train_preds[:,i], eval_set=[(X_test.iloc[:,j:j+1], test_preds[:,i])], early_stopping_rounds=early_stopping_rounds, verbose=False)\r\n                r2 = max(0, 1 - np.mean((test_preds[:,i] - model.predict(X_test.iloc[:,j:j+1]))**2) / preds_var)\r\n            dist[i,j] = 1 - r2\r\n\r\n```\r\n\r\ntried it with\r\n\r\n```\r\nimport pandas as pd\r\nimport shap\r\nimport xgboost\r\nimport sys\r\nimport platform\r\nimport numpy as np\r\nimport scipy\r\n\r\n#all latest versions\r\nprint(shap.__version__)\r\nprint(xgboost.__version__)\r\nprint(scipy.__version__)\r\nprint(sys.platform)\r\nprint(platform.version())\r\nprint(sys.version_info)\r\nprint()\r\n# copy from https://github.com/slundberg/shap/blob/master/notebooks/plots/bar.ipynb\r\n\r\n# train XGBoost model\r\nX,y = shap.datasets.adult()\r\nmodel = xgboost.XGBClassifier().fit(X, y)\r\n\r\n# compute SHAP values\r\nexplainer = shap.Explainer(model, X)\r\nshap_values = explainer(X)\r\nclustering = shap.utils.hclust(X, y) # by default this trains (X.shape[1] choose 2) 2-feature XGBoost models\r\nshap.plots.bar(shap_values, clustering=clustering)\r\n\r\n0.36.0\r\n1.2.0\r\n1.5.2\r\nwin32\r\n10.0.19041\r\nsys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\r\n\r\n```\r\n![image](https://user-images.githubusercontent.com/62068629/93193597-b8047b80-f74f-11ea-865a-9e1e027d7238.png)\r\n",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/1431/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/1431/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
