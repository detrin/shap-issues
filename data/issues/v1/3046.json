{
  "url": "https://api.github.com/repos/shap/shap/issues/3046",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/3046/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/3046/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/3046/events",
  "html_url": "https://github.com/shap/shap/pull/3046",
  "id": 1775078227,
  "node_id": "PR_kwDOBHDcK85T78Nn",
  "number": 3046,
  "title": "CHORE: Use faster test translation scenario, cut CI time by ~5mins",
  "user": {
    "login": "connortann",
    "id": 71127464,
    "node_id": "MDQ6VXNlcjcxMTI3NDY0",
    "avatar_url": "https://avatars.githubusercontent.com/u/71127464?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/connortann",
    "html_url": "https://github.com/connortann",
    "followers_url": "https://api.github.com/users/connortann/followers",
    "following_url": "https://api.github.com/users/connortann/following{/other_user}",
    "gists_url": "https://api.github.com/users/connortann/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/connortann/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/connortann/subscriptions",
    "organizations_url": "https://api.github.com/users/connortann/orgs",
    "repos_url": "https://api.github.com/users/connortann/repos",
    "events_url": "https://api.github.com/users/connortann/events{/privacy}",
    "received_events_url": "https://api.github.com/users/connortann/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 486901331,
      "node_id": "MDU6TGFiZWw0ODY5MDEzMzE=",
      "url": "https://api.github.com/repos/shap/shap/labels/enhancement",
      "name": "enhancement",
      "color": "84b6eb",
      "default": true,
      "description": "Indicates new feature requests"
    },
    {
      "id": 5577305596,
      "node_id": "LA_kwDOBHDcK88AAAABTG7t_A",
      "url": "https://api.github.com/repos/shap/shap/labels/ci",
      "name": "ci",
      "color": "006b75",
      "default": false,
      "description": "Relating to Continuous Integration / GitHub Actions"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "connortann",
    "id": 71127464,
    "node_id": "MDQ6VXNlcjcxMTI3NDY0",
    "avatar_url": "https://avatars.githubusercontent.com/u/71127464?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/connortann",
    "html_url": "https://github.com/connortann",
    "followers_url": "https://api.github.com/users/connortann/followers",
    "following_url": "https://api.github.com/users/connortann/following{/other_user}",
    "gists_url": "https://api.github.com/users/connortann/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/connortann/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/connortann/subscriptions",
    "organizations_url": "https://api.github.com/users/connortann/orgs",
    "repos_url": "https://api.github.com/users/connortann/repos",
    "events_url": "https://api.github.com/users/connortann/events{/privacy}",
    "received_events_url": "https://api.github.com/users/connortann/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "connortann",
      "id": 71127464,
      "node_id": "MDQ6VXNlcjcxMTI3NDY0",
      "avatar_url": "https://avatars.githubusercontent.com/u/71127464?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/connortann",
      "html_url": "https://github.com/connortann",
      "followers_url": "https://api.github.com/users/connortann/followers",
      "following_url": "https://api.github.com/users/connortann/following{/other_user}",
      "gists_url": "https://api.github.com/users/connortann/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/connortann/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/connortann/subscriptions",
      "organizations_url": "https://api.github.com/users/connortann/orgs",
      "repos_url": "https://api.github.com/users/connortann/repos",
      "events_url": "https://api.github.com/users/connortann/events{/privacy}",
      "received_events_url": "https://api.github.com/users/connortann/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2023-06-26T15:42:04Z",
  "updated_at": "2023-06-27T15:16:05Z",
  "closed_at": "2023-06-27T15:15:35Z",
  "author_association": "COLLABORATOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/shap/shap/pulls/3046",
    "html_url": "https://github.com/shap/shap/pull/3046",
    "diff_url": "https://github.com/shap/shap/pull/3046.diff",
    "patch_url": "https://github.com/shap/shap/pull/3046.patch",
    "merged_at": "2023-06-27T15:15:35Z"
  },
  "body": "Supports #3045\r\n\r\n### Overview\r\n\r\nChanges the model used in the translation scenario to amuch smaller one that will run much faster:\r\n<https://huggingface.co/mesolitica/finetune-translation-t5-super-super-tiny-standard-bahasa-cased>\r\n\r\n\r\n### Timings\r\n\r\nThe change seems to save ~5 min on Linux, and 7+ min on MacOS.\r\n\r\nOn Linux GH runner python 3.11, test timings before:\r\n\r\n```\r\n80.04s call     tests/explainers/test_partition.py::test_translation\r\n76.44s call     tests/explainers/test_partition.py::test_translation_auto\r\n76.27s call     tests/explainers/test_partition.py::test_translation_algorithm_arg\r\n74.24s call     tests/explainers/test_partition.py::test_serialization\r\n73.27s call     tests/explainers/test_partition.py::test_serialization_custom_model_save\r\n69.42s call     tests/explainers/test_partition.py::test_serialization_no_model_or_masker\r\n```\r\n\r\nTest timings after:\r\n\r\n```\r\n22.75s call     tests/explainers/test_partition.py::test_translation\r\n<19s   call     tests/explainers/test_partition.py::test_translation_auto\r\n<19s   call     tests/explainers/test_partition.py::test_translation_algorithm_arg\r\n20.38s call     tests/explainers/test_partition.py::test_serialization\r\n20.70s call     tests/explainers/test_partition.py::test_serialization_custom_model_save\r\n19.80s call     tests/explainers/test_partition.py::test_serialization_no_model_or_masker\r\n```\r\n\r\nOverall that's `328 seconds` faster on python 3.11 ðŸŽ‰\r\n\r\nTimings vary between python versions and platforms, so the overall average speedup may differ.\r\n\r\n### Note about protobuf\r\n\r\nThis new model require that we use `protobuf<=3.20.x`, or otherwise a TypeError is thrown. There is a related thread on stackoverflow [here](https://stackoverflow.com/q/72441758).\r\n\r\nHere is the full traceback:\r\n\r\n<details>\r\n\r\n```\r\n____________ ERROR at setup of test_serialization_custom_model_save ____________\r\n\r\n    @pytest.mark.skipif(sys.platform == 'win32', reason=\"Integer division bug in HuggingFace on Windows\")\r\n    @pytest.fixture(scope=\"session\")\r\n    def basic_translation_scenario():\r\n        \"\"\" Create a basic transformers translation model and tokenizer.\r\n        \"\"\"\r\n        AutoTokenizer = pytest.importorskip(\"transformers\").AutoTokenizer\r\n        AutoModelForSeq2SeqLM = pytest.importorskip(\"transformers\").AutoModelForSeq2SeqLM\r\n    \r\n        # Use a very small model, for speed\r\n        name = \"mesolitica/finetune-translation-t5-super-super-tiny-standard-bahasa-cased\"\r\n>       tokenizer = AutoTokenizer.from_pretrained(name)\r\n\r\ntests/explainers/conftest.py:16: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:691: in from_pretrained\r\n    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1825: in from_pretrained\r\n    return cls._from_pretrained(\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1988: in _from_pretrained\r\n    tokenizer = cls(*init_inputs, **init_kwargs)\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:133: in __init__\r\n    super().__init__(\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:114: in __init__\r\n    fast_tokenizer = convert_slow_tokenizer(slow_tokenizer)\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:1307: in convert_slow_tokenizer\r\n    return converter_class(transformer_tokenizer).converted()\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:445: in __init__\r\n    from .utils import sentencepiece_model_pb2 as model_pb2\r\n/opt/hostedtoolcache/Python/3.11.4/x64/lib/python3.11/site-packages/transformers/utils/sentencepiece_model_pb2.py:91: in <module>\r\n    _descriptor.EnumValueDescriptor(\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ncls = <class 'google.protobuf.descriptor.EnumValueDescriptor'>, name = 'UNIGRAM'\r\nindex = 0, number = 1, type = None, options = None, serialized_options = None\r\ncreate_key = <object object at 0x7f886b0750d0>\r\n\r\n    def __new__(cls, name, index, number,\r\n                type=None,  # pylint: disable=redefined-builtin\r\n                options=None, serialized_options=None, create_key=None):\r\n>     _message.Message._CheckCalledFromGeneratedFile()\r\nE     TypeError: Descriptors cannot not be created directly.\r\nE     If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\r\nE     If you cannot immediately regenerate your protos, some other possible workarounds are:\r\nE      1. Downgrade the protobuf package to 3.20.x or lower.\r\nE      2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\r\nE     \r\nE     More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\r\n```\r\n\r\n</details>\r\n\r\nIn future, we might be able to relax this pin if the `transformers` library is updated, or if we find an alternative Tokenizer model that was trained with a more recent version of protobuf.",
  "closed_by": {
    "login": "thatlittleboy",
    "id": 30731072,
    "node_id": "MDQ6VXNlcjMwNzMxMDcy",
    "avatar_url": "https://avatars.githubusercontent.com/u/30731072?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/thatlittleboy",
    "html_url": "https://github.com/thatlittleboy",
    "followers_url": "https://api.github.com/users/thatlittleboy/followers",
    "following_url": "https://api.github.com/users/thatlittleboy/following{/other_user}",
    "gists_url": "https://api.github.com/users/thatlittleboy/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/thatlittleboy/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/thatlittleboy/subscriptions",
    "organizations_url": "https://api.github.com/users/thatlittleboy/orgs",
    "repos_url": "https://api.github.com/users/thatlittleboy/repos",
    "events_url": "https://api.github.com/users/thatlittleboy/events{/privacy}",
    "received_events_url": "https://api.github.com/users/thatlittleboy/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/3046/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/3046/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
