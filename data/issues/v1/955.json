{
  "url": "https://api.github.com/repos/shap/shap/issues/955",
  "repository_url": "https://api.github.com/repos/shap/shap",
  "labels_url": "https://api.github.com/repos/shap/shap/issues/955/labels{/name}",
  "comments_url": "https://api.github.com/repos/shap/shap/issues/955/comments",
  "events_url": "https://api.github.com/repos/shap/shap/issues/955/events",
  "html_url": "https://github.com/shap/shap/issues/955",
  "id": 537960701,
  "node_id": "MDU6SXNzdWU1Mzc5NjA3MDE=",
  "number": 955,
  "title": "Question: Background and explaining set sizes for TreeExplainer'ing large data sets",
  "user": {
    "login": "parrt",
    "id": 178777,
    "node_id": "MDQ6VXNlcjE3ODc3Nw==",
    "avatar_url": "https://avatars.githubusercontent.com/u/178777?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/parrt",
    "html_url": "https://github.com/parrt",
    "followers_url": "https://api.github.com/users/parrt/followers",
    "following_url": "https://api.github.com/users/parrt/following{/other_user}",
    "gists_url": "https://api.github.com/users/parrt/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/parrt/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/parrt/subscriptions",
    "organizations_url": "https://api.github.com/users/parrt/orgs",
    "repos_url": "https://api.github.com/users/parrt/repos",
    "events_url": "https://api.github.com/users/parrt/events{/privacy}",
    "received_events_url": "https://api.github.com/users/parrt/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2019-12-14T20:19:30Z",
  "updated_at": "2020-12-14T11:11:47Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "From looking through the other issues and the documentation in the source code, I think I'm coming to understand what data needs to go where when using SHAP. I'm using a random forest and therefore the tree explainer. Here is my current understanding:\r\n\r\n* `TreeExplainer(model, data=mybackset, feature_dependence=\"interventional\")` requires a \"background set\" to \"break dependencies\" between codependent variables, meaning be able to treat variables independently during simulation; cost scales linearly with `len(mybackset)`\r\n* `TreeExplainer(model, feature_dependence=\"tree_path_dependent\")` simply uses the branching of the tree itself to provide explanations without need to directly access the original training data\r\n* Runtime speed for explanations is most heavily affected by the complexity of the RF, and is quadratic in the tree depth\r\n\r\nThen we use `shap_values(Xe)`  to get the actual values for records in some `Xe` explanation set. The cost is linear in `len(Xe)`.\r\n\r\nFor speed reasons, it's clear we need to reduce the size of the background set, when needed to explain codependent variables, and the number of records in the explanation set.  Fair enough. My questions are:\r\n\r\n1. How much data is needed in the background set to break dependencies between variables? Does it depend on how many variables are codependent with each other or the sets of variables that are codependent? Your recommendation is to use less than 1000 background set examples but for a data set with, say, 40,000 records, is 1000 big enough to separate variables?\r\n2.  For a large data set, how few records in the explanatory set can we get away with? Given the quadratic complexity on the tree depth, even a few test records seems expensive. For example, using the league of legends data set from your notebook and training a modest 50-tree random forest with 1229705 records, I'm seeing 1.5s per explanatory record. For 1000 records, that would take 25 minutes. Would 1000 records be enough to adequately summarize the effect of variables among 1229705 records?\r\n\r\nEven if slow, SHAP provides answers to questions we can't get right now, so I'm not complaining haha, but it's still important to understand how well we are summarizing data given the amount of information provided to SHAP.\r\n\r\nDo you have any anecdotal evidence or experiments that suggest how much data is needed for background sets and explanatory sets to capture the underlying relationships in a data set?",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/shap/shap/issues/955/reactions",
    "total_count": 6,
    "+1": 6,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/shap/shap/issues/955/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
