<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>id</th>
      <th>number</th>
      <th>title</th>
      <th>created_at</th>
      <th>updated_at</th>
      <th>days_since_created</th>
      <th>days_since_updated</th>
      <th>author_association</th>
      <th>comments</th>
      <th>body_length</th>
      <th>description_quality</th>
      <th>summary</th>
      <th>short_label</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>612</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a>2</td>
      <td>Implement a gradient explainer for autograd</td>
      <td>2019-05-29</td>
      <td>2019-05-29</td>
      <td>1550</td>
      <td>1550</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>223</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>23</td>
      <td>Questions: Any plans of extending support to H2O.ai models(including ensembles)?</td>
      <td>2018-08-15</td>
      <td>2019-08-01</td>
      <td>1836</td>
      <td>1485</td>
      <td>NONE</td>
      <td>6</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1591</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>591</td>
      <td>Add tests for SHAP integration into the slicer repo</td>
      <td>2020-12-04</td>
      <td>2020-12-04</td>
      <td>995</td>
      <td>995</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1696</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>696</td>
      <td>Image captioning using instance/semantic segmentation</td>
      <td>2021-01-13</td>
      <td>2021-03-20</td>
      <td>954</td>
      <td>889</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1697</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>697</td>
      <td>Image captioning model with its own language model for alignment scoring</td>
      <td>2021-01-13</td>
      <td>2021-01-21</td>
      <td>954</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>446</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>46</td>
      <td>display force_plot chart on dash</td>
      <td>2019-02-13</td>
      <td>2023-08-26</td>
      <td>1654</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1723</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>723</td>
      <td>Code/Performance improvements in image captioning notebooks - in memory file buffers, batching</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>947</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1725</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>725</td>
      <td>runtime &amp; memory benchmarking</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1692</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>692</td>
      <td>shap explanation compared to attention distribution matrix</td>
      <td>2021-01-12</td>
      <td>2021-01-12</td>
      <td>956</td>
      <td>956</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1918</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>918</td>
      <td>How to get odds ratio based on SHAP, just like what logistic regression model did.</td>
      <td>2021-05-18</td>
      <td>2021-05-18</td>
      <td>830</td>
      <td>830</td>
      <td>NONE</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1741</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>741</td>
      <td>Can SHAP be applied to seq2seq LSTM (input format: [sample, time step, feature]) model? seems there is only \"one sample\" in s2s LSTM mod</td>
      <td>2021-01-27</td>
      <td>2021-01-27</td>
      <td>941</td>
      <td>941</td>
      <td>NONE</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>348</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>48</td>
      <td>Support for sklearn Pipeline</td>
      <td>2018-12-06</td>
      <td>2022-04-16</td>
      <td>1724</td>
      <td>497</td>
      <td>NONE</td>
      <td>5</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1854</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>854</td>
      <td>bug: shap.summary_plot sort=false does not change the order when using interaction values</td>
      <td>2021-04-05</td>
      <td>2021-04-05</td>
      <td>873</td>
      <td>873</td>
      <td>NONE</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1967</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>967</td>
      <td>shap  has access to  use classification</td>
      <td>2021-06-23</td>
      <td>2021-06-23</td>
      <td>794</td>
      <td>794</td>
      <td>NONE</td>
      <td>0</td>
      <td>0.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>822</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>22</td>
      <td>Is there any shap lite VERSION ? One without graphs but just only shap values of model.</td>
      <td>2019-09-23</td>
      <td>2022-08-09</td>
      <td>1433</td>
      <td>382</td>
      <td>NONE</td>
      <td>4</td>
      <td>13.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>948</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>48</td>
      <td>How to uncover interaction importance for higher order interactions (3,4,5 etc)</td>
      <td>2019-12-12</td>
      <td>2019-12-17</td>
      <td>1352</td>
      <td>1348</td>
      <td>NONE</td>
      <td>3</td>
      <td>36.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1103</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>103</td>
      <td>Shap values for MultiOutputRegressor</td>
      <td>2020-03-16</td>
      <td>2023-01-01</td>
      <td>1258</td>
      <td>237</td>
      <td>NONE</td>
      <td>7</td>
      <td>40.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>821</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>21</td>
      <td>WHL File of SHAP for amazon linux</td>
      <td>2019-09-22</td>
      <td>2022-08-09</td>
      <td>1434</td>
      <td>382</td>
      <td>NONE</td>
      <td>2</td>
      <td>40.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1724</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>724</td>
      <td>pull in common strings into a strings file</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>42.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>969</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>69</td>
      <td>get SHAP value for each feature</td>
      <td>2019-12-24</td>
      <td>2020-01-06</td>
      <td>1341</td>
      <td>1327</td>
      <td>NONE</td>
      <td>2</td>
      <td>50.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>178</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>78</td>
      <td>Using XGboost with Kernel SHAP</td>
      <td>2018-07-24</td>
      <td>2021-04-26</td>
      <td>1859</td>
      <td>852</td>
      <td>NONE</td>
      <td>13</td>
      <td>53.0</td>
      <td>No</td>
      <td>User encounters issue while using XGBoost.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1730</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>730</td>
      <td>Image to Text Explainer benchmarking notebook</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>61.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1650</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>650</td>
      <td>TreeExplainer Expected_value in binary classification Xgboost</td>
      <td>2020-12-22</td>
      <td>2020-12-24</td>
      <td>977</td>
      <td>975</td>
      <td>NONE</td>
      <td>3</td>
      <td>63.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1461</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>461</td>
      <td>gradient registry has no entry for: shap_LeakyRelu</td>
      <td>2020-09-24</td>
      <td>2023-04-04</td>
      <td>1066</td>
      <td>143</td>
      <td>NONE</td>
      <td>1</td>
      <td>64.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1006</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>006</td>
      <td>Road map for SHAP</td>
      <td>2020-01-21</td>
      <td>2020-01-21</td>
      <td>1313</td>
      <td>1313</td>
      <td>NONE</td>
      <td>0</td>
      <td>65.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>662</td>
      <td><a href="https://github.com/shap/shap/issues/67">67</a>2</td>
      <td>How to interpret pretrained BERT model using shap?</td>
      <td>2019-06-25</td>
      <td>2020-10-08</td>
      <td>1523</td>
      <td>1052</td>
      <td>NONE</td>
      <td>1</td>
      <td>71.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1575</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>575</td>
      <td>multivalue shap interaction values will come? &gt; 2 players</td>
      <td>2020-11-24</td>
      <td>2020-11-24</td>
      <td>1005</td>
      <td>1005</td>
      <td>NONE</td>
      <td>1</td>
      <td>73.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2097</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>097</td>
      <td>Multi label classification</td>
      <td>2021-10-07</td>
      <td>2021-10-07</td>
      <td>688</td>
      <td>688</td>
      <td>NONE</td>
      <td>0</td>
      <td>79.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1731</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>731</td>
      <td>SHAP Serialization for -  Additive, Gradient, Kernel, Linear, Tree Explainer</td>
      <td>2021-01-22</td>
      <td>2021-01-22</td>
      <td>945</td>
      <td>945</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>79.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1422</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>422</td>
      <td>Metrics to measure Shap accuracy</td>
      <td>2020-09-11</td>
      <td>2022-07-07</td>
      <td>1079</td>
      <td>415</td>
      <td>NONE</td>
      <td>6</td>
      <td>80.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2565</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>565</td>
      <td>shap_interaction_values for neural network models</td>
      <td>2022-10-31</td>
      <td>2022-10-31</td>
      <td>299</td>
      <td>299</td>
      <td>NONE</td>
      <td>1</td>
      <td>82.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1841</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>841</td>
      <td>why SHAP feature dependence does not be aggregated into a mean value with error bar, instead of scatter plot?</td>
      <td>2021-03-28</td>
      <td>2021-03-28</td>
      <td>881</td>
      <td>881</td>
      <td>NONE</td>
      <td>0</td>
      <td>82.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1136</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>136</td>
      <td>Does shap work with multioutput models?</td>
      <td>2020-04-04</td>
      <td>2020-05-11</td>
      <td>1239</td>
      <td>1202</td>
      <td>NONE</td>
      <td>1</td>
      <td>83.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>266</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>66</td>
      <td>save option for summary_plot</td>
      <td>2018-09-22</td>
      <td>2022-05-25</td>
      <td>1799</td>
      <td>458</td>
      <td>NONE</td>
      <td>12</td>
      <td>83.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>584</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a>4</td>
      <td>cannot import name '_validate_lengths'</td>
      <td>2019-05-11</td>
      <td>2019-05-25</td>
      <td>1568</td>
      <td>1554</td>
      <td>NONE</td>
      <td>3</td>
      <td>85.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>823</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>23</td>
      <td>How to send placeholder values in tensorflow to shap's DeepExplainer ?</td>
      <td>2019-09-23</td>
      <td>2021-05-31</td>
      <td>1433</td>
      <td>817</td>
      <td>NONE</td>
      <td>1</td>
      <td>85.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1993</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>993</td>
      <td>Thanks for the great repo, I have question regarding this</td>
      <td>2021-07-13</td>
      <td>2021-07-13</td>
      <td>774</td>
      <td>774</td>
      <td>NONE</td>
      <td>0</td>
      <td>85.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2029</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>029</td>
      <td>Scatter Colour with a Feature Not in the Training Data</td>
      <td>2021-08-09</td>
      <td>2021-08-12</td>
      <td>747</td>
      <td>744</td>
      <td>NONE</td>
      <td>2</td>
      <td>86.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1691</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>691</td>
      <td>Image Explanations Viz disappear after initial render</td>
      <td>2021-01-12</td>
      <td>2021-03-20</td>
      <td>956</td>
      <td>889</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>87.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>443</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>43</td>
      <td>Is timeseries(RNN) analysis possible with shap</td>
      <td>2019-02-12</td>
      <td>2023-05-30</td>
      <td>1655</td>
      <td>88</td>
      <td>NONE</td>
      <td>8</td>
      <td>87.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1236</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>236</td>
      <td>New release with fix for XGBoost 1.1</td>
      <td>2020-05-28</td>
      <td>2020-05-28</td>
      <td>1185</td>
      <td>1185</td>
      <td>NONE</td>
      <td>0</td>
      <td>89.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2432</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>432</td>
      <td>How to specify the pos_label for the classifier models</td>
      <td>2022-06-20</td>
      <td>2022-06-20</td>
      <td>431</td>
      <td>431</td>
      <td>NONE</td>
      <td>0</td>
      <td>89.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1690</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>690</td>
      <td>Change colour in force plot if Matplotlib = True</td>
      <td>2021-01-12</td>
      <td>2022-10-05</td>
      <td>956</td>
      <td>325</td>
      <td>NONE</td>
      <td>4</td>
      <td>91.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>243</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>43</td>
      <td>missing njobs parameter in TreeExplainer function</td>
      <td>2018-08-28</td>
      <td>2018-08-29</td>
      <td>1824</td>
      <td>1823</td>
      <td>NONE</td>
      <td>1</td>
      <td>95.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2017</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>017</td>
      <td>What's the difference between \"explainer.shap_values(X)\" and \"explainer(</td>
      <td>2021-07-31</td>
      <td>2021-08-11</td>
      <td>756</td>
      <td>745</td>
      <td>NONE</td>
      <td>1</td>
      <td>99.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>663</td>
      <td><a href="https://github.com/shap/shap/issues/67">67</a>3</td>
      <td>Question on Shap for CNN</td>
      <td>2019-06-25</td>
      <td>2019-06-26</td>
      <td>1523</td>
      <td>1522</td>
      <td>NONE</td>
      <td>1</td>
      <td>101.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>496</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>96</td>
      <td>SHAP feature importance for ranking models</td>
      <td>2019-03-17</td>
      <td>2019-05-27</td>
      <td>1622</td>
      <td>1552</td>
      <td>NONE</td>
      <td>1</td>
      <td>102.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1861</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>861</td>
      <td>how increase photo of ImageNet in shape datasets</td>
      <td>2021-04-09</td>
      <td>2021-04-09</td>
      <td>869</td>
      <td>869</td>
      <td>NONE</td>
      <td>0</td>
      <td>103.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2506</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>506</td>
      <td>How to deploy shap on C + +</td>
      <td>2022-09-13</td>
      <td>2022-09-13</td>
      <td>347</td>
      <td>347</td>
      <td>NONE</td>
      <td>0</td>
      <td>106.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>705</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>05</td>
      <td>TEXT output of SHAP visualization</td>
      <td>2019-07-18</td>
      <td>2019-07-18</td>
      <td>1499</td>
      <td>1499</td>
      <td>NONE</td>
      <td>0</td>
      <td>106.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>210</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>10</td>
      <td>Additional supported ops</td>
      <td>2018-08-10</td>
      <td>2018-08-18</td>
      <td>1842</td>
      <td>1834</td>
      <td>NONE</td>
      <td>3</td>
      <td>107.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>326</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>26</td>
      <td>support for QuantileEstimator for sklearn gradient boosting regressor</td>
      <td>2018-11-13</td>
      <td>2021-01-13</td>
      <td>1746</td>
      <td>955</td>
      <td>NONE</td>
      <td>2</td>
      <td>107.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>838</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>38</td>
      <td>Siamsese Network</td>
      <td>2019-10-03</td>
      <td>2019-10-09</td>
      <td>1423</td>
      <td>1417</td>
      <td>NONE</td>
      <td>1</td>
      <td>111.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2278</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>278</td>
      <td>Shap Values for H2O Model</td>
      <td>2022-03-11</td>
      <td>2022-03-11</td>
      <td>533</td>
      <td>533</td>
      <td>NONE</td>
      <td>0</td>
      <td>111.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1641</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>641</td>
      <td>Variable names do not come up in the plot</td>
      <td>2020-12-21</td>
      <td>2020-12-21</td>
      <td>978</td>
      <td>978</td>
      <td>NONE</td>
      <td>1</td>
      <td>112.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>219</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>19</td>
      <td>3D convolutional nueral networks</td>
      <td>2018-08-14</td>
      <td>2018-08-29</td>
      <td>1837</td>
      <td>1823</td>
      <td>NONE</td>
      <td>5</td>
      <td>112.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2077</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>077</td>
      <td>Why is there such an tensorflow-error</td>
      <td>2021-09-19</td>
      <td>2021-09-19</td>
      <td>706</td>
      <td>706</td>
      <td>NONE</td>
      <td>0</td>
      <td>113.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2101</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>101</td>
      <td>Super Learning with SHAP</td>
      <td>2021-10-10</td>
      <td>2021-10-10</td>
      <td>685</td>
      <td>685</td>
      <td>NONE</td>
      <td>0</td>
      <td>113.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>977</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>77</td>
      <td>Labels are not rendered properly</td>
      <td>2020-01-02</td>
      <td>2020-01-07</td>
      <td>1332</td>
      <td>1327</td>
      <td>NONE</td>
      <td>10</td>
      <td>114.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>427</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>27</td>
      <td>shap for stacked LSTM</td>
      <td>2019-02-05</td>
      <td>2019-02-11</td>
      <td>1663</td>
      <td>1657</td>
      <td>NONE</td>
      <td>4</td>
      <td>114.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>279</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>79</td>
      <td>tensorflow estimator support</td>
      <td>2018-10-08</td>
      <td>2021-11-27</td>
      <td>1783</td>
      <td>637</td>
      <td>NONE</td>
      <td>20</td>
      <td>116.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>294</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>94</td>
      <td>save explainer?</td>
      <td>2018-10-23</td>
      <td>2022-11-17</td>
      <td>1768</td>
      <td>282</td>
      <td>NONE</td>
      <td>46</td>
      <td>117.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>782</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>82</td>
      <td>Specify colors manually in a summaryplot for each class</td>
      <td>2019-08-30</td>
      <td>2023-08-16</td>
      <td>1457</td>
      <td>10</td>
      <td>NONE</td>
      <td>3</td>
      <td>122.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>908</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>08</td>
      <td>Shap and GBM</td>
      <td>2019-11-22</td>
      <td>2019-11-22</td>
      <td>1372</td>
      <td>1372</td>
      <td>NONE</td>
      <td>2</td>
      <td>123.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2225</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>225</td>
      <td>Enabling the matplotlib \"ax\" keyword argument to plot functio</td>
      <td>2022-01-25</td>
      <td>2023-08-26</td>
      <td>578</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>128.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1475</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>475</td>
      <td>Tensorflow1.14 .pb model supported?</td>
      <td>2020-09-28</td>
      <td>2020-09-28</td>
      <td>1062</td>
      <td>1062</td>
      <td>NONE</td>
      <td>0</td>
      <td>129.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>572</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>2</td>
      <td>_estimate_transforms in Linear Explainer</td>
      <td>2019-05-02</td>
      <td>2021-02-05</td>
      <td>1577</td>
      <td>931</td>
      <td>NONE</td>
      <td>1</td>
      <td>130.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>945</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>45</td>
      <td>shap for imbalanced data</td>
      <td>2019-12-12</td>
      <td>2022-01-04</td>
      <td>1353</td>
      <td>599</td>
      <td>NONE</td>
      <td>3</td>
      <td>131.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>407</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>07</td>
      <td>force_plot matplotlib=True -&gt; values are not rounded</td>
      <td>2019-01-24</td>
      <td>2022-09-19</td>
      <td>1675</td>
      <td>341</td>
      <td>NONE</td>
      <td>11</td>
      <td>132.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1733</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>733</td>
      <td>How do I install shap without GPU support, i.e. CPU only?</td>
      <td>2021-01-25</td>
      <td>2021-09-10</td>
      <td>943</td>
      <td>715</td>
      <td>NONE</td>
      <td>12</td>
      <td>132.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>170</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>70</td>
      <td>TreeExplainer's shap_values do not contains intercept value, it is not consistent with the doc's description</td>
      <td>2018-07-22</td>
      <td>2018-07-22</td>
      <td>1861</td>
      <td>1861</td>
      <td>NONE</td>
      <td>2</td>
      <td>133.0</td>
      <td>No</td>
      <td>Issue with 'TreeExplainer' in 'shap_model', needs troubleshooting.\n</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1821</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>821</td>
      <td>MemoryError: Unable to allocate 184. GiB for an array with shape (24759190848,) and data type float64</td>
      <td>2021-03-15</td>
      <td>2021-03-17</td>
      <td>894</td>
      <td>892</td>
      <td>NONE</td>
      <td>3</td>
      <td>134.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1450</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>450</td>
      <td>type hints?</td>
      <td>2020-09-20</td>
      <td>2020-09-20</td>
      <td>1069</td>
      <td>1069</td>
      <td>NONE</td>
      <td>0</td>
      <td>136.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>834</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>34</td>
      <td>Any thoughts to speeding up Kernel Explainer?</td>
      <td>2019-09-26</td>
      <td>2019-10-12</td>
      <td>1429</td>
      <td>1414</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>136.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1948</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>948</td>
      <td>SHAP with object detection models</td>
      <td>2021-06-09</td>
      <td>2021-09-03</td>
      <td>808</td>
      <td>721</td>
      <td>NONE</td>
      <td>1</td>
      <td>136.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>934</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>34</td>
      <td>DeepExplainer Shap_values should have an higher verbosity</td>
      <td>2019-12-09</td>
      <td>2022-01-12</td>
      <td>1356</td>
      <td>591</td>
      <td>NONE</td>
      <td>6</td>
      <td>136.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1596</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>596</td>
      <td>Can xgboost model of spark training be analyzed with shap</td>
      <td>2020-12-07</td>
      <td>2023-06-06</td>
      <td>992</td>
      <td>81</td>
      <td>NONE</td>
      <td>1</td>
      <td>137.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>739</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>39</td>
      <td>Partition Explainer for Deep Learning Models</td>
      <td>2019-08-10</td>
      <td>2019-08-10</td>
      <td>1477</td>
      <td>1477</td>
      <td>NONE</td>
      <td>0</td>
      <td>138.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>137</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>37</td>
      <td>Support for csr sparse matrices.</td>
      <td>2018-06-30</td>
      <td>2019-08-15</td>
      <td>1883</td>
      <td>1472</td>
      <td>NONE</td>
      <td>19</td>
      <td>140.0</td>
      <td>No</td>
      <td>"Support requested for cs in Ker series, current version issues."\n</td>
      <td>"Shape Support"</td>
      <td>enhancement</td>
    </tr>
    <tr>
      <td>246</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>46</td>
      <td>shap plots customization</td>
      <td>2018-08-31</td>
      <td>2021-09-28</td>
      <td>1821</td>
      <td>697</td>
      <td>NONE</td>
      <td>5</td>
      <td>140.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2483</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>483</td>
      <td>DeepExplainer Pytorch nn.Modul LSTM</td>
      <td>2022-08-20</td>
      <td>2023-03-10</td>
      <td>371</td>
      <td>169</td>
      <td>NONE</td>
      <td>1</td>
      <td>144.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2028</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>028</td>
      <td>where can I download shap documentation as pdf?</td>
      <td>2021-08-09</td>
      <td>2021-08-09</td>
      <td>747</td>
      <td>747</td>
      <td>NONE</td>
      <td>0</td>
      <td>145.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1453</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>453</td>
      <td>Categorical data with permutation /exact explainer</td>
      <td>2020-09-21</td>
      <td>2020-09-21</td>
      <td>1069</td>
      <td>1069</td>
      <td>NONE</td>
      <td>0</td>
      <td>146.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1316</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>316</td>
      <td>Dark background force plot</td>
      <td>2020-07-17</td>
      <td>2023-08-22</td>
      <td>1134</td>
      <td>4</td>
      <td>NONE</td>
      <td>1</td>
      <td>147.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>510</td>
      <td><a href="https://github.com/shap/shap/issues/52">52</a>0</td>
      <td>Graph Convolutional Networks</td>
      <td>2019-03-26</td>
      <td>2019-09-15</td>
      <td>1614</td>
      <td>1441</td>
      <td>NONE</td>
      <td>2</td>
      <td>147.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1283</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>283</td>
      <td>AssertionError: &lt;class &gt; is not currently a supported model type!</td>
      <td>2020-06-23</td>
      <td>2020-08-25</td>
      <td>1159</td>
      <td>1095</td>
      <td>NONE</td>
      <td>1</td>
      <td>148.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1968</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>968</td>
      <td>NHANES I survival data</td>
      <td>2021-06-24</td>
      <td>2021-10-01</td>
      <td>793</td>
      <td>694</td>
      <td>NONE</td>
      <td>1</td>
      <td>148.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1570</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>570</td>
      <td>readthedocs \"Edit On GitHub\" links return a 404 pa</td>
      <td>2020-11-19</td>
      <td>2023-07-27</td>
      <td>1009</td>
      <td>30</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>148.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1637</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>637</td>
      <td>Visualization - Consistent Styling</td>
      <td>2020-12-18</td>
      <td>2020-12-18</td>
      <td>980</td>
      <td>980</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>149.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>153</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>53</td>
      <td>deep lift / deep shap vs deep taylor</td>
      <td>2018-07-12</td>
      <td>2018-10-03</td>
      <td>1871</td>
      <td>1788</td>
      <td>NONE</td>
      <td>3</td>
      <td>150.0</td>
      <td>No</td>
      <td>Issue: Inquiry about deep lift / deep explainer method availability.</td>
      <td>"Shape Issue"</td>
      <td>enhancement</td>
    </tr>
    <tr>
      <td>1515</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>515</td>
      <td>link='logit' option for summary_plot</td>
      <td>2020-10-19</td>
      <td>2021-04-27</td>
      <td>1041</td>
      <td>851</td>
      <td>NONE</td>
      <td>1</td>
      <td>152.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>582</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a>2</td>
      <td>Given a shap value for an interaction, how do i trace back the actual record?</td>
      <td>2019-05-10</td>
      <td>2023-08-26</td>
      <td>1569</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>152.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2469</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>469</td>
      <td>Is it possible to rename the 'base value' label on an individual force plot?</td>
      <td>2022-08-02</td>
      <td>2022-08-02</td>
      <td>388</td>
      <td>388</td>
      <td>NONE</td>
      <td>0</td>
      <td>153.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>816</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>16</td>
      <td>Shap API /</td>
      <td>2019-09-21</td>
      <td>2019-09-22</td>
      <td>1434</td>
      <td>1434</td>
      <td>NONE</td>
      <td>1</td>
      <td>154.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>376</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>76</td>
      <td>saving force_plot to html</td>
      <td>2019-01-03</td>
      <td>2020-03-16</td>
      <td>1696</td>
      <td>1258</td>
      <td>NONE</td>
      <td>4</td>
      <td>158.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1672</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>672</td>
      <td>summary_plot legend move</td>
      <td>2021-01-04</td>
      <td>2022-02-07</td>
      <td>964</td>
      <td>565</td>
      <td>NONE</td>
      <td>1</td>
      <td>165.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>370</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>70</td>
      <td>How to get the contribution of each features with a datashape (35087, 15, 103)?</td>
      <td>2018-12-29</td>
      <td>2018-12-30</td>
      <td>1701</td>
      <td>1699</td>
      <td>NONE</td>
      <td>3</td>
      <td>165.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1673</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>673</td>
      <td>want to remove base value from force_plot</td>
      <td>2021-01-04</td>
      <td>2021-01-04</td>
      <td>964</td>
      <td>964</td>
      <td>NONE</td>
      <td>0</td>
      <td>166.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1722</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>722</td>
      <td>Can we explain BERT models using this package?</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>947</td>
      <td>947</td>
      <td>NONE</td>
      <td>0</td>
      <td>167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1558</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>558</td>
      <td>Reference for PartitionExplainer/ Owen values</td>
      <td>2020-11-14</td>
      <td>2020-11-14</td>
      <td>1015</td>
      <td>1015</td>
      <td>NONE</td>
      <td>0</td>
      <td>167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1957</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>957</td>
      <td>In a deep explainer classification problem, the background takes equal samples from all the classes?</td>
      <td>2021-06-15</td>
      <td>2021-06-15</td>
      <td>802</td>
      <td>802</td>
      <td>NONE</td>
      <td>0</td>
      <td>167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1270</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>270</td>
      <td>Request to support serialized examples as input for deep and gradient explainers.</td>
      <td>2020-06-16</td>
      <td>2020-06-16</td>
      <td>1166</td>
      <td>1165</td>
      <td>NONE</td>
      <td>0</td>
      <td>167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1381</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>381</td>
      <td>[KDD question] Shap values vs Sobol indices?</td>
      <td>2020-08-26</td>
      <td>2022-05-26</td>
      <td>1095</td>
      <td>456</td>
      <td>NONE</td>
      <td>2</td>
      <td>167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>697</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>7</td>
      <td>About the backward function of crossentropy loss in deep SHAP</td>
      <td>2019-07-11</td>
      <td>2019-07-11</td>
      <td>1507</td>
      <td>1507</td>
      <td>NONE</td>
      <td>0</td>
      <td>168.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2423</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>423</td>
      <td>shap value for multiclass export as pandas or list</td>
      <td>2022-06-13</td>
      <td>2022-12-08</td>
      <td>439</td>
      <td>261</td>
      <td>NONE</td>
      <td>2</td>
      <td>168.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>861</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>61</td>
      <td>Is there a way to change the behavior of the tree explainer to enforce float32 on the explanations?</td>
      <td>2019-10-22</td>
      <td>2019-10-22</td>
      <td>1403</td>
      <td>1403</td>
      <td>NONE</td>
      <td>0</td>
      <td>169.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2267</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>267</td>
      <td>Deep explainer when the model output is logit</td>
      <td>2022-03-01</td>
      <td>2022-03-01</td>
      <td>542</td>
      <td>542</td>
      <td>NONE</td>
      <td>0</td>
      <td>170.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1017</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>017</td>
      <td>which method is best for subsampling?</td>
      <td>2020-01-28</td>
      <td>2020-02-13</td>
      <td>1306</td>
      <td>1290</td>
      <td>NONE</td>
      <td>1</td>
      <td>171.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2037</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>037</td>
      <td>A regression based on multiple Xgboost models</td>
      <td>2021-08-12</td>
      <td>2021-08-12</td>
      <td>744</td>
      <td>744</td>
      <td>NONE</td>
      <td>0</td>
      <td>172.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2517</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>517</td>
      <td>shap.plots.bar without absolute mean</td>
      <td>2022-09-19</td>
      <td>2022-09-19</td>
      <td>341</td>
      <td>341</td>
      <td>NONE</td>
      <td>0</td>
      <td>172.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2491</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>491</td>
      <td>Can model loss be monitored in KernelExplainer like Tree explainer?</td>
      <td>2022-08-28</td>
      <td>2022-08-28</td>
      <td>363</td>
      <td>363</td>
      <td>NONE</td>
      <td>0</td>
      <td>172.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2007</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>007</td>
      <td>Adaptive online KernelExplainer ?</td>
      <td>2021-07-20</td>
      <td>2021-07-20</td>
      <td>766</td>
      <td>766</td>
      <td>NONE</td>
      <td>0</td>
      <td>172.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>533</td>
      <td><a href="https://github.com/shap/shap/issues/54">54</a>3</td>
      <td>How to change the width of force_plot?</td>
      <td>2019-04-05</td>
      <td>2019-04-05</td>
      <td>1604</td>
      <td>1604</td>
      <td>NONE</td>
      <td>1</td>
      <td>174.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1445</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>445</td>
      <td>Shap summary plot</td>
      <td>2020-09-19</td>
      <td>2020-09-19</td>
      <td>1071</td>
      <td>1071</td>
      <td>NONE</td>
      <td>0</td>
      <td>174.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2274</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>274</td>
      <td>future of shap</td>
      <td>2022-03-08</td>
      <td>2022-08-09</td>
      <td>536</td>
      <td>382</td>
      <td>NONE</td>
      <td>2</td>
      <td>175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2034</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>034</td>
      <td>Prediction from Light GBM not matching with that in Force Plot</td>
      <td>2021-08-11</td>
      <td>2021-12-11</td>
      <td>745</td>
      <td>623</td>
      <td>NONE</td>
      <td>3</td>
      <td>175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1801</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>801</td>
      <td>GPUTreeExplainer failed when data contains string categories</td>
      <td>2021-03-04</td>
      <td>2021-03-04</td>
      <td>905</td>
      <td>905</td>
      <td>NONE</td>
      <td>0</td>
      <td>175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2044</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>044</td>
      <td>Reference for permutation explainer</td>
      <td>2021-08-18</td>
      <td>2023-02-01</td>
      <td>738</td>
      <td>205</td>
      <td>CONTRIBUTOR</td>
      <td>2</td>
      <td>175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1523</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>523</td>
      <td>What is the best approach to use shap to explain a time series model from gluonts.</td>
      <td>2020-10-25</td>
      <td>2021-01-13</td>
      <td>1035</td>
      <td>955</td>
      <td>NONE</td>
      <td>1</td>
      <td>181.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2421</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>421</td>
      <td>Information about Partition Explainer</td>
      <td>2022-06-09</td>
      <td>2022-06-09</td>
      <td>443</td>
      <td>443</td>
      <td>NONE</td>
      <td>0</td>
      <td>183.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1180</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>180</td>
      <td>How does Shap deal with categorical variables in LGBM?</td>
      <td>2020-04-27</td>
      <td>2020-04-27</td>
      <td>1216</td>
      <td>1216</td>
      <td>NONE</td>
      <td>0</td>
      <td>184.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2567</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>567</td>
      <td>Does Deepshap support Multi-channel inputs for Keras models?</td>
      <td>2022-11-02</td>
      <td>2023-03-07</td>
      <td>297</td>
      <td>172</td>
      <td>NONE</td>
      <td>1</td>
      <td>184.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>994</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>94</td>
      <td>how to larger the text size of feature name  in a shap force plot</td>
      <td>2020-01-13</td>
      <td>2020-05-22</td>
      <td>1321</td>
      <td>1191</td>
      <td>NONE</td>
      <td>3</td>
      <td>185.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2412</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>412</td>
      <td>How to apply shap model to deepforest model?</td>
      <td>2022-06-06</td>
      <td>2022-06-06</td>
      <td>446</td>
      <td>446</td>
      <td>NONE</td>
      <td>0</td>
      <td>185.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1946</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>946</td>
      <td>README.md</td>
      <td>2021-06-07</td>
      <td>2021-06-07</td>
      <td>810</td>
      <td>810</td>
      <td>NONE</td>
      <td>0</td>
      <td>187.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2080</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>080</td>
      <td>AttributeError: module 'tensorflow.python.eager.backprop' has no attribute '_record_gradient'</td>
      <td>2021-09-20</td>
      <td>2023-02-17</td>
      <td>705</td>
      <td>190</td>
      <td>NONE</td>
      <td>17</td>
      <td>187.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>733</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>33</td>
      <td>May I ask what is problem in my code?</td>
      <td>2019-08-07</td>
      <td>2020-04-01</td>
      <td>1479</td>
      <td>1242</td>
      <td>NONE</td>
      <td>6</td>
      <td>188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1618</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>618</td>
      <td>How to save generated plots on disk ?</td>
      <td>2020-12-14</td>
      <td>2023-04-06</td>
      <td>985</td>
      <td>141</td>
      <td>NONE</td>
      <td>2</td>
      <td>188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1572</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>572</td>
      <td>Plot beeswarm always gives all features</td>
      <td>2020-11-20</td>
      <td>2020-11-20</td>
      <td>1009</td>
      <td>1009</td>
      <td>NONE</td>
      <td>1</td>
      <td>188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1792</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>792</td>
      <td>Benchmark link returns 404 error</td>
      <td>2021-03-01</td>
      <td>2021-03-01</td>
      <td>908</td>
      <td>908</td>
      <td>NONE</td>
      <td>0</td>
      <td>188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>709</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>09</td>
      <td>Capsule Neural Networks</td>
      <td>2019-07-22</td>
      <td>2019-08-18</td>
      <td>1496</td>
      <td>1469</td>
      <td>NONE</td>
      <td>2</td>
      <td>188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>835</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>35</td>
      <td>How would multi-variate transformation change the SHAP values?</td>
      <td>2019-09-27</td>
      <td>2019-10-09</td>
      <td>1429</td>
      <td>1417</td>
      <td>NONE</td>
      <td>1</td>
      <td>189.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2093</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>093</td>
      <td>Implementation for Multivariate Time Series Data</td>
      <td>2021-10-04</td>
      <td>2022-03-10</td>
      <td>691</td>
      <td>534</td>
      <td>NONE</td>
      <td>5</td>
      <td>191.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2040</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>040</td>
      <td>[Feature Request] Model interpretability for flax</td>
      <td>2021-08-16</td>
      <td>2023-08-26</td>
      <td>739</td>
      <td>0</td>
      <td>NONE</td>
      <td>2</td>
      <td>191.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2389</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>389</td>
      <td>TreeExplainer segmentation fault</td>
      <td>2022-05-17</td>
      <td>2022-05-17</td>
      <td>466</td>
      <td>466</td>
      <td>NONE</td>
      <td>0</td>
      <td>192.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2203</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>203</td>
      <td>transformers.pipeline dont have task of text_classification</td>
      <td>2021-12-29</td>
      <td>2021-12-29</td>
      <td>605</td>
      <td>605</td>
      <td>NONE</td>
      <td>0</td>
      <td>193.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1064</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>064</td>
      <td>When can we use Sampling explainer?</td>
      <td>2020-02-25</td>
      <td>2020-02-27</td>
      <td>1278</td>
      <td>1276</td>
      <td>NONE</td>
      <td>4</td>
      <td>193.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>212</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>12</td>
      <td>Shap for RNN models</td>
      <td>2018-08-12</td>
      <td>2023-03-17</td>
      <td>1840</td>
      <td>162</td>
      <td>NONE</td>
      <td>33</td>
      <td>195.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1229</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>229</td>
      <td>Does this package support the tf1.0 native framework(not keras)</td>
      <td>2020-05-26</td>
      <td>2020-05-26</td>
      <td>1187</td>
      <td>1187</td>
      <td>NONE</td>
      <td>0</td>
      <td>195.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1281</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>281</td>
      <td>Warning: unrecognized nn.Module</td>
      <td>2020-06-22</td>
      <td>2020-06-22</td>
      <td>1160</td>
      <td>1160</td>
      <td>NONE</td>
      <td>1</td>
      <td>196.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>688</td>
      <td><a href="https://github.com/shap/shap/issues/689">689</a></td>
      <td>Questions: shap interaction values for Explainers other than TreeExplainer</td>
      <td>2019-07-09</td>
      <td>2019-07-09</td>
      <td>1509</td>
      <td>1509</td>
      <td>NONE</td>
      <td>0</td>
      <td>196.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2027</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>027</td>
      <td>Disable logging in shap</td>
      <td>2021-08-08</td>
      <td>2023-06-27</td>
      <td>747</td>
      <td>60</td>
      <td>CONTRIBUTOR</td>
      <td>2</td>
      <td>196.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2468</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>468</td>
      <td>Metrics for Interpretability</td>
      <td>2022-08-02</td>
      <td>2022-08-13</td>
      <td>389</td>
      <td>378</td>
      <td>NONE</td>
      <td>1</td>
      <td>197.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1800</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>800</td>
      <td>Additivity check failed in GPUTreeExplainer but works fine in TreeExplainer with Light GBM</td>
      <td>2021-03-04</td>
      <td>2021-03-04</td>
      <td>905</td>
      <td>905</td>
      <td>NONE</td>
      <td>0</td>
      <td>197.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>957</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>57</td>
      <td>Can TreeExplainer be used with tf.estimator.BoostedTreesClassifier?</td>
      <td>2019-12-17</td>
      <td>2022-05-06</td>
      <td>1348</td>
      <td>477</td>
      <td>NONE</td>
      <td>6</td>
      <td>199.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>37</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>7</td>
      <td>A Spark version in plan?</td>
      <td>2018-03-01</td>
      <td>2023-08-16</td>
      <td>2004</td>
      <td>10</td>
      <td>NONE</td>
      <td>46</td>
      <td>199.0</td>
      <td>No</td>
      <td>Issue regarding "Spark version" mentioned in series titled 'title'.</td>
      <td>"Shape Issue"</td>
      <td>good first issue</td>
    </tr>
    <tr>
      <td>1638</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>638</td>
      <td>Can we use SHAP for the Neural Network (for regression) models ?</td>
      <td>2020-12-19</td>
      <td>2020-12-21</td>
      <td>980</td>
      <td>978</td>
      <td>NONE</td>
      <td>1</td>
      <td>199.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2128</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>128</td>
      <td>Some inconveniences found during use</td>
      <td>2021-11-05</td>
      <td>2021-11-05</td>
      <td>659</td>
      <td>659</td>
      <td>NONE</td>
      <td>0</td>
      <td>200.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>285</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>85</td>
      <td>Use SHAP to rank features from a Keras Sequential model</td>
      <td>2018-10-15</td>
      <td>2018-10-19</td>
      <td>1775</td>
      <td>1772</td>
      <td>NONE</td>
      <td>4</td>
      <td>200.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1396</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>396</td>
      <td>C++ version of shap</td>
      <td>2020-08-30</td>
      <td>2022-08-09</td>
      <td>1090</td>
      <td>382</td>
      <td>NONE</td>
      <td>1</td>
      <td>202.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2238</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>238</td>
      <td>Dose not Support Sklearn gaussian process</td>
      <td>2022-02-08</td>
      <td>2022-02-08</td>
      <td>564</td>
      <td>564</td>
      <td>NONE</td>
      <td>0</td>
      <td>202.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1663</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>663</td>
      <td>When SHAP interprets RNN / LSTM model, will \"sequence\" affect the calculation of Shapley valu</td>
      <td>2020-12-27</td>
      <td>2020-12-27</td>
      <td>972</td>
      <td>972</td>
      <td>NONE</td>
      <td>0</td>
      <td>204.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1845</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>845</td>
      <td>how to calculate shap value for different classes in multiclass problem?</td>
      <td>2021-03-30</td>
      <td>2021-03-30</td>
      <td>879</td>
      <td>879</td>
      <td>NONE</td>
      <td>0</td>
      <td>207.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1008</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>008</td>
      <td>Additivity of multiclass examples</td>
      <td>2020-01-21</td>
      <td>2020-02-20</td>
      <td>1312</td>
      <td>1283</td>
      <td>NONE</td>
      <td>3</td>
      <td>208.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2730</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>730</td>
      <td>custom base values for tree explainer</td>
      <td>2023-05-25</td>
      <td>2023-05-25</td>
      <td>93</td>
      <td>93</td>
      <td>NONE</td>
      <td>0</td>
      <td>208.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1979</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>979</td>
      <td>AttributeError: module 'shap' has no attribute 'TreeExplainer'</td>
      <td>2021-07-02</td>
      <td>2021-07-02</td>
      <td>785</td>
      <td>785</td>
      <td>NONE</td>
      <td>0</td>
      <td>208.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>414</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>14</td>
      <td>multi-threading possible for summary_plot?</td>
      <td>2019-01-25</td>
      <td>2019-02-05</td>
      <td>1673</td>
      <td>1663</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>209.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1521</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>521</td>
      <td>Which version of tensorflow and keras should I use for Keras LSTM for IMDB Sentiment Classification notebook?</td>
      <td>2020-10-23</td>
      <td>2020-10-26</td>
      <td>1037</td>
      <td>1034</td>
      <td>NONE</td>
      <td>1</td>
      <td>210.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>45</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>5</td>
      <td>Interaction contribution in lightgbm</td>
      <td>2018-03-16</td>
      <td>2022-03-15</td>
      <td>1989</td>
      <td>529</td>
      <td>NONE</td>
      <td>5</td>
      <td>210.0</td>
      <td>No</td>
      <td>Issue: User encountering problems with interaction in specific series shape.</td>
      <td>"Issue Shape"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>606</td>
      <td><a href="https://github.com/shap/shap/issues/61">61</a>6</td>
      <td>Example for embedding_plot</td>
      <td>2019-05-24</td>
      <td>2019-05-24</td>
      <td>1555</td>
      <td>1555</td>
      <td>NONE</td>
      <td>0</td>
      <td>211.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1126</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>126</td>
      <td>Does SHAP DL explainer works for object detection frameworks like Mask R-CNN?</td>
      <td>2020-04-01</td>
      <td>2020-07-09</td>
      <td>1242</td>
      <td>1143</td>
      <td>NONE</td>
      <td>1</td>
      <td>211.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1647</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>647</td>
      <td>Model Serialization - Save Based on type of model</td>
      <td>2020-12-21</td>
      <td>2020-12-21</td>
      <td>977</td>
      <td>977</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>213.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2509</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>509</td>
      <td>[Documentation Typo] Math behind LinearExplainer with correlation feature perturbation</td>
      <td>2022-09-14</td>
      <td>2022-09-14</td>
      <td>346</td>
      <td>346</td>
      <td>NONE</td>
      <td>0</td>
      <td>213.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2199</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>199</td>
      <td>shap.plots.bar doesn't have have the option to change colors</td>
      <td>2021-12-24</td>
      <td>2021-12-26</td>
      <td>609</td>
      <td>607</td>
      <td>NONE</td>
      <td>0</td>
      <td>214.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2433</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>433</td>
      <td>spicy 1.8.1 breaks hclust in _clustering.py</td>
      <td>2022-06-21</td>
      <td>2022-06-21</td>
      <td>430</td>
      <td>430</td>
      <td>NONE</td>
      <td>0</td>
      <td>215.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1227</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>227</td>
      <td>SHAP value too small</td>
      <td>2020-05-25</td>
      <td>2021-07-23</td>
      <td>1188</td>
      <td>763</td>
      <td>NONE</td>
      <td>1</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1843</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>843</td>
      <td>[FEATURE] Support for Asymmetric Shapley Values</td>
      <td>2021-03-30</td>
      <td>2021-06-25</td>
      <td>879</td>
      <td>792</td>
      <td>NONE</td>
      <td>1</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1220</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>220</td>
      <td>When I use GradientExplainer, the shap value returns nan</td>
      <td>2020-05-21</td>
      <td>2020-05-21</td>
      <td>1192</td>
      <td>1192</td>
      <td>NONE</td>
      <td>0</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1090</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>090</td>
      <td>shap.LinearExplainer has no attribute model_output</td>
      <td>2020-03-08</td>
      <td>2020-03-08</td>
      <td>1266</td>
      <td>1266</td>
      <td>NONE</td>
      <td>0</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1201</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>201</td>
      <td>Summary Plot Object</td>
      <td>2020-05-08</td>
      <td>2020-05-08</td>
      <td>1205</td>
      <td>1205</td>
      <td>NONE</td>
      <td>0</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2519</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>519</td>
      <td>Error with simple MLP: 'tuple' object has no attribute 'device'</td>
      <td>2022-09-19</td>
      <td>2022-09-19</td>
      <td>341</td>
      <td>341</td>
      <td>NONE</td>
      <td>0</td>
      <td>217.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2663</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>663</td>
      <td>Can we calculate Shapley value of c if c = {a, b} is a super feature as a set of features?</td>
      <td>2023-02-17</td>
      <td>2023-02-17</td>
      <td>190</td>
      <td>190</td>
      <td>NONE</td>
      <td>0</td>
      <td>218.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1242</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>242</td>
      <td>How to save the image shown by shap?</td>
      <td>2020-06-01</td>
      <td>2020-09-29</td>
      <td>1181</td>
      <td>1061</td>
      <td>NONE</td>
      <td>6</td>
      <td>218.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1079</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>079</td>
      <td>No output from shap.force_plot()</td>
      <td>2020-03-02</td>
      <td>2020-03-03</td>
      <td>1271</td>
      <td>1271</td>
      <td>NONE</td>
      <td>2</td>
      <td>218.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2010</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>010</td>
      <td>SHAP not working with BaggingRegressor model</td>
      <td>2021-07-23</td>
      <td>2021-07-23</td>
      <td>763</td>
      <td>763</td>
      <td>NONE</td>
      <td>0</td>
      <td>219.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2202</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>202</td>
      <td>shap.summary_plot(title)</td>
      <td>2021-12-29</td>
      <td>2022-04-12</td>
      <td>605</td>
      <td>501</td>
      <td>NONE</td>
      <td>1</td>
      <td>219.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1633</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>633</td>
      <td>SHAP compatibility with Attention based LSTM models?</td>
      <td>2020-12-17</td>
      <td>2020-12-17</td>
      <td>981</td>
      <td>981</td>
      <td>NONE</td>
      <td>0</td>
      <td>221.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2209</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>209</td>
      <td>code for Supplementary Figure 5</td>
      <td>2022-01-07</td>
      <td>2022-01-08</td>
      <td>596</td>
      <td>595</td>
      <td>NONE</td>
      <td>1</td>
      <td>224.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1497</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>497</td>
      <td>shap.plots.heatmap has not parameters to feature names and</td>
      <td>2020-10-09</td>
      <td>2020-10-09</td>
      <td>1051</td>
      <td>1051</td>
      <td>NONE</td>
      <td>0</td>
      <td>224.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>55</td>
      <td><a href="https://github.com/shap/shap/issues/56">56</a></td>
      <td>Agnostic explanation without the model</td>
      <td>2018-04-11</td>
      <td>2018-04-12</td>
      <td>1963</td>
      <td>1962</td>
      <td>NONE</td>
      <td>5</td>
      <td>224.0</td>
      <td>No</td>
      <td>User queries about a feature in the code titled "Agnostic expla...".</td>
      <td>"Shape Issue"</td>
      <td>bug</td>
    </tr>
    <tr>
      <td>682</td>
      <td><a href="https://github.com/shap/shap/issues/683">683</a></td>
      <td>Blacken source code?</td>
      <td>2019-07-08</td>
      <td>2023-08-26</td>
      <td>1510</td>
      <td>0</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>224.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>542</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>2</td>
      <td>Format of shap_values tensor using KernelShap?</td>
      <td>2019-04-10</td>
      <td>2023-08-26</td>
      <td>1599</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>225.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2271</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>271</td>
      <td>how get additive shap values  from waterfall (as array or dataframe)</td>
      <td>2022-03-04</td>
      <td>2022-03-04</td>
      <td>540</td>
      <td>540</td>
      <td>NONE</td>
      <td>0</td>
      <td>225.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2351</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>351</td>
      <td>Modifying probability thresholds</td>
      <td>2022-04-19</td>
      <td>2022-04-19</td>
      <td>494</td>
      <td>494</td>
      <td>NONE</td>
      <td>0</td>
      <td>225.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>842</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>42</td>
      <td>Using SHAP with a PMML</td>
      <td>2019-10-08</td>
      <td>2022-04-20</td>
      <td>1418</td>
      <td>493</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>227.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>512</td>
      <td><a href="https://github.com/shap/shap/issues/52">52</a>2</td>
      <td>Hi! I had same problem with other issue. it is about summary_plot displaying gray plot</td>
      <td>2019-03-26</td>
      <td>2021-08-18</td>
      <td>1614</td>
      <td>738</td>
      <td>NONE</td>
      <td>4</td>
      <td>227.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>610</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a>0</td>
      <td>Broken on TF 2.0</td>
      <td>2019-05-29</td>
      <td>2019-10-22</td>
      <td>1550</td>
      <td>1404</td>
      <td>NONE</td>
      <td>2</td>
      <td>227.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2129</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>129</td>
      <td>Theoretical background to shapley value aggregations</td>
      <td>2021-11-05</td>
      <td>2021-11-05</td>
      <td>659</td>
      <td>659</td>
      <td>NONE</td>
      <td>0</td>
      <td>228.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2106</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>106</td>
      <td>supported tensorflow version</td>
      <td>2021-10-14</td>
      <td>2021-10-14</td>
      <td>681</td>
      <td>681</td>
      <td>NONE</td>
      <td>0</td>
      <td>229.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2099</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>099</td>
      <td>How to adjust the font size of colorbar in scatter function?</td>
      <td>2021-10-08</td>
      <td>2021-12-23</td>
      <td>687</td>
      <td>610</td>
      <td>NONE</td>
      <td>2</td>
      <td>230.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1335</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>335</td>
      <td>Couldn't work with tensorflow .meta graph</td>
      <td>2020-07-30</td>
      <td>2020-07-30</td>
      <td>1122</td>
      <td>1122</td>
      <td>NONE</td>
      <td>0</td>
      <td>230.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2193</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>193</td>
      <td>How to get feature names and it's correspinding shap values, that is used in summary_plot?</td>
      <td>2021-12-19</td>
      <td>2021-12-19</td>
      <td>615</td>
      <td>615</td>
      <td>NONE</td>
      <td>0</td>
      <td>231.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>830</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>30</td>
      <td>Logo-design idea.</td>
      <td>2019-09-25</td>
      <td>2023-02-08</td>
      <td>1431</td>
      <td>198</td>
      <td>NONE</td>
      <td>4</td>
      <td>231.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2588</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>588</td>
      <td>In Force plot, show time instead of index numbers at the top.</td>
      <td>2022-11-18</td>
      <td>2022-11-18</td>
      <td>281</td>
      <td>281</td>
      <td>NONE</td>
      <td>0</td>
      <td>232.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2470</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>470</td>
      <td>Is it possible to change the axis for an individual force plot?</td>
      <td>2022-08-02</td>
      <td>2023-02-21</td>
      <td>388</td>
      <td>186</td>
      <td>NONE</td>
      <td>1</td>
      <td>233.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2559</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>559</td>
      <td>Using profiler for C++ extensions</td>
      <td>2022-10-24</td>
      <td>2022-10-24</td>
      <td>306</td>
      <td>306</td>
      <td>NONE</td>
      <td>0</td>
      <td>233.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1437</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>437</td>
      <td>shap_interaction_values</td>
      <td>2020-09-17</td>
      <td>2022-05-19</td>
      <td>1073</td>
      <td>464</td>
      <td>NONE</td>
      <td>10</td>
      <td>233.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>890</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>90</td>
      <td>SHAP explanation for a multimodal network</td>
      <td>2019-11-08</td>
      <td>2023-07-27</td>
      <td>1386</td>
      <td>30</td>
      <td>NONE</td>
      <td>6</td>
      <td>236.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>875</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>75</td>
      <td>Shap values and ranking depend on Y scaling</td>
      <td>2019-10-30</td>
      <td>2019-10-30</td>
      <td>1396</td>
      <td>1396</td>
      <td>NONE</td>
      <td>2</td>
      <td>237.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2555</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>555</td>
      <td>Hi, I have a problem on summary plot, which didn't like the normal one</td>
      <td>2022-10-18</td>
      <td>2022-10-18</td>
      <td>311</td>
      <td>311</td>
      <td>NONE</td>
      <td>0</td>
      <td>237.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2400</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>400</td>
      <td>shap.plots.waterfall with more decimal numbers</td>
      <td>2022-05-26</td>
      <td>2022-06-19</td>
      <td>456</td>
      <td>433</td>
      <td>NONE</td>
      <td>2</td>
      <td>237.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1400</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>400</td>
      <td>Shap for LSTM - features as timestep</td>
      <td>2020-09-01</td>
      <td>2021-09-21</td>
      <td>1089</td>
      <td>704</td>
      <td>NONE</td>
      <td>4</td>
      <td>239.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>716</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>16</td>
      <td>KernelExplainer does not work with GaussianProcessRegressor from ScikitLearn</td>
      <td>2019-07-25</td>
      <td>2019-07-27</td>
      <td>1493</td>
      <td>1491</td>
      <td>NONE</td>
      <td>1</td>
      <td>240.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2211</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>211</td>
      <td>How to deal with Correlated features in shap</td>
      <td>2022-01-10</td>
      <td>2022-01-10</td>
      <td>593</td>
      <td>593</td>
      <td>NONE</td>
      <td>0</td>
      <td>241.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1355</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>355</td>
      <td>Boolean Feature in shap</td>
      <td>2020-08-11</td>
      <td>2020-08-24</td>
      <td>1110</td>
      <td>1097</td>
      <td>NONE</td>
      <td>1</td>
      <td>241.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2014</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>014</td>
      <td>&lt;class 'tensorflow.python.keras.saving.saved_model.load.Functional'&gt; is not currently a supported model type!</td>
      <td>2021-07-28</td>
      <td>2021-07-28</td>
      <td>759</td>
      <td>759</td>
      <td>NONE</td>
      <td>0</td>
      <td>241.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2348</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>348</td>
      <td>GradientExplainer : Zebra-like red and blue stripes</td>
      <td>2022-04-18</td>
      <td>2022-04-18</td>
      <td>495</td>
      <td>495</td>
      <td>NONE</td>
      <td>0</td>
      <td>242.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1665</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>665</td>
      <td>Why is the shap value so sparse</td>
      <td>2020-12-29</td>
      <td>2020-12-30</td>
      <td>970</td>
      <td>969</td>
      <td>NONE</td>
      <td>2</td>
      <td>242.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>633</td>
      <td><a href="https://github.com/shap/shap/issues/64">64</a>3</td>
      <td>XGB independent tree shap for model loss</td>
      <td>2019-06-07</td>
      <td>2019-06-19</td>
      <td>1541</td>
      <td>1528</td>
      <td>NONE</td>
      <td>1</td>
      <td>243.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>386</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>86</td>
      <td>Keras LSTM for IMDB Sentiment Classification NoneType error</td>
      <td>2019-01-10</td>
      <td>2020-03-30</td>
      <td>1688</td>
      <td>1244</td>
      <td>NONE</td>
      <td>4</td>
      <td>245.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>61</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a></td>
      <td>support custom colors in plots</td>
      <td>2018-04-20</td>
      <td>2023-08-18</td>
      <td>1954</td>
      <td>8</td>
      <td>CONTRIBUTOR</td>
      <td>26</td>
      <td>246.0</td>
      <td>No</td>
      <td>"Support needed for custom red and blue feature."</td>
      <td>"Series Shape"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1004</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>004</td>
      <td>Summary plot type \"compact_dot\" not worki</td>
      <td>2020-01-20</td>
      <td>2020-07-17</td>
      <td>1314</td>
      <td>1135</td>
      <td>NONE</td>
      <td>1</td>
      <td>246.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1324</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>324</td>
      <td>Feature Request (non-issue) - Support for Tensorflow Lite models in DeepExplainer</td>
      <td>2020-07-21</td>
      <td>2021-02-14</td>
      <td>1131</td>
      <td>923</td>
      <td>NONE</td>
      <td>1</td>
      <td>246.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1693</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>693</td>
      <td>Deepexplainer with multiple inputs keras model</td>
      <td>2021-01-12</td>
      <td>2021-01-12</td>
      <td>955</td>
      <td>955</td>
      <td>NONE</td>
      <td>0</td>
      <td>246.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1902</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>902</td>
      <td>SOS!!! Error with Deep explainer...LookupError: gradient registry has no entry for: shap_LeakyRelu</td>
      <td>2021-05-06</td>
      <td>2023-05-25</td>
      <td>841</td>
      <td>93</td>
      <td>NONE</td>
      <td>3</td>
      <td>249.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2114</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>114</td>
      <td>_transformers_pipeline.py - Official Support Request for the Huggingface Zero-Shot Classification Pipeline</td>
      <td>2021-10-25</td>
      <td>2022-07-08</td>
      <td>670</td>
      <td>414</td>
      <td>NONE</td>
      <td>1</td>
      <td>250.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1794</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>794</td>
      <td>Get top n results in image_plot with DeepExplainer</td>
      <td>2021-03-02</td>
      <td>2021-03-02</td>
      <td>907</td>
      <td>907</td>
      <td>NONE</td>
      <td>0</td>
      <td>251.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1098</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>098</td>
      <td>is there an API for a pypmml.model.Model object</td>
      <td>2020-03-13</td>
      <td>2021-02-11</td>
      <td>1261</td>
      <td>926</td>
      <td>NONE</td>
      <td>1</td>
      <td>251.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1311</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>311</td>
      <td>Force plot cut-off for categorical end value</td>
      <td>2020-07-10</td>
      <td>2020-07-10</td>
      <td>1142</td>
      <td>1142</td>
      <td>NONE</td>
      <td>0</td>
      <td>251.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2280</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>280</td>
      <td>Changing max_samples parameter for maskers</td>
      <td>2022-03-14</td>
      <td>2022-03-14</td>
      <td>530</td>
      <td>530</td>
      <td>NONE</td>
      <td>0</td>
      <td>251.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>854</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>54</td>
      <td>Time Series LSTM with SHAP</td>
      <td>2019-10-17</td>
      <td>2019-10-22</td>
      <td>1409</td>
      <td>1404</td>
      <td>NONE</td>
      <td>2</td>
      <td>252.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1602</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>602</td>
      <td>[URGENT] pip install fails on Ubuntu. No files/directories in /tmp/pip-build-JsrgB4/shap/pip-egg-info (from PKG-INFO)</td>
      <td>2020-12-08</td>
      <td>2020-12-11</td>
      <td>990</td>
      <td>988</td>
      <td>NONE</td>
      <td>5</td>
      <td>252.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1551</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>551</td>
      <td>Shapley Flow implementation?</td>
      <td>2020-11-11</td>
      <td>2022-01-31</td>
      <td>1018</td>
      <td>572</td>
      <td>NONE</td>
      <td>1</td>
      <td>252.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1867</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>867</td>
      <td>Shap method for CNN regression?</td>
      <td>2021-04-13</td>
      <td>2021-04-26</td>
      <td>865</td>
      <td>852</td>
      <td>NONE</td>
      <td>3</td>
      <td>253.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>949</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>49</td>
      <td>AssertionError: Additivity check failed in TreeExplainer! Please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option.</td>
      <td>2019-12-12</td>
      <td>2022-04-15</td>
      <td>1352</td>
      <td>497</td>
      <td>NONE</td>
      <td>15</td>
      <td>255.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>442</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>42</td>
      <td>Explaining interactions impossible?</td>
      <td>2019-02-12</td>
      <td>2019-02-16</td>
      <td>1656</td>
      <td>1652</td>
      <td>NONE</td>
      <td>3</td>
      <td>256.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2273</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>273</td>
      <td>How to save shap.force_plot as a picture?</td>
      <td>2022-03-05</td>
      <td>2023-06-03</td>
      <td>539</td>
      <td>84</td>
      <td>NONE</td>
      <td>1</td>
      <td>257.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1876</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>876</td>
      <td>How to select GPU id when using shap.explainers.GPUTree?</td>
      <td>2021-04-21</td>
      <td>2021-04-21</td>
      <td>857</td>
      <td>857</td>
      <td>NONE</td>
      <td>0</td>
      <td>257.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1878</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>878</td>
      <td>SHAP for simple neural net taking extremely long time</td>
      <td>2021-04-23</td>
      <td>2021-06-24</td>
      <td>855</td>
      <td>793</td>
      <td>NONE</td>
      <td>1</td>
      <td>257.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1167</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>167</td>
      <td>ValueError: cannot reshape array of size for Deconv model</td>
      <td>2020-04-23</td>
      <td>2020-04-23</td>
      <td>1220</td>
      <td>1220</td>
      <td>NONE</td>
      <td>0</td>
      <td>257.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>909</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>09</td>
      <td>SHAP DeepExplainer shap_values</td>
      <td>2019-11-23</td>
      <td>2019-11-26</td>
      <td>1372</td>
      <td>1369</td>
      <td>NONE</td>
      <td>1</td>
      <td>258.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1539</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>539</td>
      <td>Multivariate outputs issue with DeepExplainer</td>
      <td>2020-11-05</td>
      <td>2020-11-05</td>
      <td>1024</td>
      <td>1024</td>
      <td>NONE</td>
      <td>0</td>
      <td>259.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1191</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>191</td>
      <td>implement predictions with spark models</td>
      <td>2020-04-30</td>
      <td>2020-04-30</td>
      <td>1213</td>
      <td>1213</td>
      <td>NONE</td>
      <td>0</td>
      <td>260.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2181</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>181</td>
      <td>ShAP for Bayesian Networks</td>
      <td>2021-12-12</td>
      <td>2021-12-12</td>
      <td>622</td>
      <td>622</td>
      <td>NONE</td>
      <td>0</td>
      <td>261.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2450</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>450</td>
      <td>How to explain stacking models? One model output is an input feature to the final model</td>
      <td>2022-07-11</td>
      <td>2022-08-09</td>
      <td>411</td>
      <td>382</td>
      <td>NONE</td>
      <td>2</td>
      <td>261.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1883</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>883</td>
      <td>Dependent plot is not working on DeepExplainer</td>
      <td>2021-04-26</td>
      <td>2021-04-28</td>
      <td>852</td>
      <td>850</td>
      <td>NONE</td>
      <td>3</td>
      <td>262.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1051</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>051</td>
      <td>shap for unsupervised model</td>
      <td>2020-02-18</td>
      <td>2020-02-20</td>
      <td>1285</td>
      <td>1282</td>
      <td>NONE</td>
      <td>3</td>
      <td>262.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1181</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>181</td>
      <td>Dataset with more than 100 features and multiclass with RandonForestClassifier Model?</td>
      <td>2020-04-27</td>
      <td>2020-04-27</td>
      <td>1216</td>
      <td>1216</td>
      <td>NONE</td>
      <td>0</td>
      <td>262.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1132</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>132</td>
      <td>Variance for Tree SHAP with interventional feature perturbation</td>
      <td>2020-04-02</td>
      <td>2020-04-02</td>
      <td>1241</td>
      <td>1241</td>
      <td>NONE</td>
      <td>0</td>
      <td>262.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1727</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>727</td>
      <td>Image explainer visualization enhancement: derivation of SHAP for super pixel region</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>263.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1729</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>729</td>
      <td>Image masker's ability to interchange between different segmentation and axes-aligned partitioning approaches.</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>264.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1879</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>879</td>
      <td>`shap.Explanation` lacks documentation</td>
      <td>2021-04-23</td>
      <td>2023-07-03</td>
      <td>855</td>
      <td>54</td>
      <td>NONE</td>
      <td>2</td>
      <td>264.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2572</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>572</td>
      <td>NameError: name 'shap_values' is not defined. Did you mean: 'shap_value'?</td>
      <td>2022-11-09</td>
      <td>2023-07-22</td>
      <td>290</td>
      <td>35</td>
      <td>NONE</td>
      <td>1</td>
      <td>267.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1216</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>216</td>
      <td>How to remove noise from dependence plots</td>
      <td>2020-05-20</td>
      <td>2020-05-20</td>
      <td>1193</td>
      <td>1193</td>
      <td>NONE</td>
      <td>0</td>
      <td>267.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1269</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>269</td>
      <td>Save function for plot_image.</td>
      <td>2020-06-15</td>
      <td>2020-06-22</td>
      <td>1167</td>
      <td>1160</td>
      <td>NONE</td>
      <td>1</td>
      <td>268.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>104</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>04</td>
      <td>Sequence data with recurrent neural nets?</td>
      <td>2018-06-01</td>
      <td>2021-03-22</td>
      <td>1912</td>
      <td>886</td>
      <td>NONE</td>
      <td>6</td>
      <td>268.0</td>
      <td>No</td>
      <td>Issue related to single-dimensional sequence data representations.</td>
      <td>"Data Shape"</td>
      <td>documentation</td>
    </tr>
    <tr>
      <td>1156</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>156</td>
      <td>Background dataset in SamplingExplainer</td>
      <td>2020-04-15</td>
      <td>2020-04-16</td>
      <td>1227</td>
      <td>1227</td>
      <td>NONE</td>
      <td>3</td>
      <td>268.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1860</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>860</td>
      <td>AttributeError: module 'shap' has no attribute 'Explainer'</td>
      <td>2021-04-08</td>
      <td>2021-07-02</td>
      <td>869</td>
      <td>785</td>
      <td>NONE</td>
      <td>3</td>
      <td>270.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1465</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>465</td>
      <td>Decision Plot plotted prediction line offset from x_axis labels, making interpretation difficult</td>
      <td>2020-09-24</td>
      <td>2020-09-24</td>
      <td>1065</td>
      <td>1065</td>
      <td>NONE</td>
      <td>0</td>
      <td>273.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1002</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>002</td>
      <td>shap Deep Explainer (0.34.0)</td>
      <td>2020-01-20</td>
      <td>2020-01-20</td>
      <td>1314</td>
      <td>1314</td>
      <td>NONE</td>
      <td>0</td>
      <td>275.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2062</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>062</td>
      <td>Im getting this error .I dont Know how to solve it</td>
      <td>2021-09-08</td>
      <td>2021-09-13</td>
      <td>717</td>
      <td>712</td>
      <td>NONE</td>
      <td>1</td>
      <td>275.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1428</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>428</td>
      <td>Would It be possibile to add link='logit' option to waterfall_plot? (suggestion)</td>
      <td>2020-09-14</td>
      <td>2022-08-09</td>
      <td>1076</td>
      <td>382</td>
      <td>NONE</td>
      <td>2</td>
      <td>276.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1197</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>197</td>
      <td>Keras LSTM for IMDB Sentiment Classification demo code does not work</td>
      <td>2020-05-06</td>
      <td>2022-05-29</td>
      <td>1207</td>
      <td>453</td>
      <td>NONE</td>
      <td>10</td>
      <td>276.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>800</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>00</td>
      <td>CRIM feature (shap value and feature value) in</td>
      <td>2019-09-09</td>
      <td>2019-09-09</td>
      <td>1447</td>
      <td>1447</td>
      <td>NONE</td>
      <td>0</td>
      <td>277.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2107</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>107</td>
      <td>[Question] Correct link for shap.explainers.tree example ?</td>
      <td>2021-10-15</td>
      <td>2021-10-15</td>
      <td>679</td>
      <td>679</td>
      <td>NONE</td>
      <td>0</td>
      <td>278.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2398</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>398</td>
      <td>Differences between feature importance (random forest), tree explainer and kernel explainer</td>
      <td>2022-05-25</td>
      <td>2022-05-25</td>
      <td>458</td>
      <td>458</td>
      <td>NONE</td>
      <td>0</td>
      <td>279.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1761</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>761</td>
      <td>Deep forest support</td>
      <td>2021-02-06</td>
      <td>2022-03-28</td>
      <td>931</td>
      <td>516</td>
      <td>NONE</td>
      <td>1</td>
      <td>279.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2461</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>461</td>
      <td>Shap not working with bert fine tuned multi text classification problem.</td>
      <td>2022-07-23</td>
      <td>2023-07-30</td>
      <td>399</td>
      <td>27</td>
      <td>NONE</td>
      <td>1</td>
      <td>279.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2504</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>504</td>
      <td>How is the shap values for multi output regression for Kernal Explainer is calculated?</td>
      <td>2022-09-13</td>
      <td>2023-01-04</td>
      <td>347</td>
      <td>233</td>
      <td>NONE</td>
      <td>2</td>
      <td>279.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>362</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>62</td>
      <td>Changing the Additive force graph default grouping</td>
      <td>2018-12-21</td>
      <td>2018-12-21</td>
      <td>1709</td>
      <td>1709</td>
      <td>NONE</td>
      <td>1</td>
      <td>279.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1127</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>127</td>
      <td>test_gradient.py failed sometimes</td>
      <td>2020-04-02</td>
      <td>2020-04-02</td>
      <td>1241</td>
      <td>1241</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>280.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>478</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>78</td>
      <td>Support for GradientBoostingClassifier using TreeExplainer</td>
      <td>2019-03-07</td>
      <td>2022-10-30</td>
      <td>1633</td>
      <td>300</td>
      <td>NONE</td>
      <td>8</td>
      <td>280.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2614</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>614</td>
      <td>There are something worng with the plt_show</td>
      <td>2022-12-15</td>
      <td>2022-12-15</td>
      <td>254</td>
      <td>254</td>
      <td>NONE</td>
      <td>0</td>
      <td>281.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1133</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>133</td>
      <td>What is the best plot for interpreting shap values of multivariate LSTM?</td>
      <td>2020-04-02</td>
      <td>2020-04-02</td>
      <td>1241</td>
      <td>1241</td>
      <td>NONE</td>
      <td>0</td>
      <td>282.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1451</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>451</td>
      <td>where is interaction order in explanation?</td>
      <td>2020-09-20</td>
      <td>2020-09-20</td>
      <td>1069</td>
      <td>1069</td>
      <td>NONE</td>
      <td>0</td>
      <td>283.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1296</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>296</td>
      <td>MNIST DeepExplainer demo doesn't work</td>
      <td>2020-07-03</td>
      <td>2020-12-21</td>
      <td>1149</td>
      <td>978</td>
      <td>NONE</td>
      <td>5</td>
      <td>284.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1500</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>500</td>
      <td>custom f(x) in heatmap plot</td>
      <td>2020-10-10</td>
      <td>2020-10-10</td>
      <td>1050</td>
      <td>1050</td>
      <td>NONE</td>
      <td>0</td>
      <td>285.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1728</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>728</td>
      <td>Debugging/logging mechanism for image explainers</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>285.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>193</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>93</td>
      <td>Standard Errors in Kernel Explainer</td>
      <td>2018-07-31</td>
      <td>2018-08-01</td>
      <td>1852</td>
      <td>1851</td>
      <td>NONE</td>
      <td>1</td>
      <td>285.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1903</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>903</td>
      <td>shap_values for multi-classification</td>
      <td>2021-05-07</td>
      <td>2021-08-24</td>
      <td>841</td>
      <td>732</td>
      <td>NONE</td>
      <td>1</td>
      <td>286.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>228</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>28</td>
      <td>SHAP for RNN many2many problem</td>
      <td>2018-08-19</td>
      <td>2019-01-11</td>
      <td>1833</td>
      <td>1688</td>
      <td>NONE</td>
      <td>4</td>
      <td>287.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1383</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>383</td>
      <td>Question from KDD 2020 Presentation</td>
      <td>2020-08-26</td>
      <td>2020-08-26</td>
      <td>1095</td>
      <td>1094</td>
      <td>NONE</td>
      <td>1</td>
      <td>287.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2291</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>291</td>
      <td>wrong: Only stacked models with equal numbers of trees are supported!</td>
      <td>2022-03-18</td>
      <td>2022-03-28</td>
      <td>526</td>
      <td>516</td>
      <td>NONE</td>
      <td>1</td>
      <td>287.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>880</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>80</td>
      <td>Absolute shapely values</td>
      <td>2019-11-05</td>
      <td>2019-11-05</td>
      <td>1390</td>
      <td>1390</td>
      <td>NONE</td>
      <td>0</td>
      <td>288.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1371</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>371</td>
      <td>Zero Shap values</td>
      <td>2020-08-18</td>
      <td>2020-08-29</td>
      <td>1102</td>
      <td>1092</td>
      <td>NONE</td>
      <td>1</td>
      <td>288.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2375</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>375</td>
      <td>summary_plot type bar not showing bar plot</td>
      <td>2022-05-03</td>
      <td>2022-10-20</td>
      <td>479</td>
      <td>310</td>
      <td>NONE</td>
      <td>1</td>
      <td>289.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>613</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a>3</td>
      <td>ordering of Shapley values in case of LSTM model</td>
      <td>2019-05-29</td>
      <td>2019-05-29</td>
      <td>1550</td>
      <td>1550</td>
      <td>NONE</td>
      <td>0</td>
      <td>289.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1307</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>307</td>
      <td>Can unicode minus be configurable?</td>
      <td>2020-07-10</td>
      <td>2020-07-10</td>
      <td>1142</td>
      <td>1142</td>
      <td>NONE</td>
      <td>0</td>
      <td>290.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2599</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>599</td>
      <td>DeepExplainer(pytorch): Sum of shap values is not equal to predicted value. why not using check_additivity?</td>
      <td>2022-12-05</td>
      <td>2022-12-05</td>
      <td>264</td>
      <td>264</td>
      <td>NONE</td>
      <td>0</td>
      <td>290.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2627</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>627</td>
      <td>Bar plot doesn't show the feature values</td>
      <td>2023-01-02</td>
      <td>2023-04-11</td>
      <td>236</td>
      <td>137</td>
      <td>NONE</td>
      <td>4</td>
      <td>290.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1882</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>882</td>
      <td>Which predict proba to pick ?</td>
      <td>2021-04-25</td>
      <td>2021-04-25</td>
      <td>853</td>
      <td>853</td>
      <td>NONE</td>
      <td>0</td>
      <td>291.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2000</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>000</td>
      <td>Is there a way to set seed while generating shap values for reproducibility?</td>
      <td>2021-07-17</td>
      <td>2022-10-17</td>
      <td>770</td>
      <td>313</td>
      <td>NONE</td>
      <td>4</td>
      <td>292.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1130</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>130</td>
      <td>Can deepexpainer  calculate the shap value of lstm that is used for regression?</td>
      <td>2020-04-02</td>
      <td>2020-12-10</td>
      <td>1241</td>
      <td>989</td>
      <td>NONE</td>
      <td>1</td>
      <td>298.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>316</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>16</td>
      <td>Simple question about LightGBM PredictContrib</td>
      <td>2018-11-09</td>
      <td>2018-11-23</td>
      <td>1751</td>
      <td>1737</td>
      <td>NONE</td>
      <td>5</td>
      <td>301.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2352</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>352</td>
      <td>Explainer class does not support `algorithm=kernel`</td>
      <td>2022-04-20</td>
      <td>2022-04-20</td>
      <td>493</td>
      <td>493</td>
      <td>NONE</td>
      <td>0</td>
      <td>303.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>693</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>3</td>
      <td>Avoid out of memory issues with large datasets with many features</td>
      <td>2019-07-10</td>
      <td>2023-08-26</td>
      <td>1508</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>303.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1718</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>718</td>
      <td>More details about background dataset</td>
      <td>2021-01-20</td>
      <td>2021-01-20</td>
      <td>947</td>
      <td>947</td>
      <td>NONE</td>
      <td>0</td>
      <td>304.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1209</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>209</td>
      <td>shap_values resulting in segmentation fault: 11</td>
      <td>2020-05-14</td>
      <td>2020-05-14</td>
      <td>1199</td>
      <td>1199</td>
      <td>NONE</td>
      <td>0</td>
      <td>305.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>456</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>56</td>
      <td>how to use shap for custom-built models</td>
      <td>2019-02-22</td>
      <td>2023-07-19</td>
      <td>1646</td>
      <td>38</td>
      <td>NONE</td>
      <td>6</td>
      <td>307.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2464</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>464</td>
      <td>Dependence plot `x_jitter` doesn't work when there's only a single x value</td>
      <td>2022-07-26</td>
      <td>2022-07-26</td>
      <td>395</td>
      <td>395</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>307.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>162</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>62</td>
      <td>Different summary plots for same dataset when use tree SHAP and Kernel SHAP</td>
      <td>2018-07-17</td>
      <td>2018-10-03</td>
      <td>1866</td>
      <td>1788</td>
      <td>NONE</td>
      <td>3</td>
      <td>308.0</td>
      <td>No</td>
      <td>Issue with different summarizations in the function.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1984</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>984</td>
      <td>ERROR: Files/directories not found in C:/user/&lt;folder&gt;/Appdata/Local/pip-req-build-3mlgezzc/shap/pip-egg-info</td>
      <td>2021-07-06</td>
      <td>2021-09-27</td>
      <td>781</td>
      <td>697</td>
      <td>NONE</td>
      <td>1</td>
      <td>309.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1517</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>517</td>
      <td>For KernelSHAP can I get an estimate of execution time?</td>
      <td>2020-10-20</td>
      <td>2020-11-10</td>
      <td>1040</td>
      <td>1019</td>
      <td>NONE</td>
      <td>0</td>
      <td>309.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2673</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>673</td>
      <td>question to tensorflow decision forests</td>
      <td>2023-03-05</td>
      <td>2023-06-16</td>
      <td>174</td>
      <td>71</td>
      <td>NONE</td>
      <td>0</td>
      <td>310.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1344</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>344</td>
      <td>module 'shap' has no attribute 'utils'</td>
      <td>2020-08-04</td>
      <td>2020-08-11</td>
      <td>1117</td>
      <td>1110</td>
      <td>NONE</td>
      <td>2</td>
      <td>310.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2422</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>422</td>
      <td>save KernelExplainer (Tensorflow model)?</td>
      <td>2022-06-12</td>
      <td>2022-06-12</td>
      <td>440</td>
      <td>440</td>
      <td>NONE</td>
      <td>0</td>
      <td>311.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>81</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>1</td>
      <td>Doesn't seem to run in jupyter lab</td>
      <td>2018-05-14</td>
      <td>2019-04-02</td>
      <td>1930</td>
      <td>1607</td>
      <td>NONE</td>
      <td>10</td>
      <td>311.0</td>
      <td>No</td>
      <td>Issue with string title not displaying correctly in Jupyter Lab.</td>
      <td>"Shape Issue"</td>
      <td>bug</td>
    </tr>
    <tr>
      <td>2227</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>227</td>
      <td>Multi output regressor</td>
      <td>2022-01-26</td>
      <td>2022-01-26</td>
      <td>577</td>
      <td>577</td>
      <td>NONE</td>
      <td>0</td>
      <td>311.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1317</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>317</td>
      <td>Support for Swish activation function?</td>
      <td>2020-07-17</td>
      <td>2020-11-20</td>
      <td>1134</td>
      <td>1008</td>
      <td>NONE</td>
      <td>1</td>
      <td>312.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1719</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>719</td>
      <td>Batching for function 'f' used in creating wrapped model in image captioning notebooks</td>
      <td>2021-01-20</td>
      <td>2021-01-20</td>
      <td>947</td>
      <td>947</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>312.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2689</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>689</td>
      <td>TreeExplainer support for GradientBoostingClassifier in multiclass classification</td>
      <td>2023-03-29</td>
      <td>2023-06-04</td>
      <td>150</td>
      <td>83</td>
      <td>NONE</td>
      <td>0</td>
      <td>312.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2390</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>390</td>
      <td>How to use Shap on ASR models</td>
      <td>2022-05-17</td>
      <td>2022-08-11</td>
      <td>466</td>
      <td>379</td>
      <td>NONE</td>
      <td>2</td>
      <td>313.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1138</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>138</td>
      <td>AttributeError: 'Operation' object has no attribute 'shape'</td>
      <td>2020-04-05</td>
      <td>2023-02-28</td>
      <td>1238</td>
      <td>179</td>
      <td>NONE</td>
      <td>2</td>
      <td>314.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1100</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>100</td>
      <td>[question] reinforcement learning?</td>
      <td>2020-03-15</td>
      <td>2020-12-13</td>
      <td>1259</td>
      <td>986</td>
      <td>NONE</td>
      <td>1</td>
      <td>316.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2541</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>541</td>
      <td>SHAP for CNN regression model with different image shapes</td>
      <td>2022-10-06</td>
      <td>2023-08-26</td>
      <td>324</td>
      <td>0</td>
      <td>NONE</td>
      <td>3</td>
      <td>316.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1091</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>091</td>
      <td>Summary plot for a multi-input network?</td>
      <td>2020-03-08</td>
      <td>2020-03-09</td>
      <td>1266</td>
      <td>1265</td>
      <td>NONE</td>
      <td>1</td>
      <td>317.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1895</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>895</td>
      <td>Retrieve specific data point from summary/beeswarm plots</td>
      <td>2021-05-02</td>
      <td>2021-05-07</td>
      <td>845</td>
      <td>840</td>
      <td>NONE</td>
      <td>2</td>
      <td>317.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2486</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>486</td>
      <td>Partition Explainer v.s. Permutation Explainer for Text Model</td>
      <td>2022-08-22</td>
      <td>2022-08-22</td>
      <td>368</td>
      <td>368</td>
      <td>NONE</td>
      <td>0</td>
      <td>319.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1754</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>754</td>
      <td>'Warning: unrecognized nn.Module: {}'.format(module_type) as a warning or log</td>
      <td>2021-02-01</td>
      <td>2021-02-01</td>
      <td>935</td>
      <td>935</td>
      <td>NONE</td>
      <td>0</td>
      <td>321.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2045</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>045</td>
      <td>Broken 'Edit on Github' Link on Introduction to Shapely Values Webpage</td>
      <td>2021-08-20</td>
      <td>2021-08-20</td>
      <td>736</td>
      <td>736</td>
      <td>NONE</td>
      <td>0</td>
      <td>322.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>672</td>
      <td><a href="https://github.com/shap/shap/issues/673">673</a></td>
      <td>Outputs in VGG pyTorch example look essentially the same</td>
      <td>2019-07-01</td>
      <td>2019-07-01</td>
      <td>1516</td>
      <td>1516</td>
      <td>NONE</td>
      <td>1</td>
      <td>322.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>24</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>4</td>
      <td>Typos in the Tree SHAP arXiv paper</td>
      <td>2018-01-25</td>
      <td>2023-06-04</td>
      <td>2038</td>
      <td>83</td>
      <td>NONE</td>
      <td>1</td>
      <td>323.0</td>
      <td>No</td>
      <td>"Typos identified in figure 1, needing corrections."</td>
      <td>"Typo Correction"</td>
      <td>documentation</td>
    </tr>
    <tr>
      <td>2365</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>365</td>
      <td>Can DeepSHAP support GroupNorm layer?</td>
      <td>2022-04-28</td>
      <td>2022-04-28</td>
      <td>485</td>
      <td>485</td>
      <td>NONE</td>
      <td>0</td>
      <td>324.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1687</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>687</td>
      <td>explain CNN image classification</td>
      <td>2021-01-11</td>
      <td>2021-01-11</td>
      <td>957</td>
      <td>957</td>
      <td>NONE</td>
      <td>0</td>
      <td>326.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1578</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>578</td>
      <td>Target encoding and SHAP values</td>
      <td>2020-11-24</td>
      <td>2022-06-07</td>
      <td>1005</td>
      <td>445</td>
      <td>NONE</td>
      <td>3</td>
      <td>326.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2633</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>633</td>
      <td>Can we plot shape dependence plots with histogram at x&amp;y axis in Kernalexplainer for multioutput regression (wrapper models of ensemble methods)?</td>
      <td>2023-01-04</td>
      <td>2023-01-08</td>
      <td>233</td>
      <td>230</td>
      <td>NONE</td>
      <td>1</td>
      <td>327.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1273</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>273</td>
      <td>Getting negative expected values</td>
      <td>2020-06-17</td>
      <td>2020-06-18</td>
      <td>1164</td>
      <td>1164</td>
      <td>NONE</td>
      <td>1</td>
      <td>327.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1711</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>711</td>
      <td>How do i get SHAP input feature importance summary results (regressor/classifier model) in data frame or array values instead of plots ?</td>
      <td>2021-01-18</td>
      <td>2021-10-25</td>
      <td>950</td>
      <td>670</td>
      <td>NONE</td>
      <td>1</td>
      <td>328.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1052</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>052</td>
      <td>How to use SHAP for large dataset?</td>
      <td>2020-02-19</td>
      <td>2020-12-20</td>
      <td>1284</td>
      <td>979</td>
      <td>NONE</td>
      <td>7</td>
      <td>328.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>445</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>45</td>
      <td>Standalone java implementation</td>
      <td>2019-02-13</td>
      <td>2020-06-04</td>
      <td>1655</td>
      <td>1177</td>
      <td>NONE</td>
      <td>2</td>
      <td>329.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2661</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>661</td>
      <td>Dependance and summary plot notdrawing</td>
      <td>2023-02-10</td>
      <td>2023-06-04</td>
      <td>197</td>
      <td>83</td>
      <td>NONE</td>
      <td>1</td>
      <td>329.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>177</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>77</td>
      <td>summary_plot for shap_interaction_value fails with \"index is out of bounds\" err</td>
      <td>2018-07-24</td>
      <td>2019-05-23</td>
      <td>1859</td>
      <td>1555</td>
      <td>NONE</td>
      <td>2</td>
      <td>330.0</td>
      <td>No</td>
      <td>Issue: "summary_plot function failing in /shap directory."</td>
      <td>"Plot Failure"</td>
      <td>bug</td>
    </tr>
    <tr>
      <td>1208</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>208</td>
      <td>image_plot doesn't return anything regardless of \"show\" argumen</td>
      <td>2020-05-13</td>
      <td>2021-05-14</td>
      <td>1200</td>
      <td>834</td>
      <td>NONE</td>
      <td>2</td>
      <td>331.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>271</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>71</td>
      <td>shap_interaction_values for DeepExplainer</td>
      <td>2018-09-27</td>
      <td>2021-08-26</td>
      <td>1793</td>
      <td>730</td>
      <td>NONE</td>
      <td>2</td>
      <td>331.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>792</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>92</td>
      <td>SHAP for recommendation system/engine</td>
      <td>2019-09-05</td>
      <td>2022-10-02</td>
      <td>1451</td>
      <td>328</td>
      <td>NONE</td>
      <td>4</td>
      <td>331.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1020</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>020</td>
      <td>SHAP not working in Python 3.7.6</td>
      <td>2020-01-29</td>
      <td>2022-01-03</td>
      <td>1304</td>
      <td>600</td>
      <td>NONE</td>
      <td>5</td>
      <td>332.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1910</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>910</td>
      <td>when converting categorical features to OHE why one of the categorical columns shows all shap values as zero.</td>
      <td>2021-05-10</td>
      <td>2021-05-12</td>
      <td>838</td>
      <td>836</td>
      <td>NONE</td>
      <td>6</td>
      <td>333.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2332</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>332</td>
      <td>show = False does not work for shap.decision_plot()</td>
      <td>2022-04-07</td>
      <td>2022-04-13</td>
      <td>506</td>
      <td>500</td>
      <td>NONE</td>
      <td>1</td>
      <td>333.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1682</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>682</td>
      <td>Is there any way to unstack shap.force_plot() for a single row of dataframe</td>
      <td>2021-01-10</td>
      <td>2021-01-10</td>
      <td>958</td>
      <td>958</td>
      <td>NONE</td>
      <td>0</td>
      <td>333.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1003</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>003</td>
      <td>Partial Dependence Plot structure is really different from other plots</td>
      <td>2020-01-20</td>
      <td>2021-06-03</td>
      <td>1314</td>
      <td>814</td>
      <td>NONE</td>
      <td>2</td>
      <td>334.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1053</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>053</td>
      <td>shapley kernel proof (nips supplement)</td>
      <td>2020-02-20</td>
      <td>2023-06-04</td>
      <td>1283</td>
      <td>83</td>
      <td>NONE</td>
      <td>1</td>
      <td>334.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2048</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>048</td>
      <td>Merge Shap (Permutation) explanation</td>
      <td>2021-08-24</td>
      <td>2021-08-27</td>
      <td>732</td>
      <td>729</td>
      <td>NONE</td>
      <td>1</td>
      <td>335.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1145</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>145</td>
      <td>TreeSHAP in Java</td>
      <td>2020-04-08</td>
      <td>2020-05-05</td>
      <td>1235</td>
      <td>1208</td>
      <td>NONE</td>
      <td>6</td>
      <td>337.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>491</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>91</td>
      <td>Creating a Custom React Component for Shap Figures</td>
      <td>2019-03-13</td>
      <td>2021-07-07</td>
      <td>1626</td>
      <td>780</td>
      <td>NONE</td>
      <td>3</td>
      <td>337.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1116</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>116</td>
      <td>Order of Categorical Labels in explainer.expected_value</td>
      <td>2020-03-23</td>
      <td>2020-04-04</td>
      <td>1251</td>
      <td>1238</td>
      <td>NONE</td>
      <td>12</td>
      <td>338.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1088</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>088</td>
      <td>dependence_plot incorrectly flagging minmaxed variables as categorical</td>
      <td>2020-03-06</td>
      <td>2020-03-06</td>
      <td>1267</td>
      <td>1267</td>
      <td>NONE</td>
      <td>0</td>
      <td>338.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2426</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>426</td>
      <td>number of samples in `Kernel` explainer</td>
      <td>2022-06-14</td>
      <td>2022-07-04</td>
      <td>438</td>
      <td>418</td>
      <td>NONE</td>
      <td>3</td>
      <td>339.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1092</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>092</td>
      <td>SHAP 0.35.0 will not pip/conda install...</td>
      <td>2020-03-09</td>
      <td>2023-01-26</td>
      <td>1264</td>
      <td>212</td>
      <td>NONE</td>
      <td>9</td>
      <td>340.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1285</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>285</td>
      <td>Tensorflow2.2  tensors_blocked_by_false  recurse for ever</td>
      <td>2020-06-24</td>
      <td>2020-10-30</td>
      <td>1158</td>
      <td>1030</td>
      <td>NONE</td>
      <td>3</td>
      <td>340.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1257</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>257</td>
      <td>One list shap value while bianry classification</td>
      <td>2020-06-09</td>
      <td>2020-06-09</td>
      <td>1173</td>
      <td>1173</td>
      <td>NONE</td>
      <td>0</td>
      <td>341.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2059</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>059</td>
      <td>How to use Gluonts with SHAP explainer</td>
      <td>2021-09-05</td>
      <td>2021-09-05</td>
      <td>720</td>
      <td>720</td>
      <td>NONE</td>
      <td>0</td>
      <td>341.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2122</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>122</td>
      <td>Feature values for base value</td>
      <td>2021-10-29</td>
      <td>2021-10-29</td>
      <td>666</td>
      <td>666</td>
      <td>NONE</td>
      <td>0</td>
      <td>342.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2324</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>324</td>
      <td>Ordering Beeswarm Plot</td>
      <td>2022-04-04</td>
      <td>2022-04-04</td>
      <td>509</td>
      <td>509</td>
      <td>NONE</td>
      <td>0</td>
      <td>343.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1343</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>343</td>
      <td>Question about how to use the layer that does not exist in op_handler.</td>
      <td>2020-08-04</td>
      <td>2020-08-04</td>
      <td>1117</td>
      <td>1117</td>
      <td>NONE</td>
      <td>0</td>
      <td>343.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1706</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>706</td>
      <td>Use the default config parameter locations</td>
      <td>2021-01-16</td>
      <td>2021-01-16</td>
      <td>952</td>
      <td>952</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>344.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>247</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>47</td>
      <td>ValueError when using shap_interaction_values</td>
      <td>2018-08-31</td>
      <td>2019-01-12</td>
      <td>1820</td>
      <td>1686</td>
      <td>NONE</td>
      <td>12</td>
      <td>346.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2441</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>441</td>
      <td>Gradient Explainer Issue</td>
      <td>2022-06-30</td>
      <td>2023-07-10</td>
      <td>422</td>
      <td>47</td>
      <td>NONE</td>
      <td>4</td>
      <td>346.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1151</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>151</td>
      <td>Isolation forest model_output: \"decision_function\" not implement</td>
      <td>2020-04-14</td>
      <td>2021-04-23</td>
      <td>1229</td>
      <td>855</td>
      <td>NONE</td>
      <td>12</td>
      <td>346.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1350</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>350</td>
      <td>The SHAP explanations do not sum up to the model's output! This is either because of a rounding error or because an operator in your computation graph was not fully supported. If the sum difference of nan is significant compared the scale of your model outputs please post as a github issue, with a reproducable example if possible so we can debug it.</td>
      <td>2020-08-07</td>
      <td>2020-08-07</td>
      <td>1114</td>
      <td>1114</td>
      <td>NONE</td>
      <td>1</td>
      <td>347.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1026</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>026</td>
      <td>Features were not shown on shap force plot.</td>
      <td>2020-02-02</td>
      <td>2020-02-08</td>
      <td>1301</td>
      <td>1294</td>
      <td>NONE</td>
      <td>1</td>
      <td>347.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2121</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>121</td>
      <td>TreeExplainer is taking too long</td>
      <td>2021-10-28</td>
      <td>2023-07-04</td>
      <td>666</td>
      <td>53</td>
      <td>NONE</td>
      <td>3</td>
      <td>347.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1336</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>336</td>
      <td>TreeExplainer error with sklearn 0.23.1</td>
      <td>2020-07-31</td>
      <td>2020-08-30</td>
      <td>1121</td>
      <td>1091</td>
      <td>NONE</td>
      <td>1</td>
      <td>349.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1898</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>898</td>
      <td>How to set a batch size for kernelExplainer</td>
      <td>2021-05-04</td>
      <td>2021-06-03</td>
      <td>844</td>
      <td>814</td>
      <td>NONE</td>
      <td>2</td>
      <td>349.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2058</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>058</td>
      <td>Difference between XGBoost model output not matching Shap output</td>
      <td>2021-09-05</td>
      <td>2021-09-06</td>
      <td>720</td>
      <td>719</td>
      <td>NONE</td>
      <td>2</td>
      <td>350.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1293</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>293</td>
      <td>SHAP values for aleatoric and epistemic uncertainties</td>
      <td>2020-06-26</td>
      <td>2020-06-26</td>
      <td>1156</td>
      <td>1156</td>
      <td>NONE</td>
      <td>0</td>
      <td>352.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2526</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>526</td>
      <td>Variant of TreeSHAP using marginal/unconditional background distribution?</td>
      <td>2022-09-22</td>
      <td>2022-09-22</td>
      <td>337</td>
      <td>337</td>
      <td>NONE</td>
      <td>0</td>
      <td>352.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1215</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>215</td>
      <td>Incorrect tooltip with force plot</td>
      <td>2020-05-18</td>
      <td>2020-05-18</td>
      <td>1195</td>
      <td>1195</td>
      <td>NONE</td>
      <td>0</td>
      <td>352.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2563</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>563</td>
      <td>(none, none, 3) not supported for shap?</td>
      <td>2022-10-29</td>
      <td>2022-10-31</td>
      <td>301</td>
      <td>298</td>
      <td>NONE</td>
      <td>0</td>
      <td>352.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2322</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>322</td>
      <td>TypeError: Bytes object cannot be interpreted as an integer</td>
      <td>2022-04-02</td>
      <td>2023-03-20</td>
      <td>511</td>
      <td>159</td>
      <td>NONE</td>
      <td>4</td>
      <td>353.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2476</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>476</td>
      <td>interaction values scatter plot: \"dot_size\" argument not worki</td>
      <td>2022-08-11</td>
      <td>2022-08-11</td>
      <td>380</td>
      <td>380</td>
      <td>NONE</td>
      <td>0</td>
      <td>353.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1199</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>199</td>
      <td>Displaying force plots in Sypder IDE console and saving them to a folder.</td>
      <td>2020-05-07</td>
      <td>2020-08-05</td>
      <td>1206</td>
      <td>1116</td>
      <td>NONE</td>
      <td>3</td>
      <td>354.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1089</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>089</td>
      <td>Feature importance return different value</td>
      <td>2020-03-06</td>
      <td>2020-04-16</td>
      <td>1267</td>
      <td>1227</td>
      <td>NONE</td>
      <td>7</td>
      <td>359.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1328</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>328</td>
      <td>Saving the Results of a shap.summary_plot as a Pandas Dataframe</td>
      <td>2020-07-25</td>
      <td>2021-03-04</td>
      <td>1127</td>
      <td>905</td>
      <td>NONE</td>
      <td>2</td>
      <td>359.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1608</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>608</td>
      <td>Cant set titles on summary_plot</td>
      <td>2020-12-10</td>
      <td>2022-08-11</td>
      <td>989</td>
      <td>380</td>
      <td>NONE</td>
      <td>8</td>
      <td>360.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1770</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>770</td>
      <td>Using Kernel SHAP with own MNIST Model</td>
      <td>2021-02-15</td>
      <td>2023-07-31</td>
      <td>922</td>
      <td>26</td>
      <td>NONE</td>
      <td>1</td>
      <td>360.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>583</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a>3</td>
      <td>Shap classification woes</td>
      <td>2019-05-11</td>
      <td>2019-05-14</td>
      <td>1568</td>
      <td>1564</td>
      <td>NONE</td>
      <td>5</td>
      <td>362.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1097</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>097</td>
      <td>what's the difference between feature_perturbation=\"interventional\" and feature_perturbation=\"tree_path_depende</td>
      <td>2020-03-13</td>
      <td>2022-11-28</td>
      <td>1261</td>
      <td>271</td>
      <td>NONE</td>
      <td>6</td>
      <td>362.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1221</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>221</td>
      <td>feature_perturbation effect</td>
      <td>2020-05-22</td>
      <td>2020-05-22</td>
      <td>1191</td>
      <td>1191</td>
      <td>NONE</td>
      <td>0</td>
      <td>366.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2067</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>067</td>
      <td>Highlighting stop-words is a real drawback</td>
      <td>2021-09-14</td>
      <td>2021-09-14</td>
      <td>711</td>
      <td>711</td>
      <td>NONE</td>
      <td>0</td>
      <td>368.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>389</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>89</td>
      <td>AssertionError: &lt;class 'keras.wrappers.scikit_learn.KerasClassifier'&gt; is not currently a supported model type!</td>
      <td>2019-01-13</td>
      <td>2019-01-19</td>
      <td>1686</td>
      <td>1680</td>
      <td>NONE</td>
      <td>1</td>
      <td>368.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2112</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>112</td>
      <td>Support for Deep learning model?</td>
      <td>2021-10-24</td>
      <td>2021-10-24</td>
      <td>671</td>
      <td>671</td>
      <td>NONE</td>
      <td>0</td>
      <td>370.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2074</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>074</td>
      <td>NotFoundError: No algorithm worked! [Op:Conv3D]</td>
      <td>2021-09-15</td>
      <td>2021-09-15</td>
      <td>709</td>
      <td>709</td>
      <td>NONE</td>
      <td>0</td>
      <td>370.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1905</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>905</td>
      <td>remove the \"sum of other features\" from beeswarm pl</td>
      <td>2021-05-07</td>
      <td>2023-05-16</td>
      <td>840</td>
      <td>102</td>
      <td>NONE</td>
      <td>1</td>
      <td>371.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2558</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>558</td>
      <td>What are the maximum values and the minimum value that a shaley value can get?</td>
      <td>2022-10-24</td>
      <td>2022-10-24</td>
      <td>306</td>
      <td>306</td>
      <td>NONE</td>
      <td>0</td>
      <td>371.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1499</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>499</td>
      <td>more configurations for f(x) at heatmap</td>
      <td>2020-10-09</td>
      <td>2020-10-09</td>
      <td>1050</td>
      <td>1050</td>
      <td>NONE</td>
      <td>0</td>
      <td>373.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2197</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>197</td>
      <td>Add a progress bar to shap_interaction_values</td>
      <td>2021-12-22</td>
      <td>2021-12-22</td>
      <td>612</td>
      <td>612</td>
      <td>NONE</td>
      <td>0</td>
      <td>376.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2326</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>326</td>
      <td>Product of predictions</td>
      <td>2022-04-05</td>
      <td>2022-04-05</td>
      <td>508</td>
      <td>508</td>
      <td>NONE</td>
      <td>0</td>
      <td>377.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1212</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>212</td>
      <td>Negative SHAP expected value</td>
      <td>2020-05-16</td>
      <td>2020-05-30</td>
      <td>1197</td>
      <td>1183</td>
      <td>NONE</td>
      <td>2</td>
      <td>378.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1184</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>184</td>
      <td>[DOC]Can you sort variables in TreeExplainer -&gt;summaryPlot?</td>
      <td>2020-04-28</td>
      <td>2020-04-28</td>
      <td>1215</td>
      <td>1215</td>
      <td>NONE</td>
      <td>0</td>
      <td>381.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>395</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>95</td>
      <td>Interpretation on feature impact plot</td>
      <td>2019-01-17</td>
      <td>2019-01-22</td>
      <td>1681</td>
      <td>1677</td>
      <td>NONE</td>
      <td>2</td>
      <td>381.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2553</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>553</td>
      <td>Explainer calls predict with a smaller set</td>
      <td>2022-10-18</td>
      <td>2023-08-26</td>
      <td>312</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>381.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2032</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>032</td>
      <td>Using Shap with Deepmatcher</td>
      <td>2021-08-10</td>
      <td>2021-08-10</td>
      <td>746</td>
      <td>746</td>
      <td>NONE</td>
      <td>0</td>
      <td>381.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1299</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>299</td>
      <td>TreeShap shap values</td>
      <td>2020-07-06</td>
      <td>2020-07-06</td>
      <td>1146</td>
      <td>1146</td>
      <td>NONE</td>
      <td>0</td>
      <td>382.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2590</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>590</td>
      <td>Workaround for tensorflow session to  be used as 'model' for DeepExplainer module</td>
      <td>2022-11-20</td>
      <td>2022-11-20</td>
      <td>279</td>
      <td>279</td>
      <td>NONE</td>
      <td>0</td>
      <td>382.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>833</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>33</td>
      <td>It hangs when calculating shap values for RandomForestRegressor</td>
      <td>2019-09-26</td>
      <td>2020-08-10</td>
      <td>1430</td>
      <td>1111</td>
      <td>NONE</td>
      <td>6</td>
      <td>384.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>857</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>57</td>
      <td>base value in IRIS dataset is error</td>
      <td>2019-10-19</td>
      <td>2019-10-21</td>
      <td>1407</td>
      <td>1405</td>
      <td>NONE</td>
      <td>1</td>
      <td>385.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>3</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a></td>
      <td>Adjusting number of features shown</td>
      <td>2017-10-24</td>
      <td>2017-10-31</td>
      <td>2131</td>
      <td>2125</td>
      <td>NONE</td>
      <td>5</td>
      <td>386.0</td>
      <td>No</td>
      <td>Issue with visualizing data due to single-dimensional array shape.</td>
      <td>"Visualization Issue"</td>
      <td>bug</td>
    </tr>
    <tr>
      <td>958</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>58</td>
      <td>Implementation of DeepLift in DeepShap</td>
      <td>2019-12-17</td>
      <td>2019-12-17</td>
      <td>1348</td>
      <td>1348</td>
      <td>NONE</td>
      <td>1</td>
      <td>387.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1050</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>050</td>
      <td>summary plot assumes squared picture data in case shap_values.shape is 3d</td>
      <td>2020-02-18</td>
      <td>2020-02-20</td>
      <td>1285</td>
      <td>1283</td>
      <td>NONE</td>
      <td>2</td>
      <td>389.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>286</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>86</td>
      <td>weighted least squares equation to estimate phi</td>
      <td>2018-10-17</td>
      <td>2018-10-19</td>
      <td>1774</td>
      <td>1772</td>
      <td>NONE</td>
      <td>1</td>
      <td>389.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2041</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>041</td>
      <td>[ERROR] In v0.20 force_plot now requires the base value as the first parameter!</td>
      <td>2021-08-17</td>
      <td>2021-08-17</td>
      <td>739</td>
      <td>739</td>
      <td>NONE</td>
      <td>0</td>
      <td>393.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>763</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>63</td>
      <td>Show class names in SHAP summary plots</td>
      <td>2019-08-21</td>
      <td>2023-07-03</td>
      <td>1465</td>
      <td>54</td>
      <td>NONE</td>
      <td>9</td>
      <td>393.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1768</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>768</td>
      <td>SHAP explaination in BiRNN Keras model</td>
      <td>2021-02-11</td>
      <td>2021-05-09</td>
      <td>926</td>
      <td>839</td>
      <td>NONE</td>
      <td>2</td>
      <td>394.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1447</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>447</td>
      <td>A bug when running the tutorial  Mnist DeepExplainer under Keras Framework</td>
      <td>2020-09-19</td>
      <td>2020-11-15</td>
      <td>1071</td>
      <td>1014</td>
      <td>NONE</td>
      <td>1</td>
      <td>394.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2201</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>201</td>
      <td>Segmentation Fault for Catboost Regressor on M1 Mac</td>
      <td>2021-12-28</td>
      <td>2022-01-03</td>
      <td>606</td>
      <td>600</td>
      <td>NONE</td>
      <td>1</td>
      <td>394.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1321</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>321</td>
      <td>NotImplementedError: CategoricalSplit are not yet implemented</td>
      <td>2020-07-20</td>
      <td>2023-08-16</td>
      <td>1132</td>
      <td>10</td>
      <td>NONE</td>
      <td>4</td>
      <td>394.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2182</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>182</td>
      <td>AssertionError in DeepExplainer</td>
      <td>2021-12-13</td>
      <td>2022-02-26</td>
      <td>621</td>
      <td>545</td>
      <td>NONE</td>
      <td>1</td>
      <td>395.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>347</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>47</td>
      <td>If a feature is NaN, the SHAP value is never shown on a dependency plot</td>
      <td>2018-12-06</td>
      <td>2018-12-07</td>
      <td>1724</td>
      <td>1723</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>397.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2064</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>064</td>
      <td>Is it possible to only calculate SHAP for a subset of features?</td>
      <td>2021-09-10</td>
      <td>2021-09-10</td>
      <td>714</td>
      <td>714</td>
      <td>NONE</td>
      <td>0</td>
      <td>398.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>988</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>88</td>
      <td>Different results with different output activation function</td>
      <td>2020-01-08</td>
      <td>2020-01-08</td>
      <td>1325</td>
      <td>1325</td>
      <td>NONE</td>
      <td>0</td>
      <td>398.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1933</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>933</td>
      <td>Change labels</td>
      <td>2021-05-27</td>
      <td>2021-05-27</td>
      <td>821</td>
      <td>821</td>
      <td>NONE</td>
      <td>0</td>
      <td>399.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1512</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>512</td>
      <td>AttributeError: 'Explanation' object has no attribute 'cohorts'</td>
      <td>2020-10-15</td>
      <td>2020-11-30</td>
      <td>1045</td>
      <td>999</td>
      <td>NONE</td>
      <td>2</td>
      <td>401.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2562</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>562</td>
      <td>Figures in Documentation are broken links</td>
      <td>2022-10-26</td>
      <td>2023-07-30</td>
      <td>303</td>
      <td>27</td>
      <td>NONE</td>
      <td>1</td>
      <td>402.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1314</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>314</td>
      <td>Main and interaction effects components of SHAP values</td>
      <td>2020-07-14</td>
      <td>2020-08-03</td>
      <td>1138</td>
      <td>1118</td>
      <td>NONE</td>
      <td>1</td>
      <td>402.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1069</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>069</td>
      <td>AttributeError: module 'shap' has no attribute 'group_difference_plot'</td>
      <td>2020-02-27</td>
      <td>2020-08-29</td>
      <td>1276</td>
      <td>1092</td>
      <td>NONE</td>
      <td>2</td>
      <td>402.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1764</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>764</td>
      <td>base_value meaning</td>
      <td>2021-02-09</td>
      <td>2021-04-21</td>
      <td>928</td>
      <td>857</td>
      <td>NONE</td>
      <td>2</td>
      <td>402.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>885</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>85</td>
      <td>shap does not work when eager execution is disabled in tensorflow2</td>
      <td>2019-11-08</td>
      <td>2019-11-12</td>
      <td>1387</td>
      <td>1383</td>
      <td>NONE</td>
      <td>0</td>
      <td>403.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1973</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>973</td>
      <td>nvcc binary could not be located in your $PATH - I have AMD, not NVIDIA, hence I can't install CUDA</td>
      <td>2021-06-28</td>
      <td>2021-06-28</td>
      <td>789</td>
      <td>789</td>
      <td>NONE</td>
      <td>0</td>
      <td>403.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1685</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>685</td>
      <td>Found shape different from x_test shape</td>
      <td>2021-01-11</td>
      <td>2021-01-11</td>
      <td>957</td>
      <td>957</td>
      <td>NONE</td>
      <td>0</td>
      <td>403.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>829</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>29</td>
      <td>ERROR: Files/directories not found in /private/var/folders/7_/g9sfgd811rbfjfz6fwnjzxk80000gp/T/pip-install-oER4Fq/shap/pip-egg-info</td>
      <td>2019-09-24</td>
      <td>2020-09-15</td>
      <td>1432</td>
      <td>1075</td>
      <td>NONE</td>
      <td>16</td>
      <td>405.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2547</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>547</td>
      <td>GradientExplainer seems  can't draw DataParallel</td>
      <td>2022-10-11</td>
      <td>2022-12-27</td>
      <td>319</td>
      <td>242</td>
      <td>NONE</td>
      <td>1</td>
      <td>410.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1607</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>607</td>
      <td>Cannot Get Shap Values after using monotone_constraints argument in Catboost Model</td>
      <td>2020-12-09</td>
      <td>2020-12-09</td>
      <td>989</td>
      <td>989</td>
      <td>NONE</td>
      <td>0</td>
      <td>412.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>856</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>56</td>
      <td>KernelExplainer, Tensorflow / Keras, and multiple inputs</td>
      <td>2019-10-17</td>
      <td>2019-12-16</td>
      <td>1409</td>
      <td>1349</td>
      <td>NONE</td>
      <td>4</td>
      <td>412.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>933</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>33</td>
      <td>base value doesn't show in Force_plot</td>
      <td>2019-12-09</td>
      <td>2020-01-06</td>
      <td>1356</td>
      <td>1328</td>
      <td>NONE</td>
      <td>4</td>
      <td>413.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1059</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>059</td>
      <td>Shape Mismatch in Image_Plot Function for GradientExplainer Example</td>
      <td>2020-02-21</td>
      <td>2020-02-21</td>
      <td>1282</td>
      <td>1281</td>
      <td>NONE</td>
      <td>2</td>
      <td>413.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>307</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>07</td>
      <td>force_plot is cut-off from output field in jupyter notebook</td>
      <td>2018-11-01</td>
      <td>2021-12-07</td>
      <td>1759</td>
      <td>627</td>
      <td>NONE</td>
      <td>4</td>
      <td>413.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1189</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>189</td>
      <td>Question: Is the feature importance ranking computed from dataset applicable to a specific instance?</td>
      <td>2020-04-30</td>
      <td>2020-05-11</td>
      <td>1213</td>
      <td>1202</td>
      <td>NONE</td>
      <td>1</td>
      <td>416.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1989</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>989</td>
      <td>Warning: unrecognized nn.Module: CELU</td>
      <td>2021-07-10</td>
      <td>2021-10-03</td>
      <td>777</td>
      <td>692</td>
      <td>NONE</td>
      <td>1</td>
      <td>418.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2489</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>489</td>
      <td>More explanations about summary plots</td>
      <td>2022-08-25</td>
      <td>2022-08-25</td>
      <td>366</td>
      <td>366</td>
      <td>NONE</td>
      <td>0</td>
      <td>418.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>82</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>2</td>
      <td>Shap interaction values on subset of features</td>
      <td>2018-05-14</td>
      <td>2022-03-04</td>
      <td>1930</td>
      <td>539</td>
      <td>NONE</td>
      <td>3</td>
      <td>420.0</td>
      <td>No</td>
      <td>Issue with 'shape' function and interaction in Series 'title'.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2706</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>706</td>
      <td>Compatibility Issue with Voting Classifier</td>
      <td>2023-04-27</td>
      <td>2023-06-16</td>
      <td>121</td>
      <td>70</td>
      <td>NONE</td>
      <td>1</td>
      <td>422.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>942</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>42</td>
      <td>Documentation of TF Deep Explainer</td>
      <td>2019-12-12</td>
      <td>2020-03-02</td>
      <td>1353</td>
      <td>1272</td>
      <td>NONE</td>
      <td>4</td>
      <td>422.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2234</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>234</td>
      <td>how to save plot from shap.text</td>
      <td>2022-02-03</td>
      <td>2023-02-22</td>
      <td>569</td>
      <td>185</td>
      <td>NONE</td>
      <td>3</td>
      <td>423.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2096</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>096</td>
      <td>Can I scale the SHAP values and interpret the output as a percentage contribution of the prediction?</td>
      <td>2021-10-06</td>
      <td>2021-10-10</td>
      <td>689</td>
      <td>685</td>
      <td>NONE</td>
      <td>1</td>
      <td>424.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1262</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>262</td>
      <td>Pulling Feature Thresholds like LIME explainer.as_list()</td>
      <td>2020-06-11</td>
      <td>2021-01-27</td>
      <td>1170</td>
      <td>941</td>
      <td>NONE</td>
      <td>0</td>
      <td>424.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2300</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>300</td>
      <td>Including \"kernel\" as an algorithm in `Explaine</td>
      <td>2022-03-22</td>
      <td>2022-03-22</td>
      <td>522</td>
      <td>522</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>425.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2085</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>085</td>
      <td>How to calculate SHAP value for one class only?</td>
      <td>2021-09-23</td>
      <td>2021-09-23</td>
      <td>702</td>
      <td>702</td>
      <td>NONE</td>
      <td>0</td>
      <td>425.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1417</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>417</td>
      <td>Visualizations for large numbers of features</td>
      <td>2020-09-09</td>
      <td>2020-09-09</td>
      <td>1080</td>
      <td>1080</td>
      <td>NONE</td>
      <td>1</td>
      <td>426.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1566</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>566</td>
      <td>How do I know if I can increase the probability of predicting a certain value?</td>
      <td>2020-11-18</td>
      <td>2020-11-18</td>
      <td>1011</td>
      <td>1011</td>
      <td>NONE</td>
      <td>0</td>
      <td>427.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>168</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>68</td>
      <td>Should interaction defaults to None in dependence_plot?</td>
      <td>2018-07-21</td>
      <td>2018-07-25</td>
      <td>1862</td>
      <td>1857</td>
      <td>NONE</td>
      <td>1</td>
      <td>427.0</td>
      <td>No</td>
      <td>Issue with interaction in series titled 'title' with shape (1,).</td>
      <td>"Interaction Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2272</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>272</td>
      <td>Saving and Loading DeepExplainer Objects</td>
      <td>2022-03-04</td>
      <td>2023-05-18</td>
      <td>540</td>
      <td>100</td>
      <td>NONE</td>
      <td>3</td>
      <td>429.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2684</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>684</td>
      <td>Error on decision_plot.ipynb</td>
      <td>2023-03-22</td>
      <td>2023-06-16</td>
      <td>157</td>
      <td>70</td>
      <td>NONE</td>
      <td>1</td>
      <td>430.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1914</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>914</td>
      <td>Why TreeExplainer took more execution time for RandomForestClassifier</td>
      <td>2021-05-12</td>
      <td>2021-05-15</td>
      <td>836</td>
      <td>833</td>
      <td>NONE</td>
      <td>0</td>
      <td>430.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>759</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>59</td>
      <td>Question about the calculation of the permutation weights</td>
      <td>2019-08-18</td>
      <td>2019-09-01</td>
      <td>1469</td>
      <td>1454</td>
      <td>NONE</td>
      <td>1</td>
      <td>430.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2246</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>246</td>
      <td>wrong aliases in plotting function</td>
      <td>2022-02-14</td>
      <td>2022-02-14</td>
      <td>558</td>
      <td>558</td>
      <td>NONE</td>
      <td>0</td>
      <td>431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1941</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>941</td>
      <td>Estimated Running Time for DeepExplainer ?</td>
      <td>2021-06-04</td>
      <td>2021-06-04</td>
      <td>813</td>
      <td>813</td>
      <td>NONE</td>
      <td>0</td>
      <td>431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>504</td>
      <td><a href="https://github.com/shap/shap/issues/51">51</a>4</td>
      <td>Sub feature importance</td>
      <td>2019-03-23</td>
      <td>2019-03-29</td>
      <td>1617</td>
      <td>1610</td>
      <td>NONE</td>
      <td>2</td>
      <td>432.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>232</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>32</td>
      <td>Error in Census income classification with LightGBM</td>
      <td>2018-08-21</td>
      <td>2018-08-23</td>
      <td>1831</td>
      <td>1829</td>
      <td>NONE</td>
      <td>6</td>
      <td>433.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1374</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>374</td>
      <td>Attribute error: Module \"shap\" has no attribute KernelExplain</td>
      <td>2020-08-19</td>
      <td>2020-08-25</td>
      <td>1101</td>
      <td>1095</td>
      <td>NONE</td>
      <td>1</td>
      <td>435.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1830</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>830</td>
      <td>Multi-objective model : TypeError: list indices must be integers or slices, not tuple</td>
      <td>2021-03-22</td>
      <td>2021-03-22</td>
      <td>886</td>
      <td>886</td>
      <td>NONE</td>
      <td>0</td>
      <td>436.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2724</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>724</td>
      <td>cext_gpu error</td>
      <td>2023-05-18</td>
      <td>2023-07-07</td>
      <td>99</td>
      <td>50</td>
      <td>NONE</td>
      <td>2</td>
      <td>436.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>998</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>98</td>
      <td>How to get list of features from force plot?</td>
      <td>2020-01-15</td>
      <td>2020-11-18</td>
      <td>1319</td>
      <td>1011</td>
      <td>NONE</td>
      <td>4</td>
      <td>437.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>894</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>94</td>
      <td>model missing predict_proba</td>
      <td>2019-11-12</td>
      <td>2020-07-08</td>
      <td>1382</td>
      <td>1143</td>
      <td>NONE</td>
      <td>1</td>
      <td>437.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1022</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>022</td>
      <td>Modelling piecewise function</td>
      <td>2020-01-30</td>
      <td>2020-01-31</td>
      <td>1304</td>
      <td>1302</td>
      <td>NONE</td>
      <td>1</td>
      <td>437.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1325</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>325</td>
      <td>Multiple Classes - only gives you a single class</td>
      <td>2020-07-21</td>
      <td>2020-08-03</td>
      <td>1131</td>
      <td>1118</td>
      <td>NONE</td>
      <td>1</td>
      <td>438.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2413</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>413</td>
      <td>shap_interaction_values for KernelExplainer</td>
      <td>2022-06-06</td>
      <td>2022-08-26</td>
      <td>446</td>
      <td>365</td>
      <td>NONE</td>
      <td>2</td>
      <td>439.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1999</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>999</td>
      <td>Does SHAP approximate method return Shapley values at all?</td>
      <td>2021-07-16</td>
      <td>2021-07-16</td>
      <td>771</td>
      <td>771</td>
      <td>NONE</td>
      <td>0</td>
      <td>440.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2437</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>437</td>
      <td>Unrecognized Model</td>
      <td>2022-06-23</td>
      <td>2023-08-13</td>
      <td>429</td>
      <td>13</td>
      <td>NONE</td>
      <td>2</td>
      <td>441.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1358</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>358</td>
      <td>What does display = true do</td>
      <td>2020-08-11</td>
      <td>2020-08-11</td>
      <td>1109</td>
      <td>1109</td>
      <td>NONE</td>
      <td>0</td>
      <td>441.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1402</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>402</td>
      <td>Get SHAP running with Angular 2.x</td>
      <td>2020-09-02</td>
      <td>2020-09-09</td>
      <td>1088</td>
      <td>1080</td>
      <td>NONE</td>
      <td>1</td>
      <td>442.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1389</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>389</td>
      <td>DeepExplainer: how to load a Tensorflow CNN model(.pb file)</td>
      <td>2020-08-29</td>
      <td>2021-11-10</td>
      <td>1092</td>
      <td>654</td>
      <td>NONE</td>
      <td>4</td>
      <td>442.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>58</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a></td>
      <td>default to violin in summary_plot</td>
      <td>2018-04-17</td>
      <td>2019-12-06</td>
      <td>1956</td>
      <td>1358</td>
      <td>CONTRIBUTOR</td>
      <td>7</td>
      <td>443.0</td>
      <td>No</td>
      <td>Issue relates to default value of 'violet' in 'slundberg'.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>502</td>
      <td><a href="https://github.com/shap/shap/issues/51">51</a>2</td>
      <td>No module named 'xgboost'</td>
      <td>2019-03-21</td>
      <td>2019-08-07</td>
      <td>1619</td>
      <td>1480</td>
      <td>NONE</td>
      <td>3</td>
      <td>444.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1250</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>250</td>
      <td>Support of string inputs for tensorflow DeepExplainer</td>
      <td>2020-06-04</td>
      <td>2020-06-04</td>
      <td>1177</td>
      <td>1177</td>
      <td>NONE</td>
      <td>0</td>
      <td>445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2282</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>282</td>
      <td>Details about Shapley Kernel Proof</td>
      <td>2022-03-15</td>
      <td>2022-03-15</td>
      <td>529</td>
      <td>529</td>
      <td>NONE</td>
      <td>0</td>
      <td>445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1844</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>844</td>
      <td>Hierarchical feature clusterings</td>
      <td>2021-03-30</td>
      <td>2021-03-30</td>
      <td>879</td>
      <td>879</td>
      <td>NONE</td>
      <td>0</td>
      <td>447.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>566</td>
      <td><a href="https://github.com/shap/shap/issues/567">567</a></td>
      <td>Question algorithm tree shap</td>
      <td>2019-04-28</td>
      <td>2019-04-28</td>
      <td>1581</td>
      <td>1581</td>
      <td>NONE</td>
      <td>0</td>
      <td>449.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>88</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>8</td>
      <td>Interaction plot does not work for sklearn RandomForestRegressor</td>
      <td>2018-05-17</td>
      <td>2018-05-17</td>
      <td>1927</td>
      <td>1927</td>
      <td>NONE</td>
      <td>1</td>
      <td>449.0</td>
      <td>No</td>
      <td>"User experiencing issues with interaction in a trained random series."</td>
      <td>"Data Shape"</td>
      <td>'bug'</td>
    </tr>
    <tr>
      <td>563</td>
      <td><a href="https://github.com/shap/shap/issues/564">564</a></td>
      <td>UnicodeDecodeError: 'charmap' codec can't decode</td>
      <td>2019-04-25</td>
      <td>2021-06-25</td>
      <td>1583</td>
      <td>792</td>
      <td>NONE</td>
      <td>1</td>
      <td>450.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1213</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>213</td>
      <td>Shap Force Plot does not show all the feature value/names</td>
      <td>2020-05-17</td>
      <td>2020-05-24</td>
      <td>1196</td>
      <td>1189</td>
      <td>NONE</td>
      <td>0</td>
      <td>451.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1487</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>487</td>
      <td>Calculating SHAP values for large dataset</td>
      <td>2020-10-03</td>
      <td>2021-10-19</td>
      <td>1057</td>
      <td>676</td>
      <td>NONE</td>
      <td>4</td>
      <td>452.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1875</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>875</td>
      <td>I/O problems when saving a notebook with a summary plot</td>
      <td>2021-04-20</td>
      <td>2021-04-20</td>
      <td>857</td>
      <td>857</td>
      <td>NONE</td>
      <td>0</td>
      <td>453.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1175</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>175</td>
      <td>XGBoost : How to get predictions from Shap Value when objective is reg : tweedie</td>
      <td>2020-04-25</td>
      <td>2020-04-26</td>
      <td>1218</td>
      <td>1217</td>
      <td>NONE</td>
      <td>1</td>
      <td>453.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1265</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>265</td>
      <td>comparing two XGBoost models</td>
      <td>2020-06-12</td>
      <td>2020-10-28</td>
      <td>1170</td>
      <td>1032</td>
      <td>NONE</td>
      <td>0</td>
      <td>453.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1851</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>851</td>
      <td>Explain CNN for time series classification - possible?</td>
      <td>2021-04-03</td>
      <td>2021-04-16</td>
      <td>875</td>
      <td>862</td>
      <td>NONE</td>
      <td>4</td>
      <td>453.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2397</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>397</td>
      <td>How to explain only on input in a multimodal architecture</td>
      <td>2022-05-24</td>
      <td>2023-03-07</td>
      <td>459</td>
      <td>172</td>
      <td>NONE</td>
      <td>2</td>
      <td>454.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1431</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>431</td>
      <td>Code for summary_plot</td>
      <td>2020-09-15</td>
      <td>2022-05-09</td>
      <td>1075</td>
      <td>474</td>
      <td>NONE</td>
      <td>3</td>
      <td>454.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2934</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>934</td>
      <td>ENH: SHAP in PySpark ML models</td>
      <td>2023-08-16</td>
      <td>2023-08-16</td>
      <td>10</td>
      <td>10</td>
      <td>NONE</td>
      <td>1</td>
      <td>455.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1568</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>568</td>
      <td>xgboost not installed in binder env</td>
      <td>2020-11-18</td>
      <td>2020-11-20</td>
      <td>1010</td>
      <td>1008</td>
      <td>NONE</td>
      <td>2</td>
      <td>455.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>459</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>59</td>
      <td>Prediction from shap.force_plot not equal to actual prediction</td>
      <td>2019-02-25</td>
      <td>2019-05-24</td>
      <td>1643</td>
      <td>1555</td>
      <td>NONE</td>
      <td>5</td>
      <td>455.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1044</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>044</td>
      <td>SHAP for multiclass classification problem</td>
      <td>2020-02-13</td>
      <td>2020-02-13</td>
      <td>1290</td>
      <td>1290</td>
      <td>NONE</td>
      <td>0</td>
      <td>456.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>106</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>06</td>
      <td>question about kmean</td>
      <td>2018-06-05</td>
      <td>2018-06-15</td>
      <td>1907</td>
      <td>1897</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>457.0</td>
      <td>No</td>
      <td>"Question about the title's series issue with body's shape."</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1351</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>351</td>
      <td>Conspicuousness with discrete input variables</td>
      <td>2020-08-07</td>
      <td>2020-08-07</td>
      <td>1114</td>
      <td>1114</td>
      <td>NONE</td>
      <td>0</td>
      <td>458.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2629</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>629</td>
      <td>Front Page DeepExplainer MNIST Example is broken</td>
      <td>2023-01-02</td>
      <td>2023-07-27</td>
      <td>236</td>
      <td>30</td>
      <td>NONE</td>
      <td>1</td>
      <td>459.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2793</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>793</td>
      <td>ENH: The linearExplaner model currently supports only sklearn-style code. However, it is possible to add support for torch.nn functionality to the linear interpreter model.</td>
      <td>2023-06-22</td>
      <td>2023-06-23</td>
      <td>65</td>
      <td>64</td>
      <td>NONE</td>
      <td>1</td>
      <td>460.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1726</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>726</td>
      <td>Splitting of words in image captions by tokenizer</td>
      <td>2021-01-21</td>
      <td>2021-01-21</td>
      <td>946</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>461.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1379</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>379</td>
      <td>SHAP Decision Plot X-Axis meaning for regression</td>
      <td>2020-08-24</td>
      <td>2020-08-29</td>
      <td>1097</td>
      <td>1092</td>
      <td>NONE</td>
      <td>5</td>
      <td>463.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2340</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>340</td>
      <td>SHAP Summary Plot rendering problem (jupyter lab)</td>
      <td>2022-04-08</td>
      <td>2022-04-14</td>
      <td>504</td>
      <td>499</td>
      <td>NONE</td>
      <td>3</td>
      <td>463.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1372</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>372</td>
      <td>Exception: Model type not yet supported by TreeExplainer: &lt;class 'sklearn.pipeline.Pipeline'&gt;</td>
      <td>2020-08-19</td>
      <td>2023-04-03</td>
      <td>1102</td>
      <td>145</td>
      <td>NONE</td>
      <td>12</td>
      <td>466.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1426</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>426</td>
      <td>Inconsistent SHAP values for the same record passed in with different data types</td>
      <td>2020-09-11</td>
      <td>2020-09-11</td>
      <td>1078</td>
      <td>1078</td>
      <td>NONE</td>
      <td>0</td>
      <td>467.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>570</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>0</td>
      <td>SHAP components count error in scala xgboost</td>
      <td>2019-05-01</td>
      <td>2019-05-01</td>
      <td>1578</td>
      <td>1577</td>
      <td>NONE</td>
      <td>1</td>
      <td>467.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2467</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>467</td>
      <td>How to quantify the relationships in SHAP dependence plot?</td>
      <td>2022-08-02</td>
      <td>2022-08-02</td>
      <td>389</td>
      <td>389</td>
      <td>NONE</td>
      <td>0</td>
      <td>467.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2126</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>126</td>
      <td>How to generate shap values using part of the transformer sentiment analysis scores?</td>
      <td>2021-11-03</td>
      <td>2021-11-03</td>
      <td>661</td>
      <td>661</td>
      <td>NONE</td>
      <td>0</td>
      <td>468.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>337</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>37</td>
      <td>TreeExplainer support for balance ensembles from imblearn</td>
      <td>2018-11-25</td>
      <td>2022-11-22</td>
      <td>1735</td>
      <td>276</td>
      <td>NONE</td>
      <td>6</td>
      <td>470.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2899</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>899</td>
      <td>ENH: add more detailed build instructions, including CUDA and C++ compilation</td>
      <td>2023-07-28</td>
      <td>2023-07-28</td>
      <td>29</td>
      <td>29</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>470.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>832</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>32</td>
      <td>Why do we use Training Data for Shap, instead of Test Data</td>
      <td>2019-09-25</td>
      <td>2022-08-06</td>
      <td>1430</td>
      <td>385</td>
      <td>NONE</td>
      <td>2</td>
      <td>471.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2287</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>287</td>
      <td>SHAP with multi-input multi-output classification</td>
      <td>2022-03-16</td>
      <td>2022-03-16</td>
      <td>528</td>
      <td>528</td>
      <td>NONE</td>
      <td>0</td>
      <td>471.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>631</td>
      <td><a href="https://github.com/shap/shap/issues/64">64</a>1</td>
      <td>how to extract the most important feature names ?</td>
      <td>2019-06-06</td>
      <td>2023-03-08</td>
      <td>1542</td>
      <td>171</td>
      <td>NONE</td>
      <td>28</td>
      <td>472.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1510</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>510</td>
      <td>AttributeError: 'Explanation' object has no attribute '_old_format'</td>
      <td>2020-10-14</td>
      <td>2022-11-29</td>
      <td>1046</td>
      <td>270</td>
      <td>NONE</td>
      <td>9</td>
      <td>472.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1976</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>976</td>
      <td>Feature importance ranking for linear classifier with SHAP</td>
      <td>2021-06-30</td>
      <td>2021-06-30</td>
      <td>786</td>
      <td>786</td>
      <td>NONE</td>
      <td>0</td>
      <td>473.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>601</td>
      <td><a href="https://github.com/shap/shap/issues/61">61</a>1</td>
      <td>force plots: text rotation in html</td>
      <td>2019-05-22</td>
      <td>2023-08-26</td>
      <td>1557</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>473.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1859</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>859</td>
      <td>Help new man! about \"shap.dependence_plot</td>
      <td>2021-04-08</td>
      <td>2021-04-08</td>
      <td>870</td>
      <td>870</td>
      <td>NONE</td>
      <td>0</td>
      <td>474.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>537</td>
      <td><a href="https://github.com/shap/shap/issues/54">54</a>7</td>
      <td>Magnitude of SHAP Values Favoring Larger Magnitude Predictions?</td>
      <td>2019-04-08</td>
      <td>2019-04-08</td>
      <td>1601</td>
      <td>1600</td>
      <td>NONE</td>
      <td>12</td>
      <td>475.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2458</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>458</td>
      <td>Unable to import SmartExplainer. Running into ModuleNotFoundError: No module named 'tkinter' error</td>
      <td>2022-07-19</td>
      <td>2022-07-30</td>
      <td>403</td>
      <td>391</td>
      <td>NONE</td>
      <td>2</td>
      <td>475.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>371</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>71</td>
      <td>shap_values = explainer.shap_values(X_test) is a cumbersome training</td>
      <td>2018-12-30</td>
      <td>2018-12-30</td>
      <td>1700</td>
      <td>1699</td>
      <td>NONE</td>
      <td>1</td>
      <td>477.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>438</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>38</td>
      <td>how to process mutli-input model using DeepExplainer</td>
      <td>2019-02-12</td>
      <td>2022-09-29</td>
      <td>1656</td>
      <td>331</td>
      <td>NONE</td>
      <td>10</td>
      <td>479.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1300</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>300</td>
      <td>TreeExplainer warning shows regardless of the perturbation setting</td>
      <td>2020-07-07</td>
      <td>2020-07-07</td>
      <td>1145</td>
      <td>1145</td>
      <td>NONE</td>
      <td>1</td>
      <td>480.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1766</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>766</td>
      <td>Force Plot blocking browser with nan values</td>
      <td>2021-02-10</td>
      <td>2021-02-10</td>
      <td>927</td>
      <td>927</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>482.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>755</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>55</td>
      <td>Plot summary_plot as probabilities</td>
      <td>2019-08-17</td>
      <td>2019-08-18</td>
      <td>1470</td>
      <td>1469</td>
      <td>NONE</td>
      <td>2</td>
      <td>482.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1743</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>743</td>
      <td>weird force plot and overlapping problem</td>
      <td>2021-01-27</td>
      <td>2021-01-27</td>
      <td>941</td>
      <td>941</td>
      <td>NONE</td>
      <td>0</td>
      <td>483.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1440</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>440</td>
      <td>Shap Interaction</td>
      <td>2020-09-18</td>
      <td>2020-09-18</td>
      <td>1072</td>
      <td>1072</td>
      <td>NONE</td>
      <td>0</td>
      <td>486.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>803</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>03</td>
      <td>Summary plot and force plot doesn't show the entire features selection</td>
      <td>2019-09-10</td>
      <td>2019-09-10</td>
      <td>1446</td>
      <td>1446</td>
      <td>NONE</td>
      <td>2</td>
      <td>486.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1363</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>363</td>
      <td>Unable to use fasttext models for Multiclass Text Classification with SHAP for Interpretability.</td>
      <td>2020-08-14</td>
      <td>2023-01-03</td>
      <td>1107</td>
      <td>235</td>
      <td>NONE</td>
      <td>1</td>
      <td>486.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1997</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>997</td>
      <td>Light GBM: Prediction from shap.force_plot not equal to actual prediction</td>
      <td>2021-07-15</td>
      <td>2021-07-15</td>
      <td>772</td>
      <td>772</td>
      <td>NONE</td>
      <td>1</td>
      <td>486.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2609</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>609</td>
      <td>SHAP on data modeled with eras timeseries_dataset_from_array data structure</td>
      <td>2022-12-12</td>
      <td>2022-12-20</td>
      <td>256</td>
      <td>248</td>
      <td>NONE</td>
      <td>1</td>
      <td>486.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1318</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>318</td>
      <td>Support for TensorflowExtended (TFX) Keras model and tfrecords input?</td>
      <td>2020-07-18</td>
      <td>2021-02-04</td>
      <td>1133</td>
      <td>933</td>
      <td>NONE</td>
      <td>1</td>
      <td>488.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1230</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>230</td>
      <td>Force plot visual not working in Pycharm</td>
      <td>2020-05-26</td>
      <td>2021-02-02</td>
      <td>1187</td>
      <td>935</td>
      <td>NONE</td>
      <td>1</td>
      <td>489.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1207</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>207</td>
      <td>scikit-learn&gt;=0.22.0 tree models not supported by TreeExplainer</td>
      <td>2020-05-13</td>
      <td>2020-05-13</td>
      <td>1200</td>
      <td>1200</td>
      <td>NONE</td>
      <td>0</td>
      <td>489.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1627</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>627</td>
      <td>Extracting the relative weights of shap values for each class in multi-output problem</td>
      <td>2020-12-16</td>
      <td>2020-12-16</td>
      <td>982</td>
      <td>982</td>
      <td>NONE</td>
      <td>0</td>
      <td>490.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1341</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>341</td>
      <td>shap interaction values with one hot encodings</td>
      <td>2020-08-03</td>
      <td>2020-08-04</td>
      <td>1118</td>
      <td>1117</td>
      <td>NONE</td>
      <td>2</td>
      <td>492.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1780</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>780</td>
      <td>SHAP values don't sum to the predicted value in lightgbm regression</td>
      <td>2021-02-18</td>
      <td>2021-03-25</td>
      <td>918</td>
      <td>884</td>
      <td>NONE</td>
      <td>2</td>
      <td>493.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2685</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>685</td>
      <td>The SHAP library modifies the input tokens of T5 tokeniser and add extra character</td>
      <td>2023-03-23</td>
      <td>2023-06-17</td>
      <td>156</td>
      <td>70</td>
      <td>NONE</td>
      <td>4</td>
      <td>493.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2385</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>385</td>
      <td>Adding reproducible behavior to shap_values computation with Permutation explainer</td>
      <td>2022-05-13</td>
      <td>2022-05-13</td>
      <td>470</td>
      <td>470</td>
      <td>NONE</td>
      <td>0</td>
      <td>494.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>508</td>
      <td><a href="https://github.com/shap/shap/issues/51">51</a>8</td>
      <td>inconsistent base value in shap.force_plot</td>
      <td>2019-03-24</td>
      <td>2023-08-26</td>
      <td>1616</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>497.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2003</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>003</td>
      <td>Tree SHAP Sum of SHAP Values</td>
      <td>2021-07-18</td>
      <td>2021-07-22</td>
      <td>769</td>
      <td>764</td>
      <td>NONE</td>
      <td>1</td>
      <td>497.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1231</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>231</td>
      <td>Is it possible to not discretize continous values when using kernel explainer.</td>
      <td>2020-05-26</td>
      <td>2020-05-26</td>
      <td>1187</td>
      <td>1187</td>
      <td>NONE</td>
      <td>0</td>
      <td>497.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1526</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>526</td>
      <td>DeepExplainer Shap sums do not add up to model prediction</td>
      <td>2020-10-26</td>
      <td>2021-04-07</td>
      <td>1034</td>
      <td>871</td>
      <td>NONE</td>
      <td>1</td>
      <td>501.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1468</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>468</td>
      <td>SHAP doesn't work if log-normal ngboost</td>
      <td>2020-09-25</td>
      <td>2020-09-25</td>
      <td>1065</td>
      <td>1065</td>
      <td>NONE</td>
      <td>0</td>
      <td>502.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1783</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>783</td>
      <td>Summary plot doesn't contain all values</td>
      <td>2021-02-19</td>
      <td>2021-02-19</td>
      <td>918</td>
      <td>918</td>
      <td>NONE</td>
      <td>0</td>
      <td>503.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2288</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>288</td>
      <td>Scatter plot with NaNs in the interacting feature as color yields missing dots</td>
      <td>2022-03-16</td>
      <td>2022-03-16</td>
      <td>528</td>
      <td>528</td>
      <td>NONE</td>
      <td>0</td>
      <td>504.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1378</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>378</td>
      <td>Exception: Model type not yet supported by TreeExplainer: &lt;class 'sklearn.ensemble._forest.RandomForestRegressor'&gt;</td>
      <td>2020-08-24</td>
      <td>2022-08-23</td>
      <td>1097</td>
      <td>368</td>
      <td>NONE</td>
      <td>5</td>
      <td>506.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2163</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>163</td>
      <td>SHAP interpretation for image to image CNN (regression)</td>
      <td>2021-12-01</td>
      <td>2021-12-01</td>
      <td>633</td>
      <td>633</td>
      <td>NONE</td>
      <td>0</td>
      <td>508.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1384</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>384</td>
      <td>Follow up question on TreeSHAP runtime (KDD presentation 2020)</td>
      <td>2020-08-26</td>
      <td>2022-06-23</td>
      <td>1094</td>
      <td>429</td>
      <td>NONE</td>
      <td>5</td>
      <td>509.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1716</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>716</td>
      <td>shap.plots.image showing transposed image</td>
      <td>2021-01-19</td>
      <td>2021-01-19</td>
      <td>948</td>
      <td>948</td>
      <td>NONE</td>
      <td>0</td>
      <td>509.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2573</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>573</td>
      <td>SHAP Image Explainer</td>
      <td>2022-11-10</td>
      <td>2022-11-10</td>
      <td>289</td>
      <td>289</td>
      <td>NONE</td>
      <td>0</td>
      <td>511.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1798</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>798</td>
      <td>multi-class Random Forest raw shap values interpretation</td>
      <td>2021-03-03</td>
      <td>2021-03-03</td>
      <td>906</td>
      <td>906</td>
      <td>NONE</td>
      <td>1</td>
      <td>511.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2245</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>245</td>
      <td>'Explanation' object has no attribute 'conjugate'</td>
      <td>2022-02-14</td>
      <td>2022-10-04</td>
      <td>558</td>
      <td>326</td>
      <td>NONE</td>
      <td>3</td>
      <td>512.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>207</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>07</td>
      <td>tree_limit shap_values kill notebook</td>
      <td>2018-08-08</td>
      <td>2018-10-03</td>
      <td>1844</td>
      <td>1788</td>
      <td>NONE</td>
      <td>8</td>
      <td>512.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>586</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a>6</td>
      <td>Allow Softmax Option</td>
      <td>2019-05-13</td>
      <td>2019-05-14</td>
      <td>1566</td>
      <td>1564</td>
      <td>NONE</td>
      <td>2</td>
      <td>512.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1416</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>416</td>
      <td>No module named 'shap.explainers.tree' when using SHAP with LightGBM in Azure Function</td>
      <td>2020-09-09</td>
      <td>2021-02-05</td>
      <td>1081</td>
      <td>932</td>
      <td>NONE</td>
      <td>13</td>
      <td>515.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2069</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>069</td>
      <td>Zero shap values for complex-valued neural network in Pytorch</td>
      <td>2021-09-15</td>
      <td>2021-09-15</td>
      <td>710</td>
      <td>710</td>
      <td>NONE</td>
      <td>1</td>
      <td>515.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>815</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>15</td>
      <td>compute ship values for Gaussian process models.</td>
      <td>2019-09-20</td>
      <td>2019-09-20</td>
      <td>1436</td>
      <td>1436</td>
      <td>NONE</td>
      <td>0</td>
      <td>515.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2266</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>266</td>
      <td>Calculate the SHAP values for stacking ensemble model</td>
      <td>2022-02-27</td>
      <td>2023-02-10</td>
      <td>545</td>
      <td>196</td>
      <td>NONE</td>
      <td>4</td>
      <td>516.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1409</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>409</td>
      <td>Column ordering shap values</td>
      <td>2020-09-03</td>
      <td>2020-09-09</td>
      <td>1086</td>
      <td>1080</td>
      <td>NONE</td>
      <td>1</td>
      <td>517.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1868</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>868</td>
      <td>Missing explainers from shap.readthedocs.io</td>
      <td>2021-04-14</td>
      <td>2021-04-14</td>
      <td>863</td>
      <td>863</td>
      <td>NONE</td>
      <td>0</td>
      <td>519.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>951</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>51</td>
      <td>Linear explainer: Background of the \"_estimate_transforms\" functi</td>
      <td>2019-12-13</td>
      <td>2019-12-13</td>
      <td>1352</td>
      <td>1352</td>
      <td>NONE</td>
      <td>1</td>
      <td>520.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1917</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>917</td>
      <td>Is shap able to give shap values for tensors inside the model?</td>
      <td>2021-05-15</td>
      <td>2021-05-15</td>
      <td>833</td>
      <td>833</td>
      <td>NONE</td>
      <td>0</td>
      <td>520.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1438</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>438</td>
      <td>Make shap.datasets return Slicer objects</td>
      <td>2020-09-17</td>
      <td>2020-09-17</td>
      <td>1073</td>
      <td>1073</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>523.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1964</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>964</td>
      <td>Shap values = nan for the most important feature</td>
      <td>2021-06-21</td>
      <td>2021-06-21</td>
      <td>796</td>
      <td>796</td>
      <td>NONE</td>
      <td>0</td>
      <td>523.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2079</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>079</td>
      <td>TypeError: shapplot() got an unexpected keyword argument 'feature_names'</td>
      <td>2021-09-20</td>
      <td>2021-09-20</td>
      <td>705</td>
      <td>705</td>
      <td>NONE</td>
      <td>0</td>
      <td>524.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1956</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>956</td>
      <td>Notebook showing javascript error instead of force plots</td>
      <td>2021-06-15</td>
      <td>2021-06-15</td>
      <td>802</td>
      <td>802</td>
      <td>NONE</td>
      <td>0</td>
      <td>524.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>941</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>41</td>
      <td>The outpout of shape_values are all zeros.</td>
      <td>2019-12-12</td>
      <td>2021-08-13</td>
      <td>1353</td>
      <td>742</td>
      <td>NONE</td>
      <td>3</td>
      <td>524.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2075</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>075</td>
      <td>Error in Explaining a linear regression model?</td>
      <td>2021-09-17</td>
      <td>2022-01-19</td>
      <td>708</td>
      <td>584</td>
      <td>NONE</td>
      <td>1</td>
      <td>525.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1245</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>245</td>
      <td>non-column features with SHAP</td>
      <td>2020-06-03</td>
      <td>2021-03-23</td>
      <td>1179</td>
      <td>886</td>
      <td>NONE</td>
      <td>1</td>
      <td>529.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2068</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>068</td>
      <td>Using SHAP for U-Net real-valued image predictions</td>
      <td>2021-09-14</td>
      <td>2021-09-28</td>
      <td>710</td>
      <td>696</td>
      <td>NONE</td>
      <td>2</td>
      <td>530.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1820</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>820</td>
      <td>Issue in shap.Explainer</td>
      <td>2021-03-13</td>
      <td>2021-04-21</td>
      <td>896</td>
      <td>856</td>
      <td>NONE</td>
      <td>1</td>
      <td>530.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2164</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>164</td>
      <td>GPUTree: model_output='probability' not working</td>
      <td>2021-12-01</td>
      <td>2021-12-01</td>
      <td>633</td>
      <td>633</td>
      <td>NONE</td>
      <td>0</td>
      <td>532.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1927</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>927</td>
      <td>Missing requirement: matplotlib</td>
      <td>2021-05-24</td>
      <td>2021-05-24</td>
      <td>824</td>
      <td>824</td>
      <td>NONE</td>
      <td>0</td>
      <td>532.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>174</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>74</td>
      <td>Question about missingness</td>
      <td>2018-07-23</td>
      <td>2023-02-07</td>
      <td>1860</td>
      <td>200</td>
      <td>NONE</td>
      <td>16</td>
      <td>532.0</td>
      <td>No</td>
      <td>"User questions regarding series 'title' and 'body' shapes."</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2343</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>343</td>
      <td>[Tree Explainer] shap.TreeExplainer.expected_value meaning</td>
      <td>2022-04-13</td>
      <td>2022-04-18</td>
      <td>500</td>
      <td>495</td>
      <td>NONE</td>
      <td>1</td>
      <td>533.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>692</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>2</td>
      <td>unable to import shap due to reaction with dependencies scikit-image &amp; numpy</td>
      <td>2019-07-10</td>
      <td>2022-08-09</td>
      <td>1508</td>
      <td>382</td>
      <td>NONE</td>
      <td>2</td>
      <td>536.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1519</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>519</td>
      <td>Heatmap for multi-class problems</td>
      <td>2020-10-22</td>
      <td>2020-10-22</td>
      <td>1038</td>
      <td>1038</td>
      <td>NONE</td>
      <td>0</td>
      <td>536.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1137</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>137</td>
      <td>Problem with interpretation.</td>
      <td>2020-04-05</td>
      <td>2020-04-14</td>
      <td>1238</td>
      <td>1229</td>
      <td>NONE</td>
      <td>1</td>
      <td>537.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1490</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>490</td>
      <td>using shap index in keras regression problem</td>
      <td>2020-10-06</td>
      <td>2020-10-06</td>
      <td>1054</td>
      <td>1054</td>
      <td>NONE</td>
      <td>0</td>
      <td>539.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>921</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>21</td>
      <td>some question about weird output value and base value</td>
      <td>2019-12-02</td>
      <td>2019-12-24</td>
      <td>1363</td>
      <td>1341</td>
      <td>NONE</td>
      <td>11</td>
      <td>539.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2092</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>092</td>
      <td>Why can force_plot return probabilites while TreeExplainer.shap_values can't?</td>
      <td>2021-10-04</td>
      <td>2021-11-23</td>
      <td>691</td>
      <td>641</td>
      <td>NONE</td>
      <td>1</td>
      <td>541.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2355</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>355</td>
      <td>Shap with multi-class classification</td>
      <td>2022-04-20</td>
      <td>2022-04-23</td>
      <td>492</td>
      <td>490</td>
      <td>NONE</td>
      <td>2</td>
      <td>545.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2289</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>289</td>
      <td>Conflict with XGBoost 1.0.1 version for input feature categories</td>
      <td>2022-03-17</td>
      <td>2022-03-21</td>
      <td>527</td>
      <td>523</td>
      <td>NONE</td>
      <td>1</td>
      <td>546.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2579</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>579</td>
      <td>Opencv error while running the tutorial--\"Explain PyTorch MobileNetV2 using the Partition explainer</td>
      <td>2022-11-13</td>
      <td>2023-07-27</td>
      <td>286</td>
      <td>30</td>
      <td>NONE</td>
      <td>2</td>
      <td>546.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2582</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>582</td>
      <td>The SHAP explanations do not sum up to the model's output!</td>
      <td>2022-11-14</td>
      <td>2022-11-16</td>
      <td>285</td>
      <td>283</td>
      <td>NONE</td>
      <td>1</td>
      <td>547.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>13</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>3</td>
      <td>Tree SHAP for random forests?</td>
      <td>2018-01-14</td>
      <td>2023-01-13</td>
      <td>2050</td>
      <td>225</td>
      <td>NONE</td>
      <td>13</td>
      <td>548.0</td>
      <td>No</td>
      <td>"User requesting for implementation guidance on Tree SHAP feature."</td>
      <td>"Tree SHAP"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1520</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>520</td>
      <td>Use shap.plots.text() with sklearn objects</td>
      <td>2020-10-22</td>
      <td>2022-11-23</td>
      <td>1037</td>
      <td>276</td>
      <td>NONE</td>
      <td>2</td>
      <td>548.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1652</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>652</td>
      <td>Assumptions of DeepExplainer and GradientExplainer</td>
      <td>2020-12-22</td>
      <td>2021-02-24</td>
      <td>977</td>
      <td>913</td>
      <td>NONE</td>
      <td>1</td>
      <td>550.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>105</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>05</td>
      <td>Generalised pairsplot about Shap diagnostic steps?</td>
      <td>2018-06-01</td>
      <td>2018-06-04</td>
      <td>1912</td>
      <td>1908</td>
      <td>NONE</td>
      <td>1</td>
      <td>551.0</td>
      <td>No</td>
      <td>Issue with generalised pairsplots in 'title' and 'body' series shapes.</td>
      <td>"Series Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1302</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>302</td>
      <td>l1_reg=\"auto\" warning in KernelShap is outdat</td>
      <td>2020-07-09</td>
      <td>2020-08-11</td>
      <td>1143</td>
      <td>1110</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>551.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2244</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>244</td>
      <td>Add functionality for passing non-feature arguments to models through the explainer</td>
      <td>2022-02-13</td>
      <td>2022-02-13</td>
      <td>559</td>
      <td>559</td>
      <td>NONE</td>
      <td>0</td>
      <td>551.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2189</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>189</td>
      <td>shap_values slice broken</td>
      <td>2021-12-16</td>
      <td>2022-02-10</td>
      <td>618</td>
      <td>562</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>552.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2434</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>434</td>
      <td>The hard bound on Packaging module's (&gt; 20.9) version</td>
      <td>2022-06-22</td>
      <td>2022-06-22</td>
      <td>430</td>
      <td>430</td>
      <td>NONE</td>
      <td>0</td>
      <td>555.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1152</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>152</td>
      <td>RuntimeError: The size of tensor a must match the size of tensor b</td>
      <td>2020-04-14</td>
      <td>2022-04-21</td>
      <td>1229</td>
      <td>492</td>
      <td>NONE</td>
      <td>5</td>
      <td>555.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1789</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>789</td>
      <td>Regarding making shap values into probabilities</td>
      <td>2021-02-24</td>
      <td>2021-02-24</td>
      <td>913</td>
      <td>913</td>
      <td>NONE</td>
      <td>0</td>
      <td>557.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2083</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>083</td>
      <td>When is a new version expected?</td>
      <td>2021-09-22</td>
      <td>2021-09-22</td>
      <td>703</td>
      <td>703</td>
      <td>NONE</td>
      <td>0</td>
      <td>557.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1315</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>315</td>
      <td>Establish if overall feature contribution is positive or negative wrt target</td>
      <td>2020-07-14</td>
      <td>2020-07-14</td>
      <td>1138</td>
      <td>1138</td>
      <td>NONE</td>
      <td>0</td>
      <td>559.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2771</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>771</td>
      <td>ENH: Add support for pytorch embedding layers</td>
      <td>2023-06-15</td>
      <td>2023-08-22</td>
      <td>72</td>
      <td>3</td>
      <td>NONE</td>
      <td>1</td>
      <td>559.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2072</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>072</td>
      <td>SHAP for Segmentation models</td>
      <td>2021-09-15</td>
      <td>2023-08-26</td>
      <td>710</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>562.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1740</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>740</td>
      <td>Shap loss for regression problems</td>
      <td>2021-01-26</td>
      <td>2023-03-24</td>
      <td>941</td>
      <td>155</td>
      <td>NONE</td>
      <td>4</td>
      <td>562.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2583</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>583</td>
      <td>Force plot cmap not applied when matplotlib=True</td>
      <td>2022-11-15</td>
      <td>2022-11-15</td>
      <td>284</td>
      <td>284</td>
      <td>NONE</td>
      <td>0</td>
      <td>562.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2646</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>646</td>
      <td>shap.utils._exceptions.ExplainerError</td>
      <td>2023-01-21</td>
      <td>2023-05-16</td>
      <td>217</td>
      <td>101</td>
      <td>NONE</td>
      <td>1</td>
      <td>563.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1561</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>561</td>
      <td>Explaining YOLOv3 predictions</td>
      <td>2020-11-15</td>
      <td>2021-01-01</td>
      <td>1014</td>
      <td>967</td>
      <td>NONE</td>
      <td>1</td>
      <td>563.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1864</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>864</td>
      <td>summing up shap_values</td>
      <td>2021-04-13</td>
      <td>2021-04-13</td>
      <td>865</td>
      <td>865</td>
      <td>NONE</td>
      <td>0</td>
      <td>567.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2020</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>020</td>
      <td>Can the number of samples passed to the explainer affect the shap value results?</td>
      <td>2021-08-03</td>
      <td>2021-08-11</td>
      <td>753</td>
      <td>745</td>
      <td>NONE</td>
      <td>1</td>
      <td>567.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1093</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>093</td>
      <td>shap.datasets.adult() fails with silly SSL: CERTIFICATE_VERIFY_FAILED</td>
      <td>2020-03-10</td>
      <td>2020-03-10</td>
      <td>1264</td>
      <td>1264</td>
      <td>NONE</td>
      <td>0</td>
      <td>567.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1586</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>586</td>
      <td>How to single out one point in bee swarm plot ?</td>
      <td>2020-12-01</td>
      <td>2021-11-05</td>
      <td>998</td>
      <td>659</td>
      <td>NONE</td>
      <td>1</td>
      <td>568.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1166</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>166</td>
      <td>Supported Layers/operations in DeepExplainer?</td>
      <td>2020-04-22</td>
      <td>2020-04-22</td>
      <td>1221</td>
      <td>1221</td>
      <td>NONE</td>
      <td>0</td>
      <td>571.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1631</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>631</td>
      <td>TypeError: Cannot read property 'parentNode' of null</td>
      <td>2020-12-17</td>
      <td>2020-12-17</td>
      <td>982</td>
      <td>982</td>
      <td>NONE</td>
      <td>0</td>
      <td>571.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1234</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>234</td>
      <td>Shap-Values for non-stationary datasets</td>
      <td>2020-05-27</td>
      <td>2020-05-27</td>
      <td>1186</td>
      <td>1186</td>
      <td>NONE</td>
      <td>0</td>
      <td>571.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1235</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>235</td>
      <td>tree_path_dependent warning, even when set explicitly.</td>
      <td>2020-05-27</td>
      <td>2020-06-13</td>
      <td>1186</td>
      <td>1169</td>
      <td>NONE</td>
      <td>1</td>
      <td>572.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1226</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>226</td>
      <td>how to figure out whether the model works in the right way or not?</td>
      <td>2020-05-25</td>
      <td>2020-06-13</td>
      <td>1188</td>
      <td>1169</td>
      <td>NONE</td>
      <td>1</td>
      <td>575.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1404</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>404</td>
      <td>Error : version of tensorflow</td>
      <td>2020-09-02</td>
      <td>2020-09-09</td>
      <td>1088</td>
      <td>1080</td>
      <td>NONE</td>
      <td>1</td>
      <td>576.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2648</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>648</td>
      <td>Single-row decision plots fail if null-values are present -- fix ready, please let me open a PR</td>
      <td>2023-01-26</td>
      <td>2023-01-28</td>
      <td>211</td>
      <td>210</td>
      <td>NONE</td>
      <td>0</td>
      <td>577.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>394</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>94</td>
      <td>Interpretation the Feature Effect plot</td>
      <td>2019-01-17</td>
      <td>2020-04-09</td>
      <td>1681</td>
      <td>1234</td>
      <td>NONE</td>
      <td>11</td>
      <td>577.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2082</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>082</td>
      <td>ImportError: No module named deep_tf</td>
      <td>2021-09-21</td>
      <td>2021-09-21</td>
      <td>703</td>
      <td>703</td>
      <td>NONE</td>
      <td>0</td>
      <td>578.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2831</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>831</td>
      <td>ENH: Consistent axes and figsize parameters for plots</td>
      <td>2023-07-06</td>
      <td>2023-08-26</td>
      <td>51</td>
      <td>0</td>
      <td>NONE</td>
      <td>3</td>
      <td>579.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1018</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>018</td>
      <td>Making tqdm optional</td>
      <td>2020-01-29</td>
      <td>2022-07-13</td>
      <td>1305</td>
      <td>409</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>580.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1720</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>720</td>
      <td>Comparative study of image explainers</td>
      <td>2021-01-20</td>
      <td>2021-01-21</td>
      <td>947</td>
      <td>946</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>581.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2071</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>071</td>
      <td>Base and expected value in SHAP using isolation forest are outside [0, 1]</td>
      <td>2021-09-15</td>
      <td>2021-10-16</td>
      <td>710</td>
      <td>679</td>
      <td>NONE</td>
      <td>1</td>
      <td>582.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2286</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>286</td>
      <td>Question: How to have background data more than 100 samples for TreeExplainer?</td>
      <td>2022-03-15</td>
      <td>2022-03-15</td>
      <td>528</td>
      <td>528</td>
      <td>NONE</td>
      <td>0</td>
      <td>583.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1856</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>856</td>
      <td>Exception: Model type not yet supported by TreeExplainer: &lt;class 'weka.classifiers.Classifier'&gt;</td>
      <td>2021-04-07</td>
      <td>2021-04-07</td>
      <td>871</td>
      <td>871</td>
      <td>NONE</td>
      <td>0</td>
      <td>585.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>723</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>23</td>
      <td>Shap throws back a tensor shape error for concatenate keras model</td>
      <td>2019-07-30</td>
      <td>2019-12-27</td>
      <td>1487</td>
      <td>1337</td>
      <td>NONE</td>
      <td>3</td>
      <td>585.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>962</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>62</td>
      <td>How to convert logodds explanations to probabilities?</td>
      <td>2019-12-19</td>
      <td>2023-06-18</td>
      <td>1346</td>
      <td>69</td>
      <td>NONE</td>
      <td>32</td>
      <td>586.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2393</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>393</td>
      <td>Hierarchical values are not being calculated for text</td>
      <td>2022-05-18</td>
      <td>2022-05-18</td>
      <td>464</td>
      <td>464</td>
      <td>NONE</td>
      <td>0</td>
      <td>586.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1193</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>193</td>
      <td>Can shap_values() be used one new row at a time?</td>
      <td>2020-05-02</td>
      <td>2020-06-25</td>
      <td>1211</td>
      <td>1156</td>
      <td>NONE</td>
      <td>1</td>
      <td>586.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>475</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>75</td>
      <td>Different results for LinearExplainer and kernelExplainer for Logistic Regression</td>
      <td>2019-03-05</td>
      <td>2019-03-07</td>
      <td>1635</td>
      <td>1633</td>
      <td>NONE</td>
      <td>2</td>
      <td>587.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2337</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>337</td>
      <td>How to choose the best layer of the Gradient Explainer?</td>
      <td>2022-04-08</td>
      <td>2022-04-08</td>
      <td>505</td>
      <td>505</td>
      <td>NONE</td>
      <td>0</td>
      <td>587.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2260</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>260</td>
      <td>Differences between explanations</td>
      <td>2022-02-21</td>
      <td>2022-02-26</td>
      <td>550</td>
      <td>545</td>
      <td>NONE</td>
      <td>1</td>
      <td>588.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>367</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>67</td>
      <td>Questions about SHAP paper</td>
      <td>2018-12-26</td>
      <td>2018-12-31</td>
      <td>1704</td>
      <td>1699</td>
      <td>NONE</td>
      <td>8</td>
      <td>588.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1940</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>940</td>
      <td>Add summary plot examples for LightGBM single class in the doc page</td>
      <td>2021-06-02</td>
      <td>2021-06-02</td>
      <td>815</td>
      <td>815</td>
      <td>NONE</td>
      <td>0</td>
      <td>588.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>90</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>0</td>
      <td>How to use this SHAP tool for XGBoost multiclass problems?</td>
      <td>2018-05-17</td>
      <td>2019-10-26</td>
      <td>1926</td>
      <td>1400</td>
      <td>NONE</td>
      <td>8</td>
      <td>590.0</td>
      <td>No</td>
      <td>Issue: Need guidance on using a certain tool.</td>
      <td>"Usage Clarification"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1694</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>694</td>
      <td>Shap values cohorts: can I plot beeswarm or scatter or extract values as a table?</td>
      <td>2021-01-13</td>
      <td>2021-01-13</td>
      <td>955</td>
      <td>955</td>
      <td>NONE</td>
      <td>0</td>
      <td>590.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1527</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>527</td>
      <td>\"Keras LSTM for IMDB Classification\" tutorial err</td>
      <td>2020-10-27</td>
      <td>2021-10-21</td>
      <td>1033</td>
      <td>674</td>
      <td>NONE</td>
      <td>7</td>
      <td>591.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>863</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>63</td>
      <td>Issue with nudging `&lt;=` thresholds.</td>
      <td>2019-10-23</td>
      <td>2020-02-27</td>
      <td>1403</td>
      <td>1275</td>
      <td>NONE</td>
      <td>1</td>
      <td>591.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2033</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>033</td>
      <td>Interactive text is cropped on the right edge of force plots</td>
      <td>2021-08-11</td>
      <td>2021-08-11</td>
      <td>745</td>
      <td>745</td>
      <td>NONE</td>
      <td>0</td>
      <td>594.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>221</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>21</td>
      <td>Accuracy of Explaination in SHAP</td>
      <td>2018-08-15</td>
      <td>2019-08-17</td>
      <td>1837</td>
      <td>1470</td>
      <td>NONE</td>
      <td>4</td>
      <td>594.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>634</td>
      <td><a href="https://github.com/shap/shap/issues/64">64</a>4</td>
      <td>Interpreting dispersion in main effect values</td>
      <td>2019-06-07</td>
      <td>2019-06-21</td>
      <td>1540</td>
      <td>1527</td>
      <td>NONE</td>
      <td>4</td>
      <td>595.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1649</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>649</td>
      <td>The purple color of the summary plot is not displayed.</td>
      <td>2020-12-22</td>
      <td>2020-12-22</td>
      <td>977</td>
      <td>977</td>
      <td>NONE</td>
      <td>0</td>
      <td>597.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2914</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>914</td>
      <td>ENH: Documentation : add links between Examples and API Reference</td>
      <td>2023-08-01</td>
      <td>2023-08-08</td>
      <td>25</td>
      <td>18</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>597.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1168</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>168</td>
      <td>Cannot run the examples on github README.md</td>
      <td>2020-04-23</td>
      <td>2021-07-20</td>
      <td>1220</td>
      <td>767</td>
      <td>NONE</td>
      <td>4</td>
      <td>599.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2354</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>354</td>
      <td>Why is there no weight parameter for SHAP TreeExplainer?</td>
      <td>2022-04-20</td>
      <td>2022-04-20</td>
      <td>493</td>
      <td>493</td>
      <td>NONE</td>
      <td>0</td>
      <td>599.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2516</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>516</td>
      <td>SHAP plots with Explainer function</td>
      <td>2022-09-19</td>
      <td>2022-09-19</td>
      <td>341</td>
      <td>340</td>
      <td>NONE</td>
      <td>1</td>
      <td>600.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2008</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>008</td>
      <td>[Paper] Question to Proof of Theorem 1</td>
      <td>2021-07-23</td>
      <td>2021-07-23</td>
      <td>764</td>
      <td>764</td>
      <td>NONE</td>
      <td>0</td>
      <td>600.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1923</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>923</td>
      <td>Errors with example notebook in version 0.38.1</td>
      <td>2021-05-21</td>
      <td>2021-05-22</td>
      <td>827</td>
      <td>826</td>
      <td>NONE</td>
      <td>0</td>
      <td>601.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2540</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>540</td>
      <td>Predicting SHAP feature contributions for LGBM linear trees.</td>
      <td>2022-10-05</td>
      <td>2022-10-05</td>
      <td>325</td>
      <td>325</td>
      <td>NONE</td>
      <td>0</td>
      <td>602.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1593</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>593</td>
      <td>Is features parameter required to generate color-coded results in summary_plot?</td>
      <td>2020-12-05</td>
      <td>2020-12-05</td>
      <td>993</td>
      <td>993</td>
      <td>NONE</td>
      <td>0</td>
      <td>606.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2334</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>334</td>
      <td>shap_values.base_values become weird when the size of maskers is larger than 100.</td>
      <td>2022-04-08</td>
      <td>2022-06-16</td>
      <td>505</td>
      <td>436</td>
      <td>NONE</td>
      <td>1</td>
      <td>607.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2091</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>091</td>
      <td>Output of DeepExplainer</td>
      <td>2021-10-03</td>
      <td>2023-04-27</td>
      <td>692</td>
      <td>120</td>
      <td>NONE</td>
      <td>3</td>
      <td>607.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1157</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>157</td>
      <td>AttributeError: module 'shap' has no attribute 'DeepExplainer'</td>
      <td>2020-04-16</td>
      <td>2023-08-12</td>
      <td>1227</td>
      <td>13</td>
      <td>NONE</td>
      <td>7</td>
      <td>608.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1198</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>198</td>
      <td>Can The kernel Explainer be used for a neural network model</td>
      <td>2020-05-07</td>
      <td>2022-02-25</td>
      <td>1206</td>
      <td>547</td>
      <td>NONE</td>
      <td>9</td>
      <td>608.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1362</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>362</td>
      <td>Training/Validation</td>
      <td>2020-08-13</td>
      <td>2020-09-03</td>
      <td>1108</td>
      <td>1087</td>
      <td>NONE</td>
      <td>1</td>
      <td>608.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1965</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>965</td>
      <td>demo can not work</td>
      <td>2021-06-22</td>
      <td>2021-06-28</td>
      <td>795</td>
      <td>789</td>
      <td>NONE</td>
      <td>4</td>
      <td>608.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1432</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>432</td>
      <td>Adding second and third order support for AdditiveExplainer</td>
      <td>2020-09-15</td>
      <td>2020-09-15</td>
      <td>1075</td>
      <td>1074</td>
      <td>NONE</td>
      <td>1</td>
      <td>609.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1228</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>228</td>
      <td>Different Results Produced Using In-sample and Out-of-sample shap</td>
      <td>2020-05-25</td>
      <td>2020-05-25</td>
      <td>1187</td>
      <td>1187</td>
      <td>NONE</td>
      <td>0</td>
      <td>611.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2285</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>285</td>
      <td>Warning with PyTorch model that contains Flatten layer</td>
      <td>2022-03-15</td>
      <td>2023-07-18</td>
      <td>528</td>
      <td>38</td>
      <td>NONE</td>
      <td>4</td>
      <td>611.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2262</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>262</td>
      <td>On computing Shap Values</td>
      <td>2022-02-23</td>
      <td>2023-08-23</td>
      <td>549</td>
      <td>3</td>
      <td>NONE</td>
      <td>7</td>
      <td>611.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2473</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>473</td>
      <td>What is the way of explaining a neural network that takes both tabular and text data?</td>
      <td>2022-08-03</td>
      <td>2022-08-03</td>
      <td>387</td>
      <td>387</td>
      <td>NONE</td>
      <td>0</td>
      <td>611.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>914</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>14</td>
      <td>question (please answer)</td>
      <td>2019-11-27</td>
      <td>2020-01-08</td>
      <td>1368</td>
      <td>1325</td>
      <td>NONE</td>
      <td>5</td>
      <td>612.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1403</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>403</td>
      <td>Unable to install SHAP</td>
      <td>2020-09-02</td>
      <td>2022-08-09</td>
      <td>1088</td>
      <td>382</td>
      <td>NONE</td>
      <td>4</td>
      <td>612.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>955</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>55</td>
      <td>Question: Non-negative Shapley Values</td>
      <td>2019-12-16</td>
      <td>2019-12-17</td>
      <td>1349</td>
      <td>1348</td>
      <td>NONE</td>
      <td>1</td>
      <td>613.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1688</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>688</td>
      <td>shap summary plot has different class colors in different models with the same \"class_names</td>
      <td>2021-01-12</td>
      <td>2021-09-27</td>
      <td>956</td>
      <td>697</td>
      <td>NONE</td>
      <td>1</td>
      <td>616.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>845</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>45</td>
      <td>&lt;IPython.core.display.HTML object&gt;</td>
      <td>2019-10-10</td>
      <td>2019-10-22</td>
      <td>1416</td>
      <td>1404</td>
      <td>NONE</td>
      <td>1</td>
      <td>620.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1183</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>183</td>
      <td>calling shap.TreeExplainer() in a loop for individual trees</td>
      <td>2020-04-28</td>
      <td>2020-04-28</td>
      <td>1215</td>
      <td>1215</td>
      <td>NONE</td>
      <td>2</td>
      <td>621.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2362</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>362</td>
      <td>Shap value creation for XGBoost model with num_parallel_tree &gt; 1</td>
      <td>2022-04-25</td>
      <td>2022-04-25</td>
      <td>488</td>
      <td>488</td>
      <td>NONE</td>
      <td>0</td>
      <td>621.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2183</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>183</td>
      <td>watterfall plot didn't work with TreeExplainer</td>
      <td>2021-12-13</td>
      <td>2022-01-31</td>
      <td>621</td>
      <td>572</td>
      <td>NONE</td>
      <td>1</td>
      <td>622.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2538</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>538</td>
      <td>help with summary plot interpretation</td>
      <td>2022-10-04</td>
      <td>2022-10-04</td>
      <td>326</td>
      <td>326</td>
      <td>NONE</td>
      <td>0</td>
      <td>624.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1493</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>493</td>
      <td>3D data in shap</td>
      <td>2020-10-07</td>
      <td>2023-04-15</td>
      <td>1053</td>
      <td>133</td>
      <td>NONE</td>
      <td>7</td>
      <td>628.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2674</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>674</td>
      <td>Shap Waterfall Plot for Multiclass using TreeExplainer</td>
      <td>2023-03-05</td>
      <td>2023-03-22</td>
      <td>174</td>
      <td>157</td>
      <td>NONE</td>
      <td>1</td>
      <td>629.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1865</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>865</td>
      <td>check_additivity not working properly</td>
      <td>2021-04-13</td>
      <td>2022-02-18</td>
      <td>865</td>
      <td>554</td>
      <td>NONE</td>
      <td>1</td>
      <td>629.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2219</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>219</td>
      <td>SHAP for Reinforcment Learning</td>
      <td>2022-01-17</td>
      <td>2023-05-26</td>
      <td>586</td>
      <td>92</td>
      <td>NONE</td>
      <td>1</td>
      <td>629.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1122</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>122</td>
      <td>does it possible for shap to recognize  PMMLForestClassifier object load by sklearn_pmml_model package,since shap can recognize PMMLLinearRegression object created by sklearn_pmml_model pacjage</td>
      <td>2020-03-28</td>
      <td>2020-04-16</td>
      <td>1246</td>
      <td>1227</td>
      <td>NONE</td>
      <td>1</td>
      <td>629.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2254</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>254</td>
      <td>How to get the feature importance for a subgroup of samples</td>
      <td>2022-02-20</td>
      <td>2022-02-28</td>
      <td>552</td>
      <td>543</td>
      <td>NONE</td>
      <td>3</td>
      <td>631.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>498</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>98</td>
      <td>KernelExplainer Error if keep_index = True</td>
      <td>2019-03-20</td>
      <td>2023-08-26</td>
      <td>1620</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>631.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>995</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>95</td>
      <td>All shap values to 0 and shap value row doesn't match difference between expected_value and prediction</td>
      <td>2020-01-13</td>
      <td>2021-08-13</td>
      <td>1321</td>
      <td>742</td>
      <td>NONE</td>
      <td>4</td>
      <td>632.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2356</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>356</td>
      <td>All SHAP values are rounded to 0 in bar plot</td>
      <td>2022-04-20</td>
      <td>2022-08-29</td>
      <td>492</td>
      <td>362</td>
      <td>NONE</td>
      <td>4</td>
      <td>632.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2150</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>150</td>
      <td>Using custom functions and tokenizers</td>
      <td>2021-11-22</td>
      <td>2021-11-22</td>
      <td>642</td>
      <td>642</td>
      <td>NONE</td>
      <td>0</td>
      <td>632.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1928</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>928</td>
      <td>DeepExplainer target</td>
      <td>2021-05-24</td>
      <td>2021-05-25</td>
      <td>824</td>
      <td>823</td>
      <td>NONE</td>
      <td>2</td>
      <td>634.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>666</td>
      <td><a href="https://github.com/shap/shap/issues/67">67</a>6</td>
      <td>nonlinearity_2d_handler input dimensionality issue</td>
      <td>2019-06-26</td>
      <td>2019-06-27</td>
      <td>1522</td>
      <td>1521</td>
      <td>NONE</td>
      <td>2</td>
      <td>636.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2241</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>241</td>
      <td>shap.plot.text returns nothing even if Display = False</td>
      <td>2022-02-12</td>
      <td>2022-02-16</td>
      <td>559</td>
      <td>556</td>
      <td>NONE</td>
      <td>1</td>
      <td>637.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>521</td>
      <td><a href="https://github.com/shap/shap/issues/53">53</a>1</td>
      <td>summary_plot o dependence_plot save plot as vectorial format (PDF) rasterizing the points. I'd like to save in a pure vectorial way.</td>
      <td>2019-03-30</td>
      <td>2019-04-02</td>
      <td>1610</td>
      <td>1606</td>
      <td>NONE</td>
      <td>1</td>
      <td>640.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>298</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>98</td>
      <td>Doubt about definition in the NIPS article</td>
      <td>2018-10-25</td>
      <td>2018-11-02</td>
      <td>1766</td>
      <td>1757</td>
      <td>NONE</td>
      <td>1</td>
      <td>642.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>702</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>02</td>
      <td>Clipping input data to the valid range for imshow</td>
      <td>2019-07-17</td>
      <td>2021-07-06</td>
      <td>1501</td>
      <td>781</td>
      <td>NONE</td>
      <td>8</td>
      <td>642.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2320</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>320</td>
      <td>Question - Deep and Gradient Explainers with PyTorch and Embeddings</td>
      <td>2022-04-01</td>
      <td>2022-06-03</td>
      <td>512</td>
      <td>449</td>
      <td>NONE</td>
      <td>1</td>
      <td>642.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1470</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>470</td>
      <td>Using Shap with an AutoTrackable object (from loading a saved model)</td>
      <td>2020-09-25</td>
      <td>2022-06-23</td>
      <td>1065</td>
      <td>428</td>
      <td>NONE</td>
      <td>2</td>
      <td>644.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>26</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>6</td>
      <td>Explanation plotting in python instead of JS</td>
      <td>2018-01-31</td>
      <td>2022-06-14</td>
      <td>2033</td>
      <td>438</td>
      <td>NONE</td>
      <td>24</td>
      <td>644.0</td>
      <td>No</td>
      <td>Issue: Explanation problem in 'title' series and '@slundberg' tagged in 'body'.\n</td>
      <td>"Data Shape"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>200</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>00</td>
      <td>How to get shap values on new samples?</td>
      <td>2018-08-03</td>
      <td>2018-08-08</td>
      <td>1849</td>
      <td>1843</td>
      <td>NONE</td>
      <td>2</td>
      <td>646.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>678</td>
      <td><a href="https://github.com/shap/shap/issues/679">679</a></td>
      <td>How to get the importance for categorical features in Shap value</td>
      <td>2019-07-03</td>
      <td>2021-02-21</td>
      <td>1515</td>
      <td>915</td>
      <td>NONE</td>
      <td>6</td>
      <td>648.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1204</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>204</td>
      <td>Bug: TreeExplainer `predict` check uses incorrect string to check model output type.</td>
      <td>2020-05-11</td>
      <td>2020-05-11</td>
      <td>1202</td>
      <td>1202</td>
      <td>NONE</td>
      <td>0</td>
      <td>650.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>437</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>37</td>
      <td>Add facets for dependence plots</td>
      <td>2019-02-11</td>
      <td>2019-02-16</td>
      <td>1656</td>
      <td>1652</td>
      <td>NONE</td>
      <td>1</td>
      <td>651.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2443</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>443</td>
      <td>Explanation for Hybrid Transformer Network</td>
      <td>2022-07-04</td>
      <td>2022-07-04</td>
      <td>418</td>
      <td>418</td>
      <td>NONE</td>
      <td>0</td>
      <td>656.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2383</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>383</td>
      <td>SHAP predictions not matching model predictions</td>
      <td>2022-05-11</td>
      <td>2022-05-12</td>
      <td>471</td>
      <td>471</td>
      <td>NONE</td>
      <td>2</td>
      <td>659.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2235</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>235</td>
      <td>AdditiveExplainer error when defining the MaskedModel object - Missing the linearize_link attribute?</td>
      <td>2022-02-03</td>
      <td>2022-02-03</td>
      <td>569</td>
      <td>569</td>
      <td>NONE</td>
      <td>0</td>
      <td>659.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1272</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>272</td>
      <td>SHAP inner workings for an XGBoost classification model</td>
      <td>2020-06-17</td>
      <td>2020-07-23</td>
      <td>1165</td>
      <td>1128</td>
      <td>NONE</td>
      <td>1</td>
      <td>659.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2481</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>481</td>
      <td>Shap values interpretation for classification models</td>
      <td>2022-08-18</td>
      <td>2022-09-14</td>
      <td>373</td>
      <td>346</td>
      <td>NONE</td>
      <td>3</td>
      <td>660.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>338</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>38</td>
      <td>DeepExplainer no longer supports DenseData</td>
      <td>2018-11-26</td>
      <td>2018-11-26</td>
      <td>1734</td>
      <td>1734</td>
      <td>COLLABORATOR</td>
      <td>1</td>
      <td>661.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>968</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>68</td>
      <td>Unable to view features of low/zero importance</td>
      <td>2019-12-23</td>
      <td>2019-12-27</td>
      <td>1342</td>
      <td>1338</td>
      <td>NONE</td>
      <td>1</td>
      <td>661.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>453</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>53</td>
      <td>Xgboost objective = reg:tweedie, shap values and expected value much lower than predicted</td>
      <td>2019-02-21</td>
      <td>2020-08-03</td>
      <td>1647</td>
      <td>1118</td>
      <td>NONE</td>
      <td>8</td>
      <td>661.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1009</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>009</td>
      <td>GradientExplainer returns different results</td>
      <td>2020-01-22</td>
      <td>2021-02-24</td>
      <td>1311</td>
      <td>913</td>
      <td>NONE</td>
      <td>3</td>
      <td>663.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2104</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>104</td>
      <td>Error plotting shap.summary_plot for a convolutional neural network (CNN) model.</td>
      <td>2021-10-13</td>
      <td>2021-10-13</td>
      <td>682</td>
      <td>682</td>
      <td>NONE</td>
      <td>0</td>
      <td>663.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>711</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>11</td>
      <td>Shape values don't match real predictions - DeepExplainer</td>
      <td>2019-07-23</td>
      <td>2020-06-02</td>
      <td>1495</td>
      <td>1180</td>
      <td>NONE</td>
      <td>7</td>
      <td>666.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1753</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>753</td>
      <td>How does \"Census income classification with LightGBM\" notebook handle categorical featur</td>
      <td>2021-01-31</td>
      <td>2021-01-31</td>
      <td>937</td>
      <td>937</td>
      <td>NONE</td>
      <td>0</td>
      <td>666.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>300</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>00</td>
      <td>Possible Compatibility Issues in PyTorchDeepExplainer (tested in PyTorch 1.0 Preview)</td>
      <td>2018-10-27</td>
      <td>2018-11-09</td>
      <td>1764</td>
      <td>1751</td>
      <td>NONE</td>
      <td>6</td>
      <td>667.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2277</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>277</td>
      <td>Shapley Values (SV's) and Order of Variables</td>
      <td>2022-03-10</td>
      <td>2022-03-10</td>
      <td>534</td>
      <td>534</td>
      <td>NONE</td>
      <td>0</td>
      <td>668.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2453</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>453</td>
      <td>Does the following SHAP explanations make sense for a well-performed MLP-based image classifier</td>
      <td>2022-07-15</td>
      <td>2022-07-15</td>
      <td>406</td>
      <td>406</td>
      <td>NONE</td>
      <td>0</td>
      <td>669.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1784</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>784</td>
      <td>Dependence plot colour by target?</td>
      <td>2021-02-19</td>
      <td>2023-01-12</td>
      <td>918</td>
      <td>226</td>
      <td>NONE</td>
      <td>2</td>
      <td>669.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>853</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>53</td>
      <td>Comparing two datasets with SHAP</td>
      <td>2019-10-16</td>
      <td>2019-10-16</td>
      <td>1409</td>
      <td>1409</td>
      <td>NONE</td>
      <td>1</td>
      <td>669.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1301</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>301</td>
      <td>Xgboost binary format compatibility</td>
      <td>2020-07-08</td>
      <td>2022-09-24</td>
      <td>1143</td>
      <td>336</td>
      <td>CONTRIBUTOR</td>
      <td>2</td>
      <td>670.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2275</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>275</td>
      <td>Is it correct to describe a model globally by using observations that are not the train data?</td>
      <td>2022-03-08</td>
      <td>2022-03-08</td>
      <td>536</td>
      <td>536</td>
      <td>NONE</td>
      <td>0</td>
      <td>670.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1309</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>309</td>
      <td>SHAP KernelExplainer Vs LimeTabularExplainer</td>
      <td>2020-07-10</td>
      <td>2020-07-20</td>
      <td>1142</td>
      <td>1132</td>
      <td>NONE</td>
      <td>1</td>
      <td>672.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2442</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>442</td>
      <td>Force plot outputs data inconsistent with model prediction</td>
      <td>2022-06-30</td>
      <td>2022-07-06</td>
      <td>422</td>
      <td>416</td>
      <td>NONE</td>
      <td>3</td>
      <td>672.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>784</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>84</td>
      <td>Visualizers in React: this.invLinkFunction may be undefined</td>
      <td>2019-08-30</td>
      <td>2019-09-05</td>
      <td>1457</td>
      <td>1451</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>672.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>514</td>
      <td><a href="https://github.com/shap/shap/issues/52">52</a>4</td>
      <td>SHAP with tensorflow only</td>
      <td>2019-03-26</td>
      <td>2019-04-08</td>
      <td>1614</td>
      <td>1601</td>
      <td>NONE</td>
      <td>8</td>
      <td>673.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1945</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>945</td>
      <td>Exception: Additivity check failed in TreeExplainer!  though data and model are correct</td>
      <td>2021-06-06</td>
      <td>2023-03-13</td>
      <td>811</td>
      <td>166</td>
      <td>NONE</td>
      <td>1</td>
      <td>674.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>158</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>58</td>
      <td>Suppress scientific values from force plot</td>
      <td>2018-07-16</td>
      <td>2018-07-17</td>
      <td>1867</td>
      <td>1866</td>
      <td>NONE</td>
      <td>1</td>
      <td>676.0</td>
      <td>No</td>
      <td>Issue concerns suppressing scientific notation in a series title.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>133</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>33</td>
      <td>SHAP Hierarchical Clustering</td>
      <td>2018-06-28</td>
      <td>2020-11-23</td>
      <td>1885</td>
      <td>1006</td>
      <td>NONE</td>
      <td>3</td>
      <td>676.0</td>
      <td>No</td>
      <td>Issue with SHAP Hierarchical series title and body format.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2528</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>528</td>
      <td>Difference between the parameter features in explainer initialization and when calculating shap values</td>
      <td>2022-09-26</td>
      <td>2023-08-26</td>
      <td>334</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>677.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1481</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>481</td>
      <td>Not an issue rather technical question on kernel.py</td>
      <td>2020-09-30</td>
      <td>2020-09-30</td>
      <td>1060</td>
      <td>1060</td>
      <td>NONE</td>
      <td>0</td>
      <td>678.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1217</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>217</td>
      <td>Output of random forests saved differently than output of gradient boosting model</td>
      <td>2020-05-20</td>
      <td>2020-05-20</td>
      <td>1193</td>
      <td>1193</td>
      <td>NONE</td>
      <td>0</td>
      <td>681.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1787</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>787</td>
      <td>Randomness of shapley values when using KernelExplainer</td>
      <td>2021-02-23</td>
      <td>2021-07-17</td>
      <td>914</td>
      <td>770</td>
      <td>NONE</td>
      <td>3</td>
      <td>684.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>479</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>79</td>
      <td>TreeEnsemble instance has no attribute 'values' in LightGBM</td>
      <td>2019-03-07</td>
      <td>2023-07-08</td>
      <td>1633</td>
      <td>49</td>
      <td>NONE</td>
      <td>33</td>
      <td>684.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1267</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>267</td>
      <td>KernelExplainer ValueError with inf</td>
      <td>2020-06-14</td>
      <td>2023-07-23</td>
      <td>1168</td>
      <td>34</td>
      <td>NONE</td>
      <td>1</td>
      <td>687.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1755</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>755</td>
      <td>Passing test data to LinearExplainer or KernelExplainer</td>
      <td>2021-02-02</td>
      <td>2021-02-02</td>
      <td>935</td>
      <td>935</td>
      <td>NONE</td>
      <td>0</td>
      <td>688.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>611</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a>1</td>
      <td>Combining shap values for arguments of arguments of a nonlinear model</td>
      <td>2019-05-29</td>
      <td>2019-05-29</td>
      <td>1550</td>
      <td>1550</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>691.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1295</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>295</td>
      <td>image_plot cannot handle rectangular inputs</td>
      <td>2020-07-01</td>
      <td>2020-07-03</td>
      <td>1151</td>
      <td>1149</td>
      <td>NONE</td>
      <td>1</td>
      <td>691.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2290</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>290</td>
      <td>pyinstaller executable including SHAP error</td>
      <td>2022-03-18</td>
      <td>2023-05-04</td>
      <td>526</td>
      <td>114</td>
      <td>NONE</td>
      <td>6</td>
      <td>691.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1241</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>241</td>
      <td>SHAP with multi-class classification</td>
      <td>2020-05-30</td>
      <td>2021-02-02</td>
      <td>1182</td>
      <td>935</td>
      <td>NONE</td>
      <td>4</td>
      <td>693.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1922</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>922</td>
      <td>calculating shap_values slow - enable multiprocessing</td>
      <td>2021-05-19</td>
      <td>2021-05-19</td>
      <td>829</td>
      <td>829</td>
      <td>NONE</td>
      <td>0</td>
      <td>698.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2514</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>514</td>
      <td>Issue in shap values with Gradient Boasting Tree Classifier</td>
      <td>2022-09-18</td>
      <td>2022-09-18</td>
      <td>341</td>
      <td>341</td>
      <td>NONE</td>
      <td>0</td>
      <td>698.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2270</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>270</td>
      <td>Deep explainer: The shap explainer do not sum up to the models output.</td>
      <td>2022-03-04</td>
      <td>2022-03-04</td>
      <td>540</td>
      <td>540</td>
      <td>NONE</td>
      <td>0</td>
      <td>701.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2132</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>132</td>
      <td>Decision plot X axis is not intercepted at the sum of shap value plus model expected value</td>
      <td>2021-11-08</td>
      <td>2021-11-08</td>
      <td>656</td>
      <td>656</td>
      <td>NONE</td>
      <td>0</td>
      <td>704.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2311</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>311</td>
      <td>Accessing Shap values positive and negative</td>
      <td>2022-03-28</td>
      <td>2022-03-31</td>
      <td>516</td>
      <td>512</td>
      <td>NONE</td>
      <td>1</td>
      <td>704.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1835</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>835</td>
      <td>Does shap.Explainer work with any machine learning model? Question about \"masker\" paramet</td>
      <td>2021-03-23</td>
      <td>2021-03-31</td>
      <td>886</td>
      <td>878</td>
      <td>NONE</td>
      <td>1</td>
      <td>704.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2098</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>098</td>
      <td>SHAP for PySpark RandomForest: Usage of nonwhitelisted methods</td>
      <td>2021-10-07</td>
      <td>2021-10-07</td>
      <td>688</td>
      <td>688</td>
      <td>NONE</td>
      <td>0</td>
      <td>707.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1812</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>812</td>
      <td>DeepExplainer can't handle Keras GlobalMaxPooling2D</td>
      <td>2021-03-10</td>
      <td>2022-11-09</td>
      <td>899</td>
      <td>290</td>
      <td>NONE</td>
      <td>1</td>
      <td>707.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>750</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>50</td>
      <td>Trouble understanding SHAP values for missing features</td>
      <td>2019-08-15</td>
      <td>2019-08-15</td>
      <td>1471</td>
      <td>1471</td>
      <td>NONE</td>
      <td>0</td>
      <td>707.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1083</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>083</td>
      <td>Model Type not yet supported by TreeExplainer</td>
      <td>2020-03-04</td>
      <td>2020-05-07</td>
      <td>1270</td>
      <td>1206</td>
      <td>NONE</td>
      <td>22</td>
      <td>707.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>740</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>40</td>
      <td>Linear Explainer - correlated vs independent</td>
      <td>2019-08-12</td>
      <td>2023-08-26</td>
      <td>1475</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>708.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>741</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>41</td>
      <td>Is it possible to use shap to explain LTR models?</td>
      <td>2019-08-13</td>
      <td>2019-08-13</td>
      <td>1474</td>
      <td>1474</td>
      <td>NONE</td>
      <td>0</td>
      <td>710.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1005</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>005</td>
      <td>Scaling baseline and SHAPs back to original class rate</td>
      <td>2020-01-20</td>
      <td>2020-05-07</td>
      <td>1314</td>
      <td>1206</td>
      <td>NONE</td>
      <td>1</td>
      <td>713.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>850</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>50</td>
      <td>Confusion in multiclass shap output</td>
      <td>2019-10-15</td>
      <td>2019-10-16</td>
      <td>1411</td>
      <td>1409</td>
      <td>NONE</td>
      <td>1</td>
      <td>713.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1036</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>036</td>
      <td>Interpretation of output value of SHAP</td>
      <td>2020-02-11</td>
      <td>2020-02-12</td>
      <td>1292</td>
      <td>1291</td>
      <td>NONE</td>
      <td>0</td>
      <td>714.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2462</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>462</td>
      <td>SHAP interpretation for a single observation</td>
      <td>2022-07-25</td>
      <td>2022-08-03</td>
      <td>397</td>
      <td>388</td>
      <td>NONE</td>
      <td>5</td>
      <td>714.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1707</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>707</td>
      <td>Dimension mismatch when using SHAP to explain ResNet50</td>
      <td>2021-01-16</td>
      <td>2021-10-01</td>
      <td>952</td>
      <td>694</td>
      <td>NONE</td>
      <td>3</td>
      <td>715.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1528</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>528</td>
      <td>Variable Independence for Different Methods</td>
      <td>2020-10-27</td>
      <td>2020-10-27</td>
      <td>1033</td>
      <td>1033</td>
      <td>NONE</td>
      <td>0</td>
      <td>718.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>244</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>44</td>
      <td>negative shap_values for binary classification and force_plot doesn't work with 200+ features</td>
      <td>2018-08-29</td>
      <td>2018-08-30</td>
      <td>1823</td>
      <td>1822</td>
      <td>NONE</td>
      <td>2</td>
      <td>720.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2660</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>660</td>
      <td>IndexError: index 0 is out of bounds for axis 0 with size 0</td>
      <td>2023-02-09</td>
      <td>2023-07-24</td>
      <td>198</td>
      <td>33</td>
      <td>NONE</td>
      <td>13</td>
      <td>721.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>440</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>40</td>
      <td>Confidence / Error bars for shap values</td>
      <td>2019-02-12</td>
      <td>2022-11-15</td>
      <td>1656</td>
      <td>284</td>
      <td>NONE</td>
      <td>6</td>
      <td>721.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2395</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>395</td>
      <td>Can someone explain how to interpret SHAP values in mortality models?</td>
      <td>2022-05-23</td>
      <td>2022-05-28</td>
      <td>460</td>
      <td>454</td>
      <td>NONE</td>
      <td>0</td>
      <td>722.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>637</td>
      <td><a href="https://github.com/shap/shap/issues/64">64</a>7</td>
      <td>Support for ONNX models needed</td>
      <td>2019-06-10</td>
      <td>2022-07-27</td>
      <td>1538</td>
      <td>395</td>
      <td>NONE</td>
      <td>6</td>
      <td>726.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1951</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>951</td>
      <td>Interpreter died because of Segmentation fault while calculating shap values</td>
      <td>2021-06-09</td>
      <td>2021-06-09</td>
      <td>807</td>
      <td>807</td>
      <td>NONE</td>
      <td>0</td>
      <td>728.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1952</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>952</td>
      <td>Inerpreter died due to Segmentation fault while calculating shap values</td>
      <td>2021-06-09</td>
      <td>2021-06-09</td>
      <td>807</td>
      <td>807</td>
      <td>NONE</td>
      <td>0</td>
      <td>728.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>992</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>92</td>
      <td>Does mean represent the absence of feature value?</td>
      <td>2020-01-10</td>
      <td>2020-01-10</td>
      <td>1324</td>
      <td>1324</td>
      <td>NONE</td>
      <td>0</td>
      <td>730.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1664</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>664</td>
      <td>Question about `summary_plot` for binary classification</td>
      <td>2020-12-28</td>
      <td>2021-09-23</td>
      <td>971</td>
      <td>702</td>
      <td>NONE</td>
      <td>1</td>
      <td>731.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2557</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>557</td>
      <td>SHAP with CV: What values from explainer object are actually plotted in summary plot?</td>
      <td>2022-10-19</td>
      <td>2022-10-19</td>
      <td>311</td>
      <td>311</td>
      <td>NONE</td>
      <td>1</td>
      <td>731.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>569</td>
      <td><a href="https://github.com/shap/shap/issues/570">570</a></td>
      <td>Explainer for ranking task (lambdamart)</td>
      <td>2019-04-30</td>
      <td>2020-05-15</td>
      <td>1579</td>
      <td>1198</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>733.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2694</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>694</td>
      <td>TypeError: only integer scalar arrays can be converted to a scalar index</td>
      <td>2023-04-04</td>
      <td>2023-06-16</td>
      <td>144</td>
      <td>70</td>
      <td>NONE</td>
      <td>1</td>
      <td>734.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>390</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>90</td>
      <td>Choosing the background set</td>
      <td>2019-01-13</td>
      <td>2019-02-05</td>
      <td>1686</td>
      <td>1663</td>
      <td>NONE</td>
      <td>3</td>
      <td>738.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>19</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>9</td>
      <td>alternative `shap.visualize`</td>
      <td>2018-01-20</td>
      <td>2020-01-17</td>
      <td>2044</td>
      <td>1317</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>739.0</td>
      <td>No</td>
      <td>Issue with alternative string representation in series for shape (1,).</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2632</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>632</td>
      <td>Displaying two beeswarm plots side by side in the same figure using matplotlib</td>
      <td>2023-01-03</td>
      <td>2023-06-25</td>
      <td>234</td>
      <td>62</td>
      <td>NONE</td>
      <td>2</td>
      <td>741.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2600</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>600</td>
      <td>Shap.plots.txt(shap_values) raises error \"integer argument expected, got float\</td>
      <td>2022-12-05</td>
      <td>2023-06-17</td>
      <td>264</td>
      <td>70</td>
      <td>NONE</td>
      <td>4</td>
      <td>743.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>625</td>
      <td><a href="https://github.com/shap/shap/issues/63">63</a>5</td>
      <td>explaining  3-D input data (eg CNN or LSTM) for plotting (using force or summary plot)</td>
      <td>2019-05-31</td>
      <td>2019-06-12</td>
      <td>1547</td>
      <td>1536</td>
      <td>NONE</td>
      <td>0</td>
      <td>744.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2224</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>224</td>
      <td>[GPUTree] waterfall_plot requires a scalar base_values of the model output as the first parameter, but...</td>
      <td>2022-01-25</td>
      <td>2022-05-27</td>
      <td>578</td>
      <td>456</td>
      <td>NONE</td>
      <td>5</td>
      <td>744.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1095</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>095</td>
      <td>could not execute shap values</td>
      <td>2020-03-12</td>
      <td>2020-03-12</td>
      <td>1262</td>
      <td>1262</td>
      <td>NONE</td>
      <td>1</td>
      <td>745.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2452</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>452</td>
      <td>BART Abstractive Summarisation Output crossed out and shortened</td>
      <td>2022-07-13</td>
      <td>2022-12-19</td>
      <td>409</td>
      <td>250</td>
      <td>NONE</td>
      <td>2</td>
      <td>745.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1485</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>485</td>
      <td>How do you use `force_plot` html in a web application?</td>
      <td>2020-10-02</td>
      <td>2020-10-17</td>
      <td>1057</td>
      <td>1043</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>746.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1880</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>880</td>
      <td>shap_values in DeepExplainer not returning an Explanation Object with data and base values</td>
      <td>2021-04-23</td>
      <td>2021-05-27</td>
      <td>854</td>
      <td>821</td>
      <td>NONE</td>
      <td>1</td>
      <td>746.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2477</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>477</td>
      <td>\"invalid value encountered in true_divide\" Warning on Dependence pl</td>
      <td>2022-08-16</td>
      <td>2022-08-16</td>
      <td>375</td>
      <td>375</td>
      <td>NONE</td>
      <td>0</td>
      <td>747.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1710</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>710</td>
      <td>beeswarm and scatter plot for multivariate data</td>
      <td>2021-01-18</td>
      <td>2021-01-18</td>
      <td>950</td>
      <td>950</td>
      <td>NONE</td>
      <td>0</td>
      <td>748.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2409</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>409</td>
      <td>Error with matplolib version 3.5.2 with dependence_plot</td>
      <td>2022-06-03</td>
      <td>2022-06-03</td>
      <td>449</td>
      <td>449</td>
      <td>NONE</td>
      <td>0</td>
      <td>748.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>120</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>20</td>
      <td>Auto-display in Jupyter Notebook when running via python script</td>
      <td>2018-06-19</td>
      <td>2018-07-17</td>
      <td>1894</td>
      <td>1866</td>
      <td>NONE</td>
      <td>6</td>
      <td>749.0</td>
      <td>No</td>
      <td>Issue with auto-display in series affecting the body rendering.</td>
      <td>"Shape Error"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1323</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>323</td>
      <td>Regularization in explainer.shap_values: what is the sample space of masks?</td>
      <td>2020-07-20</td>
      <td>2020-07-22</td>
      <td>1132</td>
      <td>1130</td>
      <td>NONE</td>
      <td>1</td>
      <td>750.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1936</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>936</td>
      <td>DeepExplainer Attribute Error</td>
      <td>2021-05-31</td>
      <td>2022-04-06</td>
      <td>817</td>
      <td>507</td>
      <td>NONE</td>
      <td>3</td>
      <td>751.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>794</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>94</td>
      <td>Kernel SHAP Probabilities predictions</td>
      <td>2019-09-05</td>
      <td>2019-09-05</td>
      <td>1450</td>
      <td>1450</td>
      <td>NONE</td>
      <td>0</td>
      <td>752.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2185</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>185</td>
      <td>No op_handler for \"Split\" in deep_tf.</td>
      <td>2021-12-14</td>
      <td>2023-07-18</td>
      <td>620</td>
      <td>38</td>
      <td>NONE</td>
      <td>2</td>
      <td>752.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2367</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>367</td>
      <td>Add parameter to transform annotations in plots according to a scaler or custom function</td>
      <td>2022-04-28</td>
      <td>2022-04-28</td>
      <td>484</td>
      <td>484</td>
      <td>NONE</td>
      <td>0</td>
      <td>754.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2813</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>813</td>
      <td>MAINT: Improve unit test execution speed</td>
      <td>2023-06-26</td>
      <td>2023-07-30</td>
      <td>61</td>
      <td>26</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>758.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1047</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>047</td>
      <td>sigmoid vs. softmax</td>
      <td>2020-02-16</td>
      <td>2020-06-26</td>
      <td>1287</td>
      <td>1156</td>
      <td>NONE</td>
      <td>1</td>
      <td>759.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2156</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>156</td>
      <td>pyspark RandomForestRegressionModel save error AttributeError: 'TreeEnsemble' object has no attribute 'save'</td>
      <td>2021-11-23</td>
      <td>2022-01-06</td>
      <td>641</td>
      <td>597</td>
      <td>NONE</td>
      <td>2</td>
      <td>763.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2232</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>232</td>
      <td>Consider update the introduction notebook</td>
      <td>2022-01-30</td>
      <td>2022-01-30</td>
      <td>573</td>
      <td>573</td>
      <td>NONE</td>
      <td>0</td>
      <td>765.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1963</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>963</td>
      <td>Shap value for LSTM model</td>
      <td>2021-06-20</td>
      <td>2021-12-11</td>
      <td>796</td>
      <td>623</td>
      <td>NONE</td>
      <td>1</td>
      <td>766.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1815</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>815</td>
      <td>Changing color and saving image</td>
      <td>2021-03-10</td>
      <td>2021-03-10</td>
      <td>899</td>
      <td>899</td>
      <td>NONE</td>
      <td>0</td>
      <td>769.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1554</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>554</td>
      <td>Using ragged tensors</td>
      <td>2020-11-13</td>
      <td>2020-11-13</td>
      <td>1016</td>
      <td>1016</td>
      <td>NONE</td>
      <td>3</td>
      <td>771.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1556</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>556</td>
      <td>issues with shap.Force_plot in Spyder</td>
      <td>2020-11-13</td>
      <td>2020-11-13</td>
      <td>1016</td>
      <td>1016</td>
      <td>NONE</td>
      <td>0</td>
      <td>771.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2570</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>570</td>
      <td>What python code or algorithm corresponds to \"Kernel SHAP 1,000 mean ref.\" listed in Figure 3 of the main TreeSHAP reference paper Lundberg, S.M., Erion, G., Chen, H. et al. From local explanations to global understanding with explainable AI for trees. Nat Mach Intell 2, 5667 (2020</td>
      <td>2022-11-04</td>
      <td>2022-11-04</td>
      <td>295</td>
      <td>295</td>
      <td>NONE</td>
      <td>0</td>
      <td>772.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1592</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>592</td>
      <td>Help speeding up SHAP runtime</td>
      <td>2020-12-04</td>
      <td>2021-02-26</td>
      <td>995</td>
      <td>910</td>
      <td>NONE</td>
      <td>1</td>
      <td>775.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>987</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>87</td>
      <td>SHAP Main Effect Plot Unexpected Output</td>
      <td>2020-01-07</td>
      <td>2020-01-07</td>
      <td>1326</td>
      <td>1326</td>
      <td>NONE</td>
      <td>0</td>
      <td>775.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1119</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>119</td>
      <td>How SHAP handle multi-collinearity</td>
      <td>2020-03-24</td>
      <td>2023-08-14</td>
      <td>1250</td>
      <td>12</td>
      <td>NONE</td>
      <td>16</td>
      <td>775.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>881</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>81</td>
      <td>Possible problem with using conditional vs marginal expectation for dropped features in Tree SHAP?</td>
      <td>2019-11-05</td>
      <td>2023-07-06</td>
      <td>1390</td>
      <td>51</td>
      <td>NONE</td>
      <td>10</td>
      <td>778.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2598</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>598</td>
      <td>Are y labels in shap.datasets.nhanesi really the survival times?</td>
      <td>2022-12-04</td>
      <td>2023-04-15</td>
      <td>265</td>
      <td>133</td>
      <td>NONE</td>
      <td>4</td>
      <td>781.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2313</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>313</td>
      <td>error during installation of shap v0.39.0 (macOS Monterrey 12.3)</td>
      <td>2022-03-29</td>
      <td>2022-03-29</td>
      <td>515</td>
      <td>515</td>
      <td>NONE</td>
      <td>0</td>
      <td>782.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1271</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>271</td>
      <td>Tree explainer interaction values not working for catboost</td>
      <td>2020-06-16</td>
      <td>2021-09-12</td>
      <td>1166</td>
      <td>712</td>
      <td>NONE</td>
      <td>2</td>
      <td>783.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>561</td>
      <td><a href="https://github.com/shap/shap/issues/562">562</a></td>
      <td>'model_output: probability' support for TreeExplainer</td>
      <td>2019-04-25</td>
      <td>2023-08-15</td>
      <td>1584</td>
      <td>11</td>
      <td>NONE</td>
      <td>9</td>
      <td>787.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2681</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>681</td>
      <td>[New Features] Output figures as interactive web components with plotly.py</td>
      <td>2023-03-18</td>
      <td>2023-08-14</td>
      <td>161</td>
      <td>12</td>
      <td>NONE</td>
      <td>1</td>
      <td>791.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1331</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>331</td>
      <td>Is SHAP applicable to these multivariable datasets?</td>
      <td>2020-07-28</td>
      <td>2022-08-09</td>
      <td>1124</td>
      <td>382</td>
      <td>NONE</td>
      <td>1</td>
      <td>793.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2373</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>373</td>
      <td>Cannot use \"interventional\" mode with CatBoostRegress</td>
      <td>2022-05-02</td>
      <td>2022-05-02</td>
      <td>481</td>
      <td>481</td>
      <td>NONE</td>
      <td>0</td>
      <td>795.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1966</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>966</td>
      <td>Change the direction of arrow in the force_plot</td>
      <td>2021-06-22</td>
      <td>2021-06-22</td>
      <td>795</td>
      <td>795</td>
      <td>NONE</td>
      <td>0</td>
      <td>796.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1419</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>419</td>
      <td>Error in WaterFall Plot</td>
      <td>2020-09-10</td>
      <td>2023-07-10</td>
      <td>1080</td>
      <td>46</td>
      <td>NONE</td>
      <td>27</td>
      <td>798.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1182</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>182</td>
      <td>Interpreting a single prediction in case of imbalanced dataset</td>
      <td>2020-04-27</td>
      <td>2020-10-28</td>
      <td>1215</td>
      <td>1032</td>
      <td>NONE</td>
      <td>1</td>
      <td>802.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>328</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>28</td>
      <td>pytorch support for categorical and continuous variables</td>
      <td>2018-11-15</td>
      <td>2018-11-23</td>
      <td>1745</td>
      <td>1736</td>
      <td>NONE</td>
      <td>1</td>
      <td>803.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>396</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>96</td>
      <td>Questions about SHAP handling categorical variables</td>
      <td>2019-01-18</td>
      <td>2022-02-23</td>
      <td>1680</td>
      <td>549</td>
      <td>NONE</td>
      <td>15</td>
      <td>803.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1866</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>866</td>
      <td>new_base_value meaning</td>
      <td>2021-04-13</td>
      <td>2021-04-13</td>
      <td>865</td>
      <td>865</td>
      <td>NONE</td>
      <td>0</td>
      <td>805.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1455</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>455</td>
      <td>TypeError: 'NoneType' object cannot be interpreted as an integer</td>
      <td>2020-09-22</td>
      <td>2022-09-21</td>
      <td>1068</td>
      <td>339</td>
      <td>NONE</td>
      <td>16</td>
      <td>805.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1811</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>811</td>
      <td>How to manually look at shap clustering?</td>
      <td>2021-03-09</td>
      <td>2021-03-09</td>
      <td>900</td>
      <td>900</td>
      <td>NONE</td>
      <td>0</td>
      <td>806.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2284</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>284</td>
      <td>SHAP global feature importance using Random forest regression</td>
      <td>2022-03-15</td>
      <td>2022-03-15</td>
      <td>529</td>
      <td>529</td>
      <td>NONE</td>
      <td>0</td>
      <td>812.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>764</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>64</td>
      <td>dependence plot not showing the original display features' value</td>
      <td>2019-08-22</td>
      <td>2019-08-27</td>
      <td>1465</td>
      <td>1460</td>
      <td>NONE</td>
      <td>1</td>
      <td>813.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1366</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>366</td>
      <td>What is the shap_value output of dependence_plot ?</td>
      <td>2020-08-16</td>
      <td>2020-08-17</td>
      <td>1104</td>
      <td>1104</td>
      <td>NONE</td>
      <td>0</td>
      <td>816.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2087</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>087</td>
      <td>Can I use different background samples for each permutation in KernelSHAP</td>
      <td>2021-09-26</td>
      <td>2021-09-28</td>
      <td>699</td>
      <td>697</td>
      <td>NONE</td>
      <td>0</td>
      <td>819.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>189</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>89</td>
      <td>heuristic for displaying the most important features in the explanation to the user?</td>
      <td>2018-07-30</td>
      <td>2018-07-30</td>
      <td>1853</td>
      <td>1853</td>
      <td>NONE</td>
      <td>1</td>
      <td>822.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2138</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>138</td>
      <td>how to use shap.plots.text?</td>
      <td>2021-11-16</td>
      <td>2021-11-16</td>
      <td>648</td>
      <td>648</td>
      <td>NONE</td>
      <td>0</td>
      <td>826.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2466</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>466</td>
      <td>Unable to Slice Out A Single Token From All Instances</td>
      <td>2022-07-29</td>
      <td>2023-07-27</td>
      <td>393</td>
      <td>30</td>
      <td>NONE</td>
      <td>29</td>
      <td>830.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2478</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>478</td>
      <td>Colorbar does not show properly in dependent plot</td>
      <td>2022-08-16</td>
      <td>2023-01-13</td>
      <td>374</td>
      <td>224</td>
      <td>NONE</td>
      <td>3</td>
      <td>832.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1969</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>969</td>
      <td>Using Training data with SHAP</td>
      <td>2021-06-24</td>
      <td>2021-06-24</td>
      <td>793</td>
      <td>793</td>
      <td>NONE</td>
      <td>0</td>
      <td>832.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>452</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>52</td>
      <td>IndexError in shap summary plot</td>
      <td>2019-02-20</td>
      <td>2019-11-01</td>
      <td>1648</td>
      <td>1394</td>
      <td>NONE</td>
      <td>12</td>
      <td>833.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>646</td>
      <td><a href="https://github.com/shap/shap/issues/647">647</a></td>
      <td>inconsistency meaning</td>
      <td>2019-06-16</td>
      <td>2021-05-31</td>
      <td>1532</td>
      <td>817</td>
      <td>NONE</td>
      <td>6</td>
      <td>833.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1643</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>643</td>
      <td>Mismatch between force_plot() output from DeepExplainer and actual model's output</td>
      <td>2020-12-21</td>
      <td>2022-07-04</td>
      <td>978</td>
      <td>418</td>
      <td>NONE</td>
      <td>5</td>
      <td>836.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2366</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>366</td>
      <td>SHAP for Motion Prediction in Autonomous Driving</td>
      <td>2022-04-28</td>
      <td>2023-04-24</td>
      <td>484</td>
      <td>124</td>
      <td>NONE</td>
      <td>2</td>
      <td>836.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1086</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>086</td>
      <td>SGDClassifier</td>
      <td>2020-03-05</td>
      <td>2023-04-27</td>
      <td>1268</td>
      <td>121</td>
      <td>NONE</td>
      <td>2</td>
      <td>839.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1926</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>926</td>
      <td>Catboost error with GPUTree Explainer</td>
      <td>2021-05-23</td>
      <td>2021-08-02</td>
      <td>825</td>
      <td>754</td>
      <td>NONE</td>
      <td>1</td>
      <td>842.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>831</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>31</td>
      <td>Handling Transformer-style embeddings for sequence input</td>
      <td>2019-09-25</td>
      <td>2021-03-22</td>
      <td>1431</td>
      <td>887</td>
      <td>NONE</td>
      <td>8</td>
      <td>843.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>798</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>98</td>
      <td>Image_plot has overlap output</td>
      <td>2019-09-06</td>
      <td>2019-09-06</td>
      <td>1450</td>
      <td>1450</td>
      <td>NONE</td>
      <td>0</td>
      <td>844.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1901</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>901</td>
      <td>DeepExplainer.supports_model returns False for a simple model</td>
      <td>2021-05-06</td>
      <td>2021-05-06</td>
      <td>842</td>
      <td>842</td>
      <td>NONE</td>
      <td>0</td>
      <td>844.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>549</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>9</td>
      <td>Using SHAP for object detection (SSD)</td>
      <td>2019-04-12</td>
      <td>2021-05-01</td>
      <td>1597</td>
      <td>847</td>
      <td>NONE</td>
      <td>5</td>
      <td>844.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1117</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>117</td>
      <td>How to use background in DeepExplainer with multiple input types as data</td>
      <td>2020-03-23</td>
      <td>2020-03-23</td>
      <td>1251</td>
      <td>1251</td>
      <td>NONE</td>
      <td>0</td>
      <td>846.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>332</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>32</td>
      <td>TREE SHAP gives SHAP values for text tokens which are not present in the text</td>
      <td>2018-11-21</td>
      <td>2023-06-25</td>
      <td>1739</td>
      <td>62</td>
      <td>NONE</td>
      <td>1</td>
      <td>847.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2903</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>903</td>
      <td>ENH: Deprecate and remove legacy functions</td>
      <td>2023-07-30</td>
      <td>2023-08-22</td>
      <td>27</td>
      <td>3</td>
      <td>COLLABORATOR</td>
      <td>4</td>
      <td>849.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2049</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>049</td>
      <td>Figures in \"Be careful when interpreting predictive models in search of causal insights\" are not fou</td>
      <td>2021-08-25</td>
      <td>2022-01-05</td>
      <td>731</td>
      <td>597</td>
      <td>NONE</td>
      <td>1</td>
      <td>849.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2143</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>143</td>
      <td>DeepExplainer crashes when deeplift_grad hook receives nonlinear_1d handler</td>
      <td>2021-11-18</td>
      <td>2023-01-02</td>
      <td>646</td>
      <td>235</td>
      <td>NONE</td>
      <td>3</td>
      <td>850.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1077</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>077</td>
      <td>ImportError: assert_import</td>
      <td>2020-03-02</td>
      <td>2020-03-02</td>
      <td>1272</td>
      <td>1272</td>
      <td>NONE</td>
      <td>1</td>
      <td>852.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1291</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>291</td>
      <td>The shap summary plot shown different between linearExplainer and treeExplainer on same dataset</td>
      <td>2020-06-25</td>
      <td>2020-06-25</td>
      <td>1156</td>
      <td>1156</td>
      <td>NONE</td>
      <td>0</td>
      <td>853.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2394</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>394</td>
      <td>Catboost Regression: TreeEnsemble object has no attribute values BUG</td>
      <td>2022-05-19</td>
      <td>2023-07-05</td>
      <td>464</td>
      <td>52</td>
      <td>NONE</td>
      <td>1</td>
      <td>854.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2493</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>493</td>
      <td>TreeExplainer on XGBoost producing same output value (f(x)) for every instance in shap.plots.force()</td>
      <td>2022-08-30</td>
      <td>2022-08-30</td>
      <td>361</td>
      <td>361</td>
      <td>NONE</td>
      <td>0</td>
      <td>855.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1034</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>034</td>
      <td>Why does it convert data to GPU all at once in `DeepExplainer` of Pytorch?</td>
      <td>2020-02-09</td>
      <td>2020-02-14</td>
      <td>1294</td>
      <td>1289</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>856.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1176</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>176</td>
      <td>Performance for large scale usage</td>
      <td>2020-04-25</td>
      <td>2021-01-10</td>
      <td>1218</td>
      <td>958</td>
      <td>NONE</td>
      <td>2</td>
      <td>856.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2363</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>363</td>
      <td>Remove try exception around matplotlib import</td>
      <td>2022-04-27</td>
      <td>2022-04-27</td>
      <td>486</td>
      <td>486</td>
      <td>NONE</td>
      <td>0</td>
      <td>857.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1081</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>081</td>
      <td>Tree Path Dependent expected value</td>
      <td>2020-03-03</td>
      <td>2022-07-27</td>
      <td>1271</td>
      <td>394</td>
      <td>NONE</td>
      <td>4</td>
      <td>858.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1742</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>742</td>
      <td>React: AdditiveForceVisualizer does not show dividers and background for input features</td>
      <td>2021-01-27</td>
      <td>2022-04-20</td>
      <td>941</td>
      <td>493</td>
      <td>NONE</td>
      <td>2</td>
      <td>859.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>629</td>
      <td><a href="https://github.com/shap/shap/issues/63">63</a>9</td>
      <td>Model accuracy for using SHAP and advice on using folds.</td>
      <td>2019-06-05</td>
      <td>2020-06-26</td>
      <td>1543</td>
      <td>1156</td>
      <td>NONE</td>
      <td>2</td>
      <td>862.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2095</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>095</td>
      <td>ValueError: could not convert string to float when computing shap_values for numpy.array input features type</td>
      <td>2021-10-05</td>
      <td>2022-06-28</td>
      <td>690</td>
      <td>423</td>
      <td>NONE</td>
      <td>1</td>
      <td>865.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1919</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>919</td>
      <td>savefig for SHAP Approximate_Interactions</td>
      <td>2021-05-18</td>
      <td>2021-05-18</td>
      <td>830</td>
      <td>830</td>
      <td>NONE</td>
      <td>0</td>
      <td>869.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2529</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>529</td>
      <td>The SHAP explanations do not sum up to the model's output!</td>
      <td>2022-09-27</td>
      <td>2022-09-29</td>
      <td>333</td>
      <td>331</td>
      <td>NONE</td>
      <td>1</td>
      <td>874.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1232</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>232</td>
      <td>explainer.expected_value Type Inconsistencies</td>
      <td>2020-05-26</td>
      <td>2020-05-26</td>
      <td>1187</td>
      <td>1187</td>
      <td>NONE</td>
      <td>0</td>
      <td>874.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1590</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>590</td>
      <td>Several bug fix to call SHAP from EconML</td>
      <td>2020-12-03</td>
      <td>2020-12-04</td>
      <td>996</td>
      <td>994</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>875.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1172</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>172</td>
      <td>MemoryError: Unable to allocate array with shape (2602, 7470630) and data type float64</td>
      <td>2020-04-23</td>
      <td>2021-08-27</td>
      <td>1220</td>
      <td>728</td>
      <td>NONE</td>
      <td>8</td>
      <td>884.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2425</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>425</td>
      <td>generating text plots with custom model BART model results in page unresponsive error</td>
      <td>2022-06-13</td>
      <td>2022-07-19</td>
      <td>439</td>
      <td>403</td>
      <td>NONE</td>
      <td>3</td>
      <td>884.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1850</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>850</td>
      <td>Is there a way to link the features of model A to the output of model B?</td>
      <td>2021-04-01</td>
      <td>2021-04-01</td>
      <td>877</td>
      <td>877</td>
      <td>NONE</td>
      <td>0</td>
      <td>888.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2212</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>212</td>
      <td>[contributions_matrix] How to convert logodds explanations to probabilities?</td>
      <td>2022-01-10</td>
      <td>2022-01-10</td>
      <td>593</td>
      <td>593</td>
      <td>NONE</td>
      <td>0</td>
      <td>889.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1345</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>345</td>
      <td>Additivity check failed in TreeExplainer for ExtraTreesClassifier</td>
      <td>2020-08-04</td>
      <td>2022-07-26</td>
      <td>1117</td>
      <td>396</td>
      <td>NONE</td>
      <td>2</td>
      <td>889.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>895</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>95</td>
      <td>Recovering shap values from interaction shap values</td>
      <td>2019-11-13</td>
      <td>2019-11-13</td>
      <td>1381</td>
      <td>1381</td>
      <td>NONE</td>
      <td>0</td>
      <td>890.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1187</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>187</td>
      <td>Regression target pre-processing and displaying original target in decision_plot</td>
      <td>2020-04-29</td>
      <td>2020-04-29</td>
      <td>1214</td>
      <td>1214</td>
      <td>NONE</td>
      <td>0</td>
      <td>891.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2073</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>073</td>
      <td>AttributeError: 'Kernel' object has no attribute 'masker'</td>
      <td>2021-09-15</td>
      <td>2022-06-14</td>
      <td>710</td>
      <td>437</td>
      <td>NONE</td>
      <td>5</td>
      <td>891.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1128</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>128</td>
      <td>error running mnist deepexplainer</td>
      <td>2020-04-02</td>
      <td>2021-04-04</td>
      <td>1241</td>
      <td>874</td>
      <td>NONE</td>
      <td>10</td>
      <td>893.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>967</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>67</td>
      <td>How to use Shap with GridsearchCV?</td>
      <td>2019-12-23</td>
      <td>2019-12-28</td>
      <td>1342</td>
      <td>1337</td>
      <td>NONE</td>
      <td>4</td>
      <td>897.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1980</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>980</td>
      <td>SHAP summary plot does not shows contribution of features for each classes of binary class.</td>
      <td>2021-07-04</td>
      <td>2021-07-23</td>
      <td>783</td>
      <td>763</td>
      <td>NONE</td>
      <td>3</td>
      <td>898.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2038</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>038</td>
      <td>How to calculate SHAP_interaction_Values for NN models</td>
      <td>2021-08-15</td>
      <td>2023-01-08</td>
      <td>740</td>
      <td>230</td>
      <td>NONE</td>
      <td>3</td>
      <td>900.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1237</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>237</td>
      <td>Shap Deep Explainer is giving irrelevant results</td>
      <td>2020-05-28</td>
      <td>2020-07-01</td>
      <td>1185</td>
      <td>1151</td>
      <td>NONE</td>
      <td>8</td>
      <td>902.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1501</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>501</td>
      <td>model_output='log_loss' support for multiclass objectives</td>
      <td>2020-10-10</td>
      <td>2021-01-14</td>
      <td>1050</td>
      <td>953</td>
      <td>NONE</td>
      <td>2</td>
      <td>904.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1604</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>604</td>
      <td>Documentation Error</td>
      <td>2020-12-09</td>
      <td>2020-12-12</td>
      <td>990</td>
      <td>987</td>
      <td>NONE</td>
      <td>1</td>
      <td>907.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>950</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>50</td>
      <td>Numpy deprecation warning</td>
      <td>2019-12-13</td>
      <td>2023-07-09</td>
      <td>1352</td>
      <td>48</td>
      <td>NONE</td>
      <td>6</td>
      <td>910.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1814</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>814</td>
      <td>how to get an overall attribution from a KernelExplainer</td>
      <td>2021-03-10</td>
      <td>2022-02-25</td>
      <td>899</td>
      <td>546</td>
      <td>NONE</td>
      <td>1</td>
      <td>910.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>778</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>78</td>
      <td>dependence_plot messes up the figure layout where multiple axes are used</td>
      <td>2019-08-28</td>
      <td>2019-08-30</td>
      <td>1459</td>
      <td>1456</td>
      <td>NONE</td>
      <td>1</td>
      <td>910.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1828</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>828</td>
      <td>Are Shap feature importance (the global one) additive?</td>
      <td>2021-03-22</td>
      <td>2021-03-24</td>
      <td>887</td>
      <td>885</td>
      <td>NONE</td>
      <td>1</td>
      <td>912.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2568</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>568</td>
      <td>Interventional tree SHAPs per class for LGBM</td>
      <td>2022-11-03</td>
      <td>2022-11-03</td>
      <td>296</td>
      <td>296</td>
      <td>NONE</td>
      <td>1</td>
      <td>915.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1885</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>885</td>
      <td>how to interoperate &lt;&lt;ind&gt;&gt;  in shap.partial_dependence_plot</td>
      <td>2021-04-27</td>
      <td>2021-04-27</td>
      <td>851</td>
      <td>851</td>
      <td>NONE</td>
      <td>0</td>
      <td>916.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2187</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>187</td>
      <td>AssertionError: The model produced 3 output rows when given 1 input rows!</td>
      <td>2021-12-16</td>
      <td>2021-12-16</td>
      <td>618</td>
      <td>618</td>
      <td>NONE</td>
      <td>0</td>
      <td>918.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2401</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>401</td>
      <td>What should the data look like in order to interact with shap?</td>
      <td>2022-05-30</td>
      <td>2022-05-30</td>
      <td>453</td>
      <td>453</td>
      <td>NONE</td>
      <td>0</td>
      <td>925.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2255</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>255</td>
      <td>Univariate timeseries regression</td>
      <td>2022-02-20</td>
      <td>2022-02-20</td>
      <td>551</td>
      <td>551</td>
      <td>NONE</td>
      <td>0</td>
      <td>927.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1096</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>096</td>
      <td>Issues in interpreting Shap values for marketing mix optimization problems</td>
      <td>2020-03-12</td>
      <td>2020-03-12</td>
      <td>1262</td>
      <td>1262</td>
      <td>NONE</td>
      <td>0</td>
      <td>927.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>421</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>21</td>
      <td>Questions about tree shap paper</td>
      <td>2019-02-01</td>
      <td>2019-04-29</td>
      <td>1667</td>
      <td>1580</td>
      <td>NONE</td>
      <td>3</td>
      <td>927.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1459</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>459</td>
      <td>Inconsistent usage of 'shap_value' in beeswarm</td>
      <td>2020-09-22</td>
      <td>2021-11-08</td>
      <td>1067</td>
      <td>656</td>
      <td>NONE</td>
      <td>13</td>
      <td>931.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1947</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>947</td>
      <td>CatBoostClassifier is missing one of the binary classes in the shap matrix</td>
      <td>2021-06-09</td>
      <td>2021-06-09</td>
      <td>808</td>
      <td>808</td>
      <td>NONE</td>
      <td>0</td>
      <td>931.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1194</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>194</td>
      <td>Shap TreeExplainer(model).shap_interaction_values returns None for LightGBM Regressor</td>
      <td>2020-05-02</td>
      <td>2020-05-02</td>
      <td>1211</td>
      <td>1211</td>
      <td>NONE</td>
      <td>0</td>
      <td>934.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>308</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>08</td>
      <td>AdditiveForceVisualizer: doing more with explanation similarity (sort order, etc.)</td>
      <td>2018-11-02</td>
      <td>2019-09-04</td>
      <td>1758</td>
      <td>1452</td>
      <td>NONE</td>
      <td>4</td>
      <td>935.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2206</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>206</td>
      <td>Can SHAP explain a model based on the lack of presence of a particular feature?</td>
      <td>2022-01-05</td>
      <td>2022-01-05</td>
      <td>598</td>
      <td>598</td>
      <td>NONE</td>
      <td>0</td>
      <td>936.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>558</td>
      <td><a href="https://github.com/shap/shap/issues/56">56</a>8</td>
      <td>Multi-input CNN architecture</td>
      <td>2019-04-22</td>
      <td>2021-07-04</td>
      <td>1587</td>
      <td>783</td>
      <td>NONE</td>
      <td>19</td>
      <td>938.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1700</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>700</td>
      <td>For SHAP (SHapley Additive exPlanations) which one is the positive and negative class?</td>
      <td>2021-01-14</td>
      <td>2021-01-28</td>
      <td>954</td>
      <td>940</td>
      <td>NONE</td>
      <td>2</td>
      <td>939.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1953</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>953</td>
      <td>Argument error in the LSTM example</td>
      <td>2021-06-10</td>
      <td>2021-06-10</td>
      <td>807</td>
      <td>807</td>
      <td>NONE</td>
      <td>0</td>
      <td>939.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>826</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>26</td>
      <td>DeepExplainer Gets All 0 Shap_Value Outputs</td>
      <td>2019-09-23</td>
      <td>2021-02-28</td>
      <td>1432</td>
      <td>909</td>
      <td>NONE</td>
      <td>1</td>
      <td>941.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>492</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>92</td>
      <td>predict() got an unexpected keyword argument 'validate_features'</td>
      <td>2019-03-14</td>
      <td>2021-08-03</td>
      <td>1626</td>
      <td>753</td>
      <td>NONE</td>
      <td>15</td>
      <td>942.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1195</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>195</td>
      <td>SHAP can calculate shap value using sklearn CalibratedClassifierCV  ?</td>
      <td>2020-05-04</td>
      <td>2023-06-14</td>
      <td>1209</td>
      <td>73</td>
      <td>NONE</td>
      <td>2</td>
      <td>943.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>520</td>
      <td><a href="https://github.com/shap/shap/issues/53">53</a>0</td>
      <td>The C extension could not be compiled, sklearn tree models not supported.</td>
      <td>2019-03-29</td>
      <td>2022-10-30</td>
      <td>1611</td>
      <td>300</td>
      <td>NONE</td>
      <td>4</td>
      <td>943.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>126</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>26</td>
      <td>TreeSHAP for Apache Solr boosted trees json model</td>
      <td>2018-06-21</td>
      <td>2018-06-21</td>
      <td>1892</td>
      <td>1892</td>
      <td>NONE</td>
      <td>1</td>
      <td>944.0</td>
      <td>No</td>
      <td>"TreeSHAP for A issue needs addressing."</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2115</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>115</td>
      <td>Minor Suggestions for Improvement of Introductory Notebook</td>
      <td>2021-10-25</td>
      <td>2023-06-04</td>
      <td>670</td>
      <td>83</td>
      <td>NONE</td>
      <td>0</td>
      <td>945.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2134</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>134</td>
      <td>ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()</td>
      <td>2021-11-12</td>
      <td>2022-06-14</td>
      <td>652</td>
      <td>437</td>
      <td>NONE</td>
      <td>5</td>
      <td>948.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2005</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>005</td>
      <td>Difference between local shap values coming from global and from the \"shap_values\"-meth</td>
      <td>2021-07-20</td>
      <td>2022-08-17</td>
      <td>767</td>
      <td>374</td>
      <td>NONE</td>
      <td>3</td>
      <td>949.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2619</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>619</td>
      <td>AttributeError: 'tuple' object has no attribute 'device' for tuple output</td>
      <td>2022-12-19</td>
      <td>2023-08-26</td>
      <td>249</td>
      <td>0</td>
      <td>NONE</td>
      <td>2</td>
      <td>949.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1223</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>223</td>
      <td>Shap Values from kernel Explainer Change drastically with background example set change.</td>
      <td>2020-05-22</td>
      <td>2020-05-22</td>
      <td>1190</td>
      <td>1190</td>
      <td>NONE</td>
      <td>0</td>
      <td>949.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>567</td>
      <td><a href="https://github.com/shap/shap/issues/568">568</a></td>
      <td>Details of feature_dependence=independent in TreeExplainer</td>
      <td>2019-04-29</td>
      <td>2023-06-23</td>
      <td>1580</td>
      <td>64</td>
      <td>NONE</td>
      <td>2</td>
      <td>950.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>864</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>64</td>
      <td>GradientExplainer has no expected values: how to interpret it.</td>
      <td>2019-10-24</td>
      <td>2020-12-16</td>
      <td>1402</td>
      <td>983</td>
      <td>NONE</td>
      <td>3</td>
      <td>953.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>497</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>97</td>
      <td>I am using DeepExplainer, I need mini-batch.</td>
      <td>2019-03-19</td>
      <td>2020-01-28</td>
      <td>1621</td>
      <td>1306</td>
      <td>NONE</td>
      <td>3</td>
      <td>953.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2305</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>305</td>
      <td>Dealing with SHAP on multivariate LSTM network with multiple timesteps</td>
      <td>2022-03-24</td>
      <td>2022-03-24</td>
      <td>520</td>
      <td>520</td>
      <td>NONE</td>
      <td>0</td>
      <td>954.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1165</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>165</td>
      <td>How to use SHAP on Multivariate Time Series Forecast?</td>
      <td>2020-04-21</td>
      <td>2022-10-23</td>
      <td>1222</td>
      <td>307</td>
      <td>NONE</td>
      <td>4</td>
      <td>957.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2325</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>325</td>
      <td>The sum of every dots' shap values should be zero or not?</td>
      <td>2022-04-04</td>
      <td>2022-04-04</td>
      <td>509</td>
      <td>509</td>
      <td>NONE</td>
      <td>0</td>
      <td>957.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>674</td>
      <td><a href="https://github.com/shap/shap/issues/675">675</a></td>
      <td>TreeExplainer one and zero paths understanding</td>
      <td>2019-07-02</td>
      <td>2019-07-02</td>
      <td>1516</td>
      <td>1516</td>
      <td>NONE</td>
      <td>0</td>
      <td>958.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>874</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>74</td>
      <td>Understand SHAP value for Multi-class Problems</td>
      <td>2019-10-29</td>
      <td>2019-10-29</td>
      <td>1397</td>
      <td>1397</td>
      <td>NONE</td>
      <td>0</td>
      <td>961.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>511</td>
      <td><a href="https://github.com/shap/shap/issues/52">52</a>1</td>
      <td>TreeExplainer vs. KernelExplainer</td>
      <td>2019-03-26</td>
      <td>2022-04-02</td>
      <td>1614</td>
      <td>511</td>
      <td>NONE</td>
      <td>1</td>
      <td>962.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2018</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>018</td>
      <td>Differences between Sampling explainer and IME?</td>
      <td>2021-07-31</td>
      <td>2021-07-31</td>
      <td>755</td>
      <td>755</td>
      <td>NONE</td>
      <td>0</td>
      <td>965.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1298</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>298</td>
      <td>feature engineering + interactions, possible?</td>
      <td>2020-07-05</td>
      <td>2021-02-06</td>
      <td>1147</td>
      <td>931</td>
      <td>NONE</td>
      <td>1</td>
      <td>968.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1054</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>054</td>
      <td>TFDeepExplainer broken with TF2.1.0</td>
      <td>2020-02-20</td>
      <td>2022-12-22</td>
      <td>1283</td>
      <td>246</td>
      <td>NONE</td>
      <td>16</td>
      <td>970.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2664</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>664</td>
      <td>Problems about using Shap to explain deep adaptation network or GCN model</td>
      <td>2023-02-20</td>
      <td>2023-02-20</td>
      <td>187</td>
      <td>187</td>
      <td>NONE</td>
      <td>0</td>
      <td>970.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2331</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>331</td>
      <td>SHAP All Positive</td>
      <td>2022-04-06</td>
      <td>2022-08-08</td>
      <td>506</td>
      <td>383</td>
      <td>NONE</td>
      <td>1</td>
      <td>973.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1622</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>622</td>
      <td>how to extract the most important LOCAL feature names</td>
      <td>2020-12-15</td>
      <td>2021-01-22</td>
      <td>984</td>
      <td>946</td>
      <td>NONE</td>
      <td>2</td>
      <td>977.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1547</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>547</td>
      <td>Issue with the sum of Shap values of each classes and summary_plot</td>
      <td>2020-11-09</td>
      <td>2021-04-23</td>
      <td>1020</td>
      <td>854</td>
      <td>NONE</td>
      <td>2</td>
      <td>978.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>397</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>97</td>
      <td>Error when doing shap dependence plot of a single variable</td>
      <td>2019-01-18</td>
      <td>2022-09-19</td>
      <td>1680</td>
      <td>341</td>
      <td>NONE</td>
      <td>4</td>
      <td>980.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>837</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>37</td>
      <td>Questions about TreeExplainer runtime speed</td>
      <td>2019-09-29</td>
      <td>2023-06-20</td>
      <td>1427</td>
      <td>67</td>
      <td>NONE</td>
      <td>12</td>
      <td>980.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2154</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>154</td>
      <td>Logit non-linearity and Shapely values</td>
      <td>2021-11-22</td>
      <td>2021-11-22</td>
      <td>641</td>
      <td>641</td>
      <td>NONE</td>
      <td>0</td>
      <td>981.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1196</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>196</td>
      <td>Difference between shap.sample and n_samples</td>
      <td>2020-05-05</td>
      <td>2020-08-20</td>
      <td>1207</td>
      <td>1101</td>
      <td>NONE</td>
      <td>1</td>
      <td>983.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1505</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>505</td>
      <td>Differences in machine learning and statistical methods</td>
      <td>2020-10-13</td>
      <td>2020-11-02</td>
      <td>1047</td>
      <td>1027</td>
      <td>NONE</td>
      <td>1</td>
      <td>984.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>824</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>24</td>
      <td>How to use DeepSHAP with keras Sequential models?</td>
      <td>2019-09-23</td>
      <td>2020-02-13</td>
      <td>1433</td>
      <td>1289</td>
      <td>NONE</td>
      <td>1</td>
      <td>984.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1769</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>769</td>
      <td>Raise exception early if data to explain does not match data the model was trained on</td>
      <td>2021-02-11</td>
      <td>2021-02-11</td>
      <td>926</td>
      <td>926</td>
      <td>NONE</td>
      <td>0</td>
      <td>985.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1827</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>827</td>
      <td>Bug in _estimate_transforms function of Linear Explainer?</td>
      <td>2021-03-22</td>
      <td>2021-03-22</td>
      <td>887</td>
      <td>887</td>
      <td>NONE</td>
      <td>0</td>
      <td>987.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1900</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>900</td>
      <td>Cohort bar plot fails with IndexError: too many indices for array</td>
      <td>2021-05-06</td>
      <td>2021-05-06</td>
      <td>842</td>
      <td>842</td>
      <td>NONE</td>
      <td>0</td>
      <td>989.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1975</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>975</td>
      <td>Errors in \"Be careful when interpreting predictive models in search of causal insights</td>
      <td>2021-06-29</td>
      <td>2021-06-29</td>
      <td>788</td>
      <td>788</td>
      <td>NONE</td>
      <td>0</td>
      <td>992.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>828</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>28</td>
      <td>Can do the  multi-Progress when calculating the shap_values?</td>
      <td>2019-09-24</td>
      <td>2019-10-09</td>
      <td>1432</td>
      <td>1417</td>
      <td>NONE</td>
      <td>2</td>
      <td>993.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1075</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>075</td>
      <td>conda install shap cannot import; pip install shap fail; AttributeError: module 'shap' has no attribute 'initjs'</td>
      <td>2020-03-02</td>
      <td>2020-04-02</td>
      <td>1272</td>
      <td>1240</td>
      <td>NONE</td>
      <td>2</td>
      <td>994.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>770</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>70</td>
      <td>unable to use force_plot</td>
      <td>2019-08-26</td>
      <td>2022-07-22</td>
      <td>1461</td>
      <td>400</td>
      <td>NONE</td>
      <td>4</td>
      <td>996.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2621</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>621</td>
      <td>TypeError: list indices must be integers or slices, not tuple when creating scatter plot of binary classification model</td>
      <td>2022-12-20</td>
      <td>2022-12-20</td>
      <td>249</td>
      <td>249</td>
      <td>NONE</td>
      <td>0</td>
      <td>999.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1286</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>286</td>
      <td>Jupyter kernel crash when running explainer.shap_values()</td>
      <td>2020-06-24</td>
      <td>2022-11-27</td>
      <td>1158</td>
      <td>272</td>
      <td>NONE</td>
      <td>3</td>
      <td>1003.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>552</td>
      <td><a href="https://github.com/shap/shap/issues/56">56</a>2</td>
      <td>SHAP values for single feature are all of one sign</td>
      <td>2019-04-12</td>
      <td>2019-10-02</td>
      <td>1596</td>
      <td>1423</td>
      <td>NONE</td>
      <td>9</td>
      <td>1004.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>594</td>
      <td><a href="https://github.com/shap/shap/issues/60">60</a>4</td>
      <td>Using DeepExplainer with torchtext</td>
      <td>2019-05-17</td>
      <td>2022-02-17</td>
      <td>1562</td>
      <td>555</td>
      <td>NONE</td>
      <td>12</td>
      <td>1004.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>694</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>4</td>
      <td>Dependence plot side bar sometimes out of scale?</td>
      <td>2019-07-10</td>
      <td>2020-03-03</td>
      <td>1508</td>
      <td>1271</td>
      <td>NONE</td>
      <td>8</td>
      <td>1004.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2456</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>456</td>
      <td>Waterfall plot does not work with RandomForestRegressor</td>
      <td>2022-07-19</td>
      <td>2022-09-12</td>
      <td>403</td>
      <td>348</td>
      <td>NONE</td>
      <td>2</td>
      <td>1005.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2310</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>310</td>
      <td>Why does the computer overheat when calculating shap value?</td>
      <td>2022-03-28</td>
      <td>2022-03-28</td>
      <td>516</td>
      <td>516</td>
      <td>NONE</td>
      <td>0</td>
      <td>1006.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>525</td>
      <td><a href="https://github.com/shap/shap/issues/53">53</a>5</td>
      <td>TreeExplainer on LightGBMClassifier returns 2D array of shap values in binary classification case</td>
      <td>2019-04-02</td>
      <td>2022-08-26</td>
      <td>1606</td>
      <td>365</td>
      <td>COLLABORATOR</td>
      <td>15</td>
      <td>1008.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1668</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>668</td>
      <td>Return json data in _force.py visualize method</td>
      <td>2020-12-31</td>
      <td>2020-12-31</td>
      <td>968</td>
      <td>968</td>
      <td>NONE</td>
      <td>0</td>
      <td>1009.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1971</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>971</td>
      <td>SHAP AttributeError: 'Tensor' object has no attribute 'copy'</td>
      <td>2021-06-25</td>
      <td>2021-07-05</td>
      <td>792</td>
      <td>782</td>
      <td>NONE</td>
      <td>4</td>
      <td>1010.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>797</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>97</td>
      <td>The use of reference data when SHAP values are calculated</td>
      <td>2019-09-06</td>
      <td>2019-09-10</td>
      <td>1450</td>
      <td>1446</td>
      <td>NONE</td>
      <td>0</td>
      <td>1014.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2444</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>444</td>
      <td>Overalapping shap_values</td>
      <td>2022-07-05</td>
      <td>2022-07-29</td>
      <td>417</td>
      <td>392</td>
      <td>NONE</td>
      <td>4</td>
      <td>1017.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1252</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>252</td>
      <td>Change Baseline in TreeExplainer</td>
      <td>2020-06-05</td>
      <td>2023-04-18</td>
      <td>1177</td>
      <td>130</td>
      <td>NONE</td>
      <td>15</td>
      <td>1018.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1483</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>483</td>
      <td>\"LookupError: gradient registry has no entry for: shap_TensorListStack\" using DeepExplainer for Keras Mod</td>
      <td>2020-10-01</td>
      <td>2022-12-31</td>
      <td>1059</td>
      <td>238</td>
      <td>NONE</td>
      <td>15</td>
      <td>1021.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>836</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>36</td>
      <td>TreeExplainer on binary LightGBM model produces shap values for multi-class</td>
      <td>2019-09-29</td>
      <td>2020-04-01</td>
      <td>1427</td>
      <td>1242</td>
      <td>NONE</td>
      <td>9</td>
      <td>1023.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1582</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>582</td>
      <td>Using xgboost, the wrong result is on some data sets</td>
      <td>2020-11-28</td>
      <td>2020-11-28</td>
      <td>1001</td>
      <td>1001</td>
      <td>NONE</td>
      <td>0</td>
      <td>1024.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1813</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>813</td>
      <td>how to deal with the \"mask  data\" in SH</td>
      <td>2021-03-10</td>
      <td>2021-03-10</td>
      <td>899</td>
      <td>899</td>
      <td>NONE</td>
      <td>0</td>
      <td>1024.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1046</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>046</td>
      <td>`ValueError: shape mismatch: objects cannot be broadcast to a single shape`</td>
      <td>2020-02-15</td>
      <td>2020-02-15</td>
      <td>1288</td>
      <td>1288</td>
      <td>NONE</td>
      <td>0</td>
      <td>1027.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1233</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>233</td>
      <td>Can't obtain incremental probability impact from TreeExplainer if data contains pd.Categorical dtype</td>
      <td>2020-05-26</td>
      <td>2020-10-24</td>
      <td>1186</td>
      <td>1036</td>
      <td>NONE</td>
      <td>5</td>
      <td>1029.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2475</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>475</td>
      <td>_bar.py does not open a new figure</td>
      <td>2022-08-08</td>
      <td>2022-08-08</td>
      <td>383</td>
      <td>383</td>
      <td>NONE</td>
      <td>0</td>
      <td>1030.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1779</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>779</td>
      <td>How to interpret shap feature interactions heat map?</td>
      <td>2021-02-18</td>
      <td>2021-06-30</td>
      <td>919</td>
      <td>787</td>
      <td>NONE</td>
      <td>1</td>
      <td>1031.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1772</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>772</td>
      <td>SHAP explanation in a text summarization model written in tensorflow.</td>
      <td>2021-02-15</td>
      <td>2021-02-15</td>
      <td>922</td>
      <td>922</td>
      <td>NONE</td>
      <td>0</td>
      <td>1032.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1319</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>319</td>
      <td>Understanding TreeShap Algorithm in recent paper</td>
      <td>2020-07-19</td>
      <td>2023-08-08</td>
      <td>1133</td>
      <td>18</td>
      <td>NONE</td>
      <td>9</td>
      <td>1034.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>813</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>13</td>
      <td>Kernel SHAP and Deep SHAP values differ from true model coefficients</td>
      <td>2019-09-19</td>
      <td>2019-09-24</td>
      <td>1437</td>
      <td>1432</td>
      <td>NONE</td>
      <td>3</td>
      <td>1035.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>976</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>76</td>
      <td>How to interpret the Shop force plot?</td>
      <td>2020-01-02</td>
      <td>2023-06-04</td>
      <td>1332</td>
      <td>83</td>
      <td>NONE</td>
      <td>14</td>
      <td>1038.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1749</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>749</td>
      <td>sklearn.ensemble.RandomForestRegressor builds incorrect shap_values object and selection fails</td>
      <td>2021-01-29</td>
      <td>2021-02-02</td>
      <td>939</td>
      <td>935</td>
      <td>NONE</td>
      <td>0</td>
      <td>1040.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1469</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>469</td>
      <td>Documentation of maskers</td>
      <td>2020-09-25</td>
      <td>2023-01-03</td>
      <td>1065</td>
      <td>235</td>
      <td>NONE</td>
      <td>2</td>
      <td>1040.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2640</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>640</td>
      <td>IndexError: tuple index out of range in shap.plots.bar</td>
      <td>2023-01-14</td>
      <td>2023-01-14</td>
      <td>224</td>
      <td>224</td>
      <td>NONE</td>
      <td>0</td>
      <td>1041.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1669</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>669</td>
      <td>Why does LinearExplainer summary_plot with plot_type=\"bar\" sometimes produce different feature importance order than model.coef</td>
      <td>2020-12-31</td>
      <td>2020-12-31</td>
      <td>967</td>
      <td>967</td>
      <td>NONE</td>
      <td>0</td>
      <td>1044.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2192</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>192</td>
      <td>Implementing a New Batch Kernel Explainer</td>
      <td>2021-12-18</td>
      <td>2021-12-20</td>
      <td>616</td>
      <td>614</td>
      <td>NONE</td>
      <td>0</td>
      <td>1045.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>989</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>89</td>
      <td>question please</td>
      <td>2020-01-08</td>
      <td>2020-01-31</td>
      <td>1325</td>
      <td>1302</td>
      <td>NONE</td>
      <td>3</td>
      <td>1045.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1433</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>433</td>
      <td>Issue with shap.force_plot() from shap values computed with a LinearExplainer</td>
      <td>2020-09-15</td>
      <td>2020-09-16</td>
      <td>1074</td>
      <td>1073</td>
      <td>NONE</td>
      <td>0</td>
      <td>1046.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>851</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>51</td>
      <td>Passing dictionary as a model</td>
      <td>2019-10-15</td>
      <td>2019-10-17</td>
      <td>1411</td>
      <td>1409</td>
      <td>NONE</td>
      <td>2</td>
      <td>1047.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1418</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>418</td>
      <td>Unrecognized model_output parameter value: predict_proba with TreeExplainer and scikit RandomForestClassifier</td>
      <td>2020-09-10</td>
      <td>2020-09-14</td>
      <td>1080</td>
      <td>1075</td>
      <td>NONE</td>
      <td>3</td>
      <td>1054.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>719</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>19</td>
      <td>Having issues with learning_phase_flags</td>
      <td>2019-07-28</td>
      <td>2019-07-28</td>
      <td>1490</td>
      <td>1490</td>
      <td>NONE</td>
      <td>0</td>
      <td>1055.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1960</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>960</td>
      <td>Kernel dies when trying to import shap latest 2 versions</td>
      <td>2021-06-16</td>
      <td>2023-08-14</td>
      <td>801</td>
      <td>12</td>
      <td>NONE</td>
      <td>5</td>
      <td>1056.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2613</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>613</td>
      <td>\"tuple index out of range\" when using Deep Explainer with PyTorch mod</td>
      <td>2022-12-14</td>
      <td>2023-03-17</td>
      <td>255</td>
      <td>162</td>
      <td>NONE</td>
      <td>1</td>
      <td>1056.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1836</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>836</td>
      <td>The latent vector explaining the expected value itself</td>
      <td>2021-03-25</td>
      <td>2021-10-09</td>
      <td>884</td>
      <td>685</td>
      <td>NONE</td>
      <td>0</td>
      <td>1057.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2195</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>195</td>
      <td>Applying SHAP with custom tokenizer to BERT</td>
      <td>2021-12-20</td>
      <td>2022-06-30</td>
      <td>614</td>
      <td>422</td>
      <td>NONE</td>
      <td>2</td>
      <td>1062.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>312</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>12</td>
      <td>SHAP values and influential features different with Kernelexplainer and tree explainer</td>
      <td>2018-11-06</td>
      <td>2018-11-09</td>
      <td>1754</td>
      <td>1751</td>
      <td>NONE</td>
      <td>1</td>
      <td>1063.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2023</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>023</td>
      <td>`TreeExplainer.save` throws `AttributeError: 'TreeEnsemble' object has no attribute 'save'`</td>
      <td>2021-08-04</td>
      <td>2023-08-22</td>
      <td>752</td>
      <td>4</td>
      <td>CONTRIBUTOR</td>
      <td>9</td>
      <td>1064.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2359</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>359</td>
      <td>DeepExplainer ***TypeError with CNN LSTM</td>
      <td>2022-04-22</td>
      <td>2022-04-22</td>
      <td>491</td>
      <td>491</td>
      <td>NONE</td>
      <td>0</td>
      <td>1066.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1888</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>888</td>
      <td>Solution for installing on newer macOS</td>
      <td>2021-04-29</td>
      <td>2021-04-29</td>
      <td>849</td>
      <td>849</td>
      <td>NONE</td>
      <td>0</td>
      <td>1070.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1028</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>028</td>
      <td>Questions on feature importance plot on a multi-class scenario</td>
      <td>2020-02-03</td>
      <td>2020-02-08</td>
      <td>1299</td>
      <td>1295</td>
      <td>NONE</td>
      <td>3</td>
      <td>1073.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2454</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>454</td>
      <td>SKLearn ElasticNetCV model not supported.</td>
      <td>2022-07-17</td>
      <td>2022-07-17</td>
      <td>405</td>
      <td>405</td>
      <td>NONE</td>
      <td>0</td>
      <td>1075.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>220</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>20</td>
      <td>Calculate SHAP values on distributed xgboost</td>
      <td>2018-08-15</td>
      <td>2019-07-19</td>
      <td>1837</td>
      <td>1499</td>
      <td>NONE</td>
      <td>4</td>
      <td>1077.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2447</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>447</td>
      <td>Shap importances of explainers.Tree and explainers.Sampling for XGBoost are vastly different</td>
      <td>2022-07-08</td>
      <td>2022-07-20</td>
      <td>414</td>
      <td>402</td>
      <td>NONE</td>
      <td>5</td>
      <td>1078.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1370</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>370</td>
      <td>SHAP independent tree explainer: Fractions of zeros and ones for filling up the subsets with EXTEND function</td>
      <td>2020-08-18</td>
      <td>2020-08-24</td>
      <td>1103</td>
      <td>1096</td>
      <td>NONE</td>
      <td>1</td>
      <td>1078.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2667</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>667</td>
      <td>KernelExplainer not thread-safe</td>
      <td>2023-02-22</td>
      <td>2023-08-26</td>
      <td>185</td>
      <td>0</td>
      <td>NONE</td>
      <td>3</td>
      <td>1082.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1785</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>785</td>
      <td>Installation issue on Python 3.8/3.9 on Big Sur</td>
      <td>2021-02-19</td>
      <td>2021-11-16</td>
      <td>917</td>
      <td>648</td>
      <td>NONE</td>
      <td>7</td>
      <td>1086.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2061</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>061</td>
      <td>Force plot not displaying</td>
      <td>2021-09-08</td>
      <td>2021-12-30</td>
      <td>717</td>
      <td>604</td>
      <td>NONE</td>
      <td>1</td>
      <td>1090.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1007</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>007</td>
      <td>Question about shap values and possible cross-validation scheme</td>
      <td>2020-01-21</td>
      <td>2022-11-29</td>
      <td>1312</td>
      <td>270</td>
      <td>NONE</td>
      <td>3</td>
      <td>1097.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>248</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>48</td>
      <td>Shap values for accessing variables influence</td>
      <td>2018-09-01</td>
      <td>2019-02-10</td>
      <td>1820</td>
      <td>1658</td>
      <td>NONE</td>
      <td>4</td>
      <td>1100.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2166</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>166</td>
      <td>Error in image_plot for image binary classification</td>
      <td>2021-12-02</td>
      <td>2021-12-02</td>
      <td>632</td>
      <td>632</td>
      <td>NONE</td>
      <td>0</td>
      <td>1105.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>805</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>05</td>
      <td>Summary Plot with Multi-classification Using CatBoost</td>
      <td>2019-09-12</td>
      <td>2019-09-12</td>
      <td>1444</td>
      <td>1444</td>
      <td>NONE</td>
      <td>0</td>
      <td>1107.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1506</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>506</td>
      <td>Top N features that are responsible for the local SHAP value</td>
      <td>2020-10-13</td>
      <td>2020-10-14</td>
      <td>1046</td>
      <td>1046</td>
      <td>NONE</td>
      <td>1</td>
      <td>1111.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2065</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>065</td>
      <td>Shap Values do not sum up to the models output (are all zero) for LSTM</td>
      <td>2021-09-11</td>
      <td>2021-09-12</td>
      <td>714</td>
      <td>713</td>
      <td>NONE</td>
      <td>1</td>
      <td>1116.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1776</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>776</td>
      <td>Shap interaction with XGBoost with interventional feature pertubation not supported?</td>
      <td>2021-02-17</td>
      <td>2022-07-05</td>
      <td>920</td>
      <td>417</td>
      <td>NONE</td>
      <td>5</td>
      <td>1119.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>793</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>93</td>
      <td>error in v0.30.0</td>
      <td>2019-09-05</td>
      <td>2019-09-11</td>
      <td>1451</td>
      <td>1444</td>
      <td>NONE</td>
      <td>1</td>
      <td>1121.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1085</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>085</td>
      <td>shap.depenence_plot to multi page pdf</td>
      <td>2020-03-05</td>
      <td>2020-03-09</td>
      <td>1269</td>
      <td>1265</td>
      <td>NONE</td>
      <td>1</td>
      <td>1125.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2140</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>140</td>
      <td>shap not compatible with sklearn API</td>
      <td>2021-11-16</td>
      <td>2022-06-05</td>
      <td>647</td>
      <td>447</td>
      <td>NONE</td>
      <td>1</td>
      <td>1130.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>873</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>73</td>
      <td>Does DeepExplainer work with Lambda layers?</td>
      <td>2019-10-29</td>
      <td>2022-11-28</td>
      <td>1397</td>
      <td>271</td>
      <td>NONE</td>
      <td>1</td>
      <td>1132.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1356</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>356</td>
      <td>KernelExplainer with Prophet Model</td>
      <td>2020-08-11</td>
      <td>2023-06-23</td>
      <td>1110</td>
      <td>64</td>
      <td>NONE</td>
      <td>6</td>
      <td>1133.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2226</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>226</td>
      <td>CatBoostClassifier: SHAP values don't add up to the output</td>
      <td>2022-01-26</td>
      <td>2022-01-26</td>
      <td>577</td>
      <td>577</td>
      <td>NONE</td>
      <td>1</td>
      <td>1136.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>85</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>5</td>
      <td>Question about SHAP value intuition</td>
      <td>2018-05-15</td>
      <td>2018-10-02</td>
      <td>1929</td>
      <td>1789</td>
      <td>NONE</td>
      <td>19</td>
      <td>1139.0</td>
      <td>No</td>
      <td>"Question and inquiry regarding series body shape in Python."</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2417</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>417</td>
      <td>Interprete categorical Feature values in a summary plot. Is it even possible?</td>
      <td>2022-06-07</td>
      <td>2022-07-04</td>
      <td>445</td>
      <td>418</td>
      <td>NONE</td>
      <td>1</td>
      <td>1142.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1333</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>333</td>
      <td>Calling shap_interaction_values changes explainer's expected value</td>
      <td>2020-07-28</td>
      <td>2020-07-28</td>
      <td>1124</td>
      <td>1123</td>
      <td>NONE</td>
      <td>1</td>
      <td>1142.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2615</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>615</td>
      <td>ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])</td>
      <td>2022-12-17</td>
      <td>2022-12-17</td>
      <td>252</td>
      <td>252</td>
      <td>NONE</td>
      <td>0</td>
      <td>1144.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>43</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>3</td>
      <td>Should I use SHAP contributions for debugging why did my XGB classifier does not transfer to another population?</td>
      <td>2018-03-11</td>
      <td>2018-03-12</td>
      <td>1994</td>
      <td>1993</td>
      <td>NONE</td>
      <td>1</td>
      <td>1146.0</td>
      <td>No</td>
      <td>Issue regarding choosing Series in a one-dimensional data structure.</td>
      <td>"Training Issue"</td>
      <td>'bug'</td>
    </tr>
    <tr>
      <td>2678</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>678</td>
      <td>The SHAP explanations do not sum up to the model's output!</td>
      <td>2023-03-13</td>
      <td>2023-04-27</td>
      <td>165</td>
      <td>120</td>
      <td>NONE</td>
      <td>1</td>
      <td>1149.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1365</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>365</td>
      <td>Question about TreeExplainer data parameter &amp; train/test subsets.</td>
      <td>2020-08-15</td>
      <td>2021-01-13</td>
      <td>1106</td>
      <td>955</td>
      <td>NONE</td>
      <td>8</td>
      <td>1149.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1807</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>807</td>
      <td>Additivity check failed ,TreeExplainer varying difference with different amount of data</td>
      <td>2021-03-07</td>
      <td>2021-03-07</td>
      <td>902</td>
      <td>902</td>
      <td>NONE</td>
      <td>0</td>
      <td>1151.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2358</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>358</td>
      <td>Different result values for the same query</td>
      <td>2022-04-21</td>
      <td>2022-04-21</td>
      <td>492</td>
      <td>492</td>
      <td>NONE</td>
      <td>0</td>
      <td>1157.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1629</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>629</td>
      <td>Bug using base_margin() with TreeSHAP (with notebook), sum of shap values off the margin prediction by log(2). Biased shap values for variables with large effects</td>
      <td>2020-12-16</td>
      <td>2020-12-16</td>
      <td>982</td>
      <td>982</td>
      <td>NONE</td>
      <td>0</td>
      <td>1158.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2842</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>842</td>
      <td>BUG: benchmark tests are not being collected and run by pytest</td>
      <td>2023-07-10</td>
      <td>2023-07-18</td>
      <td>47</td>
      <td>39</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>1161.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1158</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>158</td>
      <td>DeepSHAP baseline x,y do not take mean values?</td>
      <td>2020-04-16</td>
      <td>2020-04-17</td>
      <td>1227</td>
      <td>1226</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>1161.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2501</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>501</td>
      <td>Re-scaling of target variable problematic with shap values</td>
      <td>2022-09-07</td>
      <td>2023-06-16</td>
      <td>353</td>
      <td>71</td>
      <td>NONE</td>
      <td>1</td>
      <td>1164.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1288</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>288</td>
      <td>Multioutput chained regression using TreeExplainer</td>
      <td>2020-06-24</td>
      <td>2020-06-24</td>
      <td>1157</td>
      <td>1157</td>
      <td>NONE</td>
      <td>0</td>
      <td>1164.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2637</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>637</td>
      <td>explain models generated using MLJAR</td>
      <td>2023-01-10</td>
      <td>2023-01-14</td>
      <td>228</td>
      <td>224</td>
      <td>NONE</td>
      <td>1</td>
      <td>1165.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1950</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>950</td>
      <td>KernelExplainer with Categorical Encoding in Model Pipeline</td>
      <td>2021-06-09</td>
      <td>2023-04-12</td>
      <td>808</td>
      <td>135</td>
      <td>NONE</td>
      <td>2</td>
      <td>1167.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2258</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>258</td>
      <td>PartitionExplainer reference material</td>
      <td>2022-02-21</td>
      <td>2022-02-21</td>
      <td>551</td>
      <td>551</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>1175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2191</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>191</td>
      <td>shap.image_plot(shap_values) not working</td>
      <td>2021-12-18</td>
      <td>2021-12-18</td>
      <td>616</td>
      <td>616</td>
      <td>NONE</td>
      <td>0</td>
      <td>1175.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2190</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>190</td>
      <td>shap_values summary_plot change dramatically</td>
      <td>2021-12-16</td>
      <td>2021-12-16</td>
      <td>617</td>
      <td>617</td>
      <td>NONE</td>
      <td>0</td>
      <td>1178.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>576</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>6</td>
      <td>KernelExplainer for Multiclass XGBoost model - returns NaN Value Error</td>
      <td>2019-05-07</td>
      <td>2023-07-23</td>
      <td>1572</td>
      <td>34</td>
      <td>NONE</td>
      <td>5</td>
      <td>1180.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>604</td>
      <td><a href="https://github.com/shap/shap/issues/61">61</a>4</td>
      <td>doesn't all the shap values sum to 1 for LSTM model</td>
      <td>2019-05-23</td>
      <td>2019-05-24</td>
      <td>1555</td>
      <td>1555</td>
      <td>NONE</td>
      <td>0</td>
      <td>1182.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>878</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>78</td>
      <td>Readme file example, (Tree ensemble example with TreeExplainer) throws error</td>
      <td>2019-10-31</td>
      <td>2019-10-31</td>
      <td>1394</td>
      <td>1394</td>
      <td>NONE</td>
      <td>4</td>
      <td>1186.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1504</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>504</td>
      <td>shap.decision_plot model output value is different to the model predicted value</td>
      <td>2020-10-13</td>
      <td>2020-10-13</td>
      <td>1047</td>
      <td>1047</td>
      <td>NONE</td>
      <td>0</td>
      <td>1186.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2823</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>823</td>
      <td>MAINT: adopt dynamic versioning to facilitate TestPyPi releases</td>
      <td>2023-07-04</td>
      <td>2023-07-16</td>
      <td>52</td>
      <td>41</td>
      <td>COLLABORATOR</td>
      <td>2</td>
      <td>1187.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2610</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>610</td>
      <td>\"ValueError: minvalue must be less than or equal to maxvalue\" when  calling shap.plots.scatt</td>
      <td>2022-12-13</td>
      <td>2022-12-13</td>
      <td>256</td>
      <td>256</td>
      <td>NONE</td>
      <td>0</td>
      <td>1188.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1872</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>872</td>
      <td>Shap v0.39 apparently doesn't support Kernel</td>
      <td>2021-04-20</td>
      <td>2021-04-20</td>
      <td>858</td>
      <td>858</td>
      <td>NONE</td>
      <td>0</td>
      <td>1189.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1104</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>104</td>
      <td>: Additivity check failed in TreeExplainer! Please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option.</td>
      <td>2020-03-17</td>
      <td>2020-04-02</td>
      <td>1257</td>
      <td>1241</td>
      <td>NONE</td>
      <td>1</td>
      <td>1193.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1920</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>920</td>
      <td>KernelExplainer fails when link=\"logit\" and probability is 1 or</td>
      <td>2021-05-18</td>
      <td>2021-05-18</td>
      <td>830</td>
      <td>830</td>
      <td>NONE</td>
      <td>0</td>
      <td>1204.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1387</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>387</td>
      <td>What I expect as expected value is different than the actual expected value in TreeExplainer</td>
      <td>2020-08-28</td>
      <td>2022-11-09</td>
      <td>1092</td>
      <td>290</td>
      <td>NONE</td>
      <td>8</td>
      <td>1205.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1334</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>334</td>
      <td>shap.maskers not visible in pip installed package</td>
      <td>2020-07-28</td>
      <td>2020-11-02</td>
      <td>1123</td>
      <td>1026</td>
      <td>NONE</td>
      <td>2</td>
      <td>1208.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2634</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>634</td>
      <td>SHAP dependence plots with histograms and regression lines from Kernalexplainer and multioutput regression, wrapper tree based ensemble models.</td>
      <td>2023-01-04</td>
      <td>2023-01-08</td>
      <td>233</td>
      <td>230</td>
      <td>NONE</td>
      <td>1</td>
      <td>1208.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1932</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>932</td>
      <td>shap.plots.bar do not have 'plot_size' argument</td>
      <td>2021-05-27</td>
      <td>2021-06-07</td>
      <td>821</td>
      <td>810</td>
      <td>NONE</td>
      <td>1</td>
      <td>1209.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2306</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>306</td>
      <td>which feature_perturbation method in TreeSHAP uses marginal contributions rather than conditional? (Urgent! - viva soon)</td>
      <td>2022-03-24</td>
      <td>2022-03-24</td>
      <td>520</td>
      <td>520</td>
      <td>NONE</td>
      <td>0</td>
      <td>1211.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2039</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>039</td>
      <td>Waterfall plot .base_values error</td>
      <td>2021-08-16</td>
      <td>2022-01-27</td>
      <td>740</td>
      <td>576</td>
      <td>NONE</td>
      <td>3</td>
      <td>1213.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1600</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>600</td>
      <td>Quick question on approximate=True and feature_perturbation = interventional</td>
      <td>2020-12-08</td>
      <td>2020-12-08</td>
      <td>991</td>
      <td>991</td>
      <td>NONE</td>
      <td>0</td>
      <td>1214.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>545</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>5</td>
      <td>Using SHAP for mixed data</td>
      <td>2019-04-11</td>
      <td>2020-06-24</td>
      <td>1598</td>
      <td>1158</td>
      <td>NONE</td>
      <td>2</td>
      <td>1214.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>468</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>68</td>
      <td>Most tests do not verify assumptions of the method</td>
      <td>2019-03-01</td>
      <td>2019-03-01</td>
      <td>1639</td>
      <td>1639</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>1215.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1279</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>279</td>
      <td>Question regarding Fig 5 in Nature MI 2020 Tree Explainer paper</td>
      <td>2020-06-20</td>
      <td>2020-06-20</td>
      <td>1161</td>
      <td>1161</td>
      <td>NONE</td>
      <td>0</td>
      <td>1223.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1541</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>541</td>
      <td>SHAP dependence plot issue</td>
      <td>2020-11-06</td>
      <td>2020-11-06</td>
      <td>1023</td>
      <td>1023</td>
      <td>NONE</td>
      <td>0</td>
      <td>1225.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1863</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>863</td>
      <td>ImportError for SHAP GPUTree: DLL load failed while importing _cext_gpu</td>
      <td>2021-04-12</td>
      <td>2021-08-10</td>
      <td>866</td>
      <td>746</td>
      <td>NONE</td>
      <td>2</td>
      <td>1231.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>575</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>5</td>
      <td>Binary CatBoost classifier using TreeExplainer with model_output='probability' and tree_dependence='Independent'</td>
      <td>2019-05-06</td>
      <td>2019-05-12</td>
      <td>1572</td>
      <td>1567</td>
      <td>NONE</td>
      <td>3</td>
      <td>1235.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1405</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>405</td>
      <td>Gradient Explainer; LookupError: gradient registry has no entry for: shap_StridedSlice</td>
      <td>2020-09-02</td>
      <td>2023-06-06</td>
      <td>1087</td>
      <td>81</td>
      <td>NONE</td>
      <td>17</td>
      <td>1241.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2136</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>136</td>
      <td>Summarising text explanations -custom set of features</td>
      <td>2021-11-14</td>
      <td>2021-11-15</td>
      <td>650</td>
      <td>649</td>
      <td>NONE</td>
      <td>1</td>
      <td>1247.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2770</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>770</td>
      <td>BUG: TypeError: 'NoneType' object is not callable</td>
      <td>2023-06-15</td>
      <td>2023-06-16</td>
      <td>72</td>
      <td>71</td>
      <td>NONE</td>
      <td>1</td>
      <td>1248.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>827</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>27</td>
      <td>`import shap` can cause memory leaks when any one of `xgboost`, `catboost`, etc. is not found</td>
      <td>2019-09-23</td>
      <td>2019-09-23</td>
      <td>1432</td>
      <td>1432</td>
      <td>NONE</td>
      <td>0</td>
      <td>1254.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1777</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>777</td>
      <td>How does overfitting affects SHAP Values?</td>
      <td>2021-02-17</td>
      <td>2022-10-21</td>
      <td>920</td>
      <td>309</td>
      <td>NONE</td>
      <td>4</td>
      <td>1259.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>980</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>80</td>
      <td>Question: Correct interpretation of summary_plot graph</td>
      <td>2020-01-03</td>
      <td>2020-04-14</td>
      <td>1331</td>
      <td>1229</td>
      <td>NONE</td>
      <td>1</td>
      <td>1262.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>926</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>26</td>
      <td>DeepExplainer TypeError: shap_values() takes from 2 to 6 positional arguments but 7 were given</td>
      <td>2019-12-04</td>
      <td>2019-12-16</td>
      <td>1361</td>
      <td>1349</td>
      <td>NONE</td>
      <td>2</td>
      <td>1264.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1514</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>514</td>
      <td>How to show the mean |SHAP value| data label within the summary plot ( for multiclass output using lightgbm)</td>
      <td>2020-10-16</td>
      <td>2020-10-20</td>
      <td>1043</td>
      <td>1039</td>
      <td>NONE</td>
      <td>1</td>
      <td>1264.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1778</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>778</td>
      <td>Plans for PartitionExplainer</td>
      <td>2021-02-18</td>
      <td>2021-03-05</td>
      <td>919</td>
      <td>904</td>
      <td>NONE</td>
      <td>1</td>
      <td>1264.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2268</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>268</td>
      <td>How to interpret shap Force plot for all data points?</td>
      <td>2022-03-02</td>
      <td>2022-03-02</td>
      <td>542</td>
      <td>542</td>
      <td>NONE</td>
      <td>0</td>
      <td>1265.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2283</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>283</td>
      <td>What is a good way to merge Shap values of all tokens?</td>
      <td>2022-03-15</td>
      <td>2022-03-15</td>
      <td>529</td>
      <td>529</td>
      <td>NONE</td>
      <td>0</td>
      <td>1267.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1170</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>170</td>
      <td>Approximate interaction values</td>
      <td>2020-04-23</td>
      <td>2022-09-02</td>
      <td>1220</td>
      <td>358</td>
      <td>NONE</td>
      <td>1</td>
      <td>1269.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2276</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>276</td>
      <td>Shap plot predicts the opposite label than the classifier predicted</td>
      <td>2022-03-09</td>
      <td>2023-06-27</td>
      <td>535</td>
      <td>60</td>
      <td>NONE</td>
      <td>7</td>
      <td>1272.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>639</td>
      <td><a href="https://github.com/shap/shap/issues/64">64</a>9</td>
      <td>Usage of KernelExplainer for a Pipeline and a multi-class classification</td>
      <td>2019-06-11</td>
      <td>2019-06-18</td>
      <td>1537</td>
      <td>1530</td>
      <td>NONE</td>
      <td>2</td>
      <td>1276.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2499</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>499</td>
      <td>How is the class-order in an Explainer object defined?</td>
      <td>2022-09-05</td>
      <td>2023-05-10</td>
      <td>355</td>
      <td>108</td>
      <td>NONE</td>
      <td>1</td>
      <td>1277.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2764</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>764</td>
      <td>MWE for Batch Processing SHAP?</td>
      <td>2023-06-12</td>
      <td>2023-06-15</td>
      <td>75</td>
      <td>72</td>
      <td>NONE</td>
      <td>5</td>
      <td>1283.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>253</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>53</td>
      <td>Automatically selecting the other feature in SHAP dependency plots.</td>
      <td>2018-09-03</td>
      <td>2019-04-09</td>
      <td>1817</td>
      <td>1600</td>
      <td>NONE</td>
      <td>3</td>
      <td>1285.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>953</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>53</td>
      <td>sklearn RF Bus error with TreeExplainer</td>
      <td>2019-12-14</td>
      <td>2022-04-14</td>
      <td>1350</td>
      <td>499</td>
      <td>NONE</td>
      <td>2</td>
      <td>1286.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>363</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>63</td>
      <td>Highlighting feature value colors when using KernelExplainer with TFIDFVectorizer</td>
      <td>2018-12-22</td>
      <td>2019-01-07</td>
      <td>1708</td>
      <td>1692</td>
      <td>NONE</td>
      <td>6</td>
      <td>1287.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1759</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>759</td>
      <td>Additivity check fails for imblearn BalancedRandomForestClassifier</td>
      <td>2021-02-05</td>
      <td>2021-02-05</td>
      <td>932</td>
      <td>932</td>
      <td>NONE</td>
      <td>0</td>
      <td>1293.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>264</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>64</td>
      <td>Future plans for inclusion of scikit_learn.KerasClassifier, PyTorch, Pyro, and C++ implantation version?</td>
      <td>2018-09-21</td>
      <td>2018-10-02</td>
      <td>1800</td>
      <td>1788</td>
      <td>NONE</td>
      <td>1</td>
      <td>1295.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1048</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>048</td>
      <td>Loosing timezone info on dataframe creation with keep_index=True and with KernelExplainer</td>
      <td>2020-02-17</td>
      <td>2020-02-17</td>
      <td>1286</td>
      <td>1286</td>
      <td>NONE</td>
      <td>1</td>
      <td>1297.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1376</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>376</td>
      <td>Background data failing due to np.isnan</td>
      <td>2020-08-20</td>
      <td>2020-08-29</td>
      <td>1101</td>
      <td>1092</td>
      <td>NONE</td>
      <td>2</td>
      <td>1300.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>858</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>58</td>
      <td>shap.TreeExplainer crashes with xgboost R binary when using background data</td>
      <td>2019-10-21</td>
      <td>2019-10-22</td>
      <td>1405</td>
      <td>1404</td>
      <td>NONE</td>
      <td>1</td>
      <td>1301.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>574</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>4</td>
      <td>Error in using categorical features in Census income classification with LightGBM notebook?</td>
      <td>2019-05-06</td>
      <td>2023-08-26</td>
      <td>1573</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>1305.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1823</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>823</td>
      <td>Documentation for example force plot needs updating</td>
      <td>2021-03-18</td>
      <td>2023-07-27</td>
      <td>891</td>
      <td>30</td>
      <td>NONE</td>
      <td>1</td>
      <td>1307.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1015</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>015</td>
      <td>shap.datasets.adult giving error</td>
      <td>2020-01-24</td>
      <td>2023-01-24</td>
      <td>1310</td>
      <td>214</td>
      <td>NONE</td>
      <td>2</td>
      <td>1307.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>609</td>
      <td><a href="https://github.com/shap/shap/issues/61">61</a>9</td>
      <td>set an input feature equal output, why this feature is not the top contribution feature</td>
      <td>2019-05-28</td>
      <td>2019-05-28</td>
      <td>1551</td>
      <td>1551</td>
      <td>NONE</td>
      <td>0</td>
      <td>1308.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1752</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>752</td>
      <td>Model type not yet supported by TreeExplainer: &lt;class 'tensorflow.python.keras.engine.sequential.Sequential'&gt;</td>
      <td>2021-01-31</td>
      <td>2021-02-09</td>
      <td>937</td>
      <td>928</td>
      <td>NONE</td>
      <td>1</td>
      <td>1311.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1982</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>982</td>
      <td>DeepExplainer input parameters</td>
      <td>2021-07-04</td>
      <td>2021-07-04</td>
      <td>782</td>
      <td>782</td>
      <td>NONE</td>
      <td>0</td>
      <td>1313.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2116</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>116</td>
      <td>shap v0.40 : shap.plots.bar(shape_values) + RandomForestClassfier = Fail</td>
      <td>2021-10-25</td>
      <td>2021-11-01</td>
      <td>670</td>
      <td>663</td>
      <td>NONE</td>
      <td>3</td>
      <td>1315.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>922</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>22</td>
      <td>Importing shap gives error</td>
      <td>2019-12-03</td>
      <td>2019-12-03</td>
      <td>1362</td>
      <td>1362</td>
      <td>NONE</td>
      <td>5</td>
      <td>1317.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>351</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>51</td>
      <td>Interpretation of Base Value and Predicted Value in SHAP Plots</td>
      <td>2018-12-10</td>
      <td>2023-04-10</td>
      <td>1720</td>
      <td>138</td>
      <td>NONE</td>
      <td>17</td>
      <td>1319.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1616</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>616</td>
      <td>different process  of two gradient functions in DeepEXplainrer and GradientExplainer to deal with None value</td>
      <td>2020-12-13</td>
      <td>2020-12-13</td>
      <td>986</td>
      <td>986</td>
      <td>NONE</td>
      <td>0</td>
      <td>1320.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1717</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>717</td>
      <td>Errors when using e.shap_values() on networks with BatchNormalization OR GlobalMaxPooling</td>
      <td>2021-01-20</td>
      <td>2021-08-04</td>
      <td>948</td>
      <td>752</td>
      <td>NONE</td>
      <td>2</td>
      <td>1321.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>651</td>
      <td><a href="https://github.com/shap/shap/issues/66">66</a>1</td>
      <td>Explainer.expected_value changes after calling shap_values() method</td>
      <td>2019-06-19</td>
      <td>2019-06-23</td>
      <td>1529</td>
      <td>1525</td>
      <td>NONE</td>
      <td>9</td>
      <td>1325.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1066</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>066</td>
      <td>Using KernelShap with Pytorch</td>
      <td>2020-02-26</td>
      <td>2020-07-06</td>
      <td>1277</td>
      <td>1146</td>
      <td>NONE</td>
      <td>4</td>
      <td>1329.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2624</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>624</td>
      <td>support for sparkxgb xgboost models</td>
      <td>2022-12-23</td>
      <td>2022-12-23</td>
      <td>246</td>
      <td>246</td>
      <td>NONE</td>
      <td>0</td>
      <td>1331.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>23</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>3</td>
      <td>how does the algorithm consider the number of subsets behind each path?</td>
      <td>2018-01-25</td>
      <td>2020-12-28</td>
      <td>2038</td>
      <td>971</td>
      <td>NONE</td>
      <td>24</td>
      <td>1332.0</td>
      <td>No</td>
      <td>Issue regarding understanding of a single-dimensional series in Python.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2329</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>329</td>
      <td>\"Additivity check failed in TreeExplainer\" Fixed by Running in Batch</td>
      <td>2022-04-06</td>
      <td>2022-04-06</td>
      <td>507</td>
      <td>507</td>
      <td>NONE</td>
      <td>0</td>
      <td>1336.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>240</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>40</td>
      <td>Dependence plot shows wrong colormap with some one-hot encoded features.</td>
      <td>2018-08-27</td>
      <td>2018-08-27</td>
      <td>1825</td>
      <td>1825</td>
      <td>NONE</td>
      <td>1</td>
      <td>1337.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>14</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>4</td>
      <td>(Paper): Conditional Expectation Calculation &amp; Inverse Function Questions</td>
      <td>2018-01-15</td>
      <td>2018-01-18</td>
      <td>2049</td>
      <td>2046</td>
      <td>NONE</td>
      <td>3</td>
      <td>1338.0</td>
      <td>No</td>
      <td>Issue regarding the shape of Series in Paper: Condi project.</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>1429</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>429</td>
      <td>Plot style incoherent with default plot params</td>
      <td>2020-09-15</td>
      <td>2020-09-15</td>
      <td>1075</td>
      <td>1075</td>
      <td>NONE</td>
      <td>0</td>
      <td>1340.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1981</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>981</td>
      <td>Coalitional Methods to Reduce Computation Time</td>
      <td>2021-07-04</td>
      <td>2021-07-04</td>
      <td>783</td>
      <td>783</td>
      <td>NONE</td>
      <td>0</td>
      <td>1345.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2682</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>682</td>
      <td>AttributeError: module 'shap.models' has no attribute 'TeacherForcingLogits'</td>
      <td>2023-03-18</td>
      <td>2023-07-08</td>
      <td>161</td>
      <td>49</td>
      <td>NONE</td>
      <td>3</td>
      <td>1345.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2554</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>554</td>
      <td>shap.KernelExplainer seems that it cannot correctly identify the data format</td>
      <td>2022-10-18</td>
      <td>2023-02-01</td>
      <td>312</td>
      <td>206</td>
      <td>NONE</td>
      <td>1</td>
      <td>1346.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>925</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>25</td>
      <td>Explaining LSTM predictions for model using Dropout as a Bayesian Approximation</td>
      <td>2019-12-04</td>
      <td>2019-12-27</td>
      <td>1361</td>
      <td>1337</td>
      <td>NONE</td>
      <td>4</td>
      <td>1356.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1443</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>443</td>
      <td>shap summary plot has different class colors across train and test data</td>
      <td>2020-09-19</td>
      <td>2020-11-06</td>
      <td>1071</td>
      <td>1022</td>
      <td>NONE</td>
      <td>1</td>
      <td>1358.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>315</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>15</td>
      <td>TreeExplainer expected_value is `None`?</td>
      <td>2018-11-09</td>
      <td>2021-11-02</td>
      <td>1751</td>
      <td>662</td>
      <td>NONE</td>
      <td>4</td>
      <td>1361.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1375</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>375</td>
      <td>unable to create explainer from mleap deserialized pyspark model</td>
      <td>2020-08-20</td>
      <td>2022-07-13</td>
      <td>1101</td>
      <td>409</td>
      <td>NONE</td>
      <td>4</td>
      <td>1363.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1992</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>992</td>
      <td>Shap.TreeExplainer for CatboostClassifier Segmentation Fault</td>
      <td>2021-07-13</td>
      <td>2021-11-15</td>
      <td>774</td>
      <td>649</td>
      <td>NONE</td>
      <td>1</td>
      <td>1364.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2522</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>522</td>
      <td>Split function in shap.plots.bar assumes that yticklabels are strings</td>
      <td>2022-09-21</td>
      <td>2022-09-21</td>
      <td>338</td>
      <td>338</td>
      <td>NONE</td>
      <td>0</td>
      <td>1364.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1078</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>078</td>
      <td>Error using DeepExplainer in TF 2.1</td>
      <td>2020-03-02</td>
      <td>2021-02-22</td>
      <td>1272</td>
      <td>914</td>
      <td>NONE</td>
      <td>4</td>
      <td>1365.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2815</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>815</td>
      <td>Legend starts to overlap with the plot when multiple cohorts were selected.</td>
      <td>2023-06-26</td>
      <td>2023-06-26</td>
      <td>61</td>
      <td>61</td>
      <td>NONE</td>
      <td>0</td>
      <td>1366.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1261</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>261</td>
      <td>IndexError: string index out of range</td>
      <td>2020-06-10</td>
      <td>2021-10-29</td>
      <td>1172</td>
      <td>666</td>
      <td>NONE</td>
      <td>5</td>
      <td>1379.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>547</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>7</td>
      <td>SHAP DeepExplainer has no attribute 'get_session' with TF 2.0</td>
      <td>2019-04-11</td>
      <td>2020-08-24</td>
      <td>1598</td>
      <td>1097</td>
      <td>NONE</td>
      <td>17</td>
      <td>1382.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1846</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>846</td>
      <td>SHAP for multiple input multiple output problems (sensors selection for physics field decoder challange)</td>
      <td>2021-03-30</td>
      <td>2021-03-30</td>
      <td>879</td>
      <td>879</td>
      <td>NONE</td>
      <td>3</td>
      <td>1386.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>528</td>
      <td><a href="https://github.com/shap/shap/issues/53">53</a>8</td>
      <td>TreeExplainer.shap_values() incorrect results for model with output vector</td>
      <td>2019-04-03</td>
      <td>2019-04-19</td>
      <td>1606</td>
      <td>1590</td>
      <td>NONE</td>
      <td>4</td>
      <td>1391.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>730</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>30</td>
      <td>numpy 1.16.4 not supported due to scikit-image use of _validate_lengths in versions below 0.15!</td>
      <td>2019-08-06</td>
      <td>2019-08-06</td>
      <td>1481</td>
      <td>1481</td>
      <td>NONE</td>
      <td>1</td>
      <td>1397.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>696</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>6</td>
      <td>Feature values not showing</td>
      <td>2019-07-11</td>
      <td>2019-07-11</td>
      <td>1507</td>
      <td>1507</td>
      <td>NONE</td>
      <td>0</td>
      <td>1399.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1357</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>357</td>
      <td>Force Plot Is not Displayed</td>
      <td>2020-08-11</td>
      <td>2023-05-25</td>
      <td>1109</td>
      <td>93</td>
      <td>NONE</td>
      <td>7</td>
      <td>1399.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>480</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>80</td>
      <td>Problem in LIGHTGBM  and CatBoost using TreeExplainer with model_output = \"probibility</td>
      <td>2019-03-07</td>
      <td>2023-07-10</td>
      <td>1633</td>
      <td>47</td>
      <td>NONE</td>
      <td>6</td>
      <td>1401.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1163</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>163</td>
      <td>'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'mean'</td>
      <td>2020-04-17</td>
      <td>2020-12-04</td>
      <td>1226</td>
      <td>995</td>
      <td>NONE</td>
      <td>3</td>
      <td>1402.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2223</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>223</td>
      <td>File descriptor not closed in CatBoostTreeModelLoader ctor</td>
      <td>2022-01-24</td>
      <td>2022-01-24</td>
      <td>579</td>
      <td>579</td>
      <td>NONE</td>
      <td>0</td>
      <td>1421.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1458</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>458</td>
      <td>Inconsistent slicing of base values and values of the Explanation object sliced to visualize feature contributions towards a class in a multiclass scenario leading to error in visualizing text plots</td>
      <td>2020-09-22</td>
      <td>2020-09-22</td>
      <td>1068</td>
      <td>1068</td>
      <td>COLLABORATOR</td>
      <td>0</td>
      <td>1422.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2917</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>917</td>
      <td>BUG: Strange base value of exact explainer</td>
      <td>2023-08-01</td>
      <td>2023-08-17</td>
      <td>25</td>
      <td>9</td>
      <td>NONE</td>
      <td>2</td>
      <td>1423.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2214</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>214</td>
      <td>cannot import name 'DenseData' and 'visualize' from 'shap'</td>
      <td>2022-01-10</td>
      <td>2022-01-19</td>
      <td>593</td>
      <td>584</td>
      <td>NONE</td>
      <td>1</td>
      <td>1425.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1308</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>308</td>
      <td>Error in Sentiment Analysis with Logistic Regression notebook</td>
      <td>2020-07-10</td>
      <td>2020-07-10</td>
      <td>1142</td>
      <td>1142</td>
      <td>NONE</td>
      <td>0</td>
      <td>1427.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2665</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>665</td>
      <td>In TreeExplainer, when feature_pertrubation='tree_path_dependent' but data is not None, do we have 'interventional' shap?</td>
      <td>2023-02-20</td>
      <td>2023-02-22</td>
      <td>187</td>
      <td>185</td>
      <td>NONE</td>
      <td>1</td>
      <td>1431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>868</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>68</td>
      <td>Not work TF.keras</td>
      <td>2019-10-28</td>
      <td>2023-05-23</td>
      <td>1398</td>
      <td>94</td>
      <td>NONE</td>
      <td>4</td>
      <td>1431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1277</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>277</td>
      <td>Different predictions for explainer.model?</td>
      <td>2020-06-19</td>
      <td>2020-06-19</td>
      <td>1163</td>
      <td>1163</td>
      <td>NONE</td>
      <td>1</td>
      <td>1432.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2078</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>078</td>
      <td>Global Shapley Values not working on Pytorch</td>
      <td>2021-09-19</td>
      <td>2022-07-22</td>
      <td>706</td>
      <td>400</td>
      <td>NONE</td>
      <td>1</td>
      <td>1434.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1290</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>290</td>
      <td>TreeExplainer different output for binary classification with XGBoost compared to other based tree ensemble</td>
      <td>2020-06-25</td>
      <td>2021-09-23</td>
      <td>1157</td>
      <td>702</td>
      <td>NONE</td>
      <td>1</td>
      <td>1435.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1056</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>056</td>
      <td>PyTorch DeepExplainer, RNNs, and Element-Wise Multiplication</td>
      <td>2020-02-20</td>
      <td>2020-09-22</td>
      <td>1283</td>
      <td>1068</td>
      <td>NONE</td>
      <td>5</td>
      <td>1448.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1280</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>280</td>
      <td>Interpreting SHAP values and baselines in TreeExplainer</td>
      <td>2020-06-22</td>
      <td>2020-06-22</td>
      <td>1160</td>
      <td>1160</td>
      <td>NONE</td>
      <td>1</td>
      <td>1454.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1436</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>436</td>
      <td>'TreeEnsemble' object has no attribute 'values' when model predictions are all from one class</td>
      <td>2020-09-16</td>
      <td>2020-09-19</td>
      <td>1074</td>
      <td>1071</td>
      <td>NONE</td>
      <td>2</td>
      <td>1454.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>485</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>85</td>
      <td>Best way to use SHAP for text without losing word position</td>
      <td>2019-03-10</td>
      <td>2019-03-11</td>
      <td>1629</td>
      <td>1628</td>
      <td>NONE</td>
      <td>1</td>
      <td>1456.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1110</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>110</td>
      <td>DeepExplainer on CUDA raises hook 'deeplift_grad' error</td>
      <td>2020-03-19</td>
      <td>2023-05-24</td>
      <td>1255</td>
      <td>94</td>
      <td>NONE</td>
      <td>4</td>
      <td>1456.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>366</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>66</td>
      <td>Understanding SHAP for multi-classification problem</td>
      <td>2018-12-24</td>
      <td>2023-07-21</td>
      <td>1706</td>
      <td>36</td>
      <td>NONE</td>
      <td>25</td>
      <td>1457.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2109</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>109</td>
      <td>Coloring of \"Sum of X other features\" in beeswarm pl</td>
      <td>2021-10-21</td>
      <td>2023-07-03</td>
      <td>674</td>
      <td>54</td>
      <td>NONE</td>
      <td>0</td>
      <td>1457.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2745</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>745</td>
      <td>Random floating-point errors in GitHub Actions</td>
      <td>2023-06-03</td>
      <td>2023-07-08</td>
      <td>83</td>
      <td>48</td>
      <td>COLLABORATOR</td>
      <td>8</td>
      <td>1462.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2269</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>269</td>
      <td>Which is the correct way to compare SHAP values from two ML models?</td>
      <td>2022-03-03</td>
      <td>2022-10-07</td>
      <td>541</td>
      <td>323</td>
      <td>NONE</td>
      <td>1</td>
      <td>1470.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1530</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>530</td>
      <td>Additivity check failed for largeish Xgboost Model</td>
      <td>2020-10-28</td>
      <td>2020-11-03</td>
      <td>1032</td>
      <td>1026</td>
      <td>NONE</td>
      <td>1</td>
      <td>1472.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1552</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>552</td>
      <td>expected_values don't match with average predicted values</td>
      <td>2020-11-11</td>
      <td>2020-11-12</td>
      <td>1017</td>
      <td>1016</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>1474.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>761</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>61</td>
      <td>force_plot visualizing all predictions doesn't show the feature with highest shap values</td>
      <td>2019-08-20</td>
      <td>2019-08-31</td>
      <td>1467</td>
      <td>1455</td>
      <td>NONE</td>
      <td>1</td>
      <td>1476.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1518</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>518</td>
      <td>TreeExplainer breaks for large XGB models</td>
      <td>2020-10-20</td>
      <td>2020-10-21</td>
      <td>1039</td>
      <td>1039</td>
      <td>NONE</td>
      <td>0</td>
      <td>1484.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1014</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>014</td>
      <td>DeepExplainer returns error as Explanations do not sum up to the model's output</td>
      <td>2020-01-23</td>
      <td>2020-02-20</td>
      <td>1311</td>
      <td>1283</td>
      <td>NONE</td>
      <td>5</td>
      <td>1484.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>365</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>65</td>
      <td>Understanding Keras and TensorFlow Text Classification Outputs</td>
      <td>2018-12-22</td>
      <td>2018-12-29</td>
      <td>1708</td>
      <td>1700</td>
      <td>NONE</td>
      <td>3</td>
      <td>1489.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1377</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>377</td>
      <td>TreeExplainer efficiency fail points to bug with XGBoost model loading</td>
      <td>2020-08-20</td>
      <td>2020-08-27</td>
      <td>1101</td>
      <td>1094</td>
      <td>CONTRIBUTOR</td>
      <td>2</td>
      <td>1498.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>728</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>28</td>
      <td>explainer.expected_value changes from scalar to list after calling TreeExplainer.shap_values() with LightGBM model</td>
      <td>2019-08-05</td>
      <td>2020-05-05</td>
      <td>1481</td>
      <td>1208</td>
      <td>CONTRIBUTOR</td>
      <td>5</td>
      <td>1501.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2717</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>717</td>
      <td>partial_dependence using \"rank(number)\" as index seems to always err</td>
      <td>2023-05-13</td>
      <td>2023-06-17</td>
      <td>105</td>
      <td>70</td>
      <td>NONE</td>
      <td>2</td>
      <td>1502.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2144</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>144</td>
      <td>Error when using TeacherForcing model for explainer due to the TeacherForcing __call__() taking 2 positional args</td>
      <td>2021-11-18</td>
      <td>2021-11-18</td>
      <td>646</td>
      <td>646</td>
      <td>NONE</td>
      <td>0</td>
      <td>1504.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2463</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>463</td>
      <td>Error while pickling kernal explainer from a trained StackingClassifier</td>
      <td>2022-07-26</td>
      <td>2022-08-04</td>
      <td>395</td>
      <td>387</td>
      <td>NONE</td>
      <td>12</td>
      <td>1505.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1702</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>702</td>
      <td>Shap values give additivity error with XGBoost when the parameters 'tree_method': 'hist' is set</td>
      <td>2021-01-14</td>
      <td>2023-04-13</td>
      <td>954</td>
      <td>135</td>
      <td>NONE</td>
      <td>1</td>
      <td>1505.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1070</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>070</td>
      <td>TreeExplainer failing additivity check by huge margin randomly</td>
      <td>2020-02-27</td>
      <td>2020-08-19</td>
      <td>1276</td>
      <td>1102</td>
      <td>NONE</td>
      <td>10</td>
      <td>1506.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>929</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>29</td>
      <td>AssertionError: Explanations do not sum up to the model's output! Please post as a github issue.</td>
      <td>2019-12-05</td>
      <td>2020-09-29</td>
      <td>1360</td>
      <td>1061</td>
      <td>NONE</td>
      <td>16</td>
      <td>1509.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1744</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>744</td>
      <td>[Question] how to get meaningful expected value with down-sampled dataset</td>
      <td>2021-01-28</td>
      <td>2022-03-10</td>
      <td>940</td>
      <td>534</td>
      <td>NONE</td>
      <td>1</td>
      <td>1512.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1775</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>775</td>
      <td>explaining force_plot when feature=0</td>
      <td>2021-02-17</td>
      <td>2021-02-17</td>
      <td>920</td>
      <td>920</td>
      <td>NONE</td>
      <td>0</td>
      <td>1513.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1837</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>837</td>
      <td>Explainer (explanation object) vs Kernel/Tree explainer (ndarray shap values) tabular data</td>
      <td>2021-03-25</td>
      <td>2022-03-14</td>
      <td>884</td>
      <td>530</td>
      <td>NONE</td>
      <td>5</td>
      <td>1515.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1340</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>340</td>
      <td>running time question of shap_values if with model_output = \"logloss\" in explain</td>
      <td>2020-08-03</td>
      <td>2020-12-02</td>
      <td>1118</td>
      <td>996</td>
      <td>NONE</td>
      <td>1</td>
      <td>1519.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1931</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>931</td>
      <td>Speeding up partition_tree (O(n**2) -&gt; O(n))</td>
      <td>2021-05-27</td>
      <td>2021-05-27</td>
      <td>821</td>
      <td>821</td>
      <td>NONE</td>
      <td>0</td>
      <td>1519.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1808</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>808</td>
      <td>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 337: invalid start byte</td>
      <td>2021-03-08</td>
      <td>2021-09-01</td>
      <td>901</td>
      <td>723</td>
      <td>NONE</td>
      <td>2</td>
      <td>1519.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1805</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>805</td>
      <td>RuntimeError: only Tensors of floating point dtype can require gradients</td>
      <td>2021-03-05</td>
      <td>2021-03-29</td>
      <td>904</td>
      <td>880</td>
      <td>NONE</td>
      <td>1</td>
      <td>1524.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2292</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>292</td>
      <td>How to extract information from  ``shap.utils.hclust`` to remove redundant features not only by visual inspection barplot?</td>
      <td>2022-03-19</td>
      <td>2022-03-19</td>
      <td>525</td>
      <td>525</td>
      <td>NONE</td>
      <td>0</td>
      <td>1525.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2628</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>628</td>
      <td>Why is shap.plots.bar() not working for me?</td>
      <td>2023-01-02</td>
      <td>2023-01-16</td>
      <td>236</td>
      <td>221</td>
      <td>NONE</td>
      <td>2</td>
      <td>1525.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1560</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>560</td>
      <td>Docu: Linear Regression SHAP motivation example wrong (notebook general/Explainable AI with SHAP values)</td>
      <td>2020-11-14</td>
      <td>2020-11-14</td>
      <td>1014</td>
      <td>1014</td>
      <td>NONE</td>
      <td>0</td>
      <td>1526.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>439</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>39</td>
      <td>Question about handling pretrained embeddings variables</td>
      <td>2019-02-12</td>
      <td>2019-03-20</td>
      <td>1656</td>
      <td>1620</td>
      <td>NONE</td>
      <td>3</td>
      <td>1527.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>795</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>95</td>
      <td>LightGBM summary_plot \"dot\" with binary objecti</td>
      <td>2019-09-06</td>
      <td>2020-09-22</td>
      <td>1450</td>
      <td>1068</td>
      <td>NONE</td>
      <td>4</td>
      <td>1531.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>643</td>
      <td><a href="https://github.com/shap/shap/issues/644">644</a></td>
      <td>Explaining stateful LSTM model</td>
      <td>2019-06-13</td>
      <td>2019-09-30</td>
      <td>1535</td>
      <td>1426</td>
      <td>NONE</td>
      <td>5</td>
      <td>1531.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1625</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>625</td>
      <td>Explanation for Shap Deep Explainer Binary classification</td>
      <td>2020-12-15</td>
      <td>2020-12-18</td>
      <td>984</td>
      <td>981</td>
      <td>NONE</td>
      <td>1</td>
      <td>1533.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2726</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>726</td>
      <td>GradientExplainer only works on copies of models?</td>
      <td>2023-05-20</td>
      <td>2023-05-20</td>
      <td>98</td>
      <td>98</td>
      <td>NONE</td>
      <td>0</td>
      <td>1534.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2019</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>019</td>
      <td>How to save explainer object</td>
      <td>2021-08-02</td>
      <td>2023-08-16</td>
      <td>753</td>
      <td>10</td>
      <td>NONE</td>
      <td>11</td>
      <td>1537.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1274</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>274</td>
      <td>Catboost dependence plot not working on categorical features (strings)</td>
      <td>2020-06-17</td>
      <td>2021-09-16</td>
      <td>1164</td>
      <td>709</td>
      <td>NONE</td>
      <td>3</td>
      <td>1545.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>867</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>67</td>
      <td>Only analyze features included in model (predcontrib,predinteraction)</td>
      <td>2019-10-27</td>
      <td>2019-11-04</td>
      <td>1399</td>
      <td>1390</td>
      <td>NONE</td>
      <td>4</td>
      <td>1550.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>486</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>86</td>
      <td>1d array training data fails explainer object creation</td>
      <td>2019-03-11</td>
      <td>2019-03-13</td>
      <td>1628</td>
      <td>1627</td>
      <td>NONE</td>
      <td>4</td>
      <td>1553.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>718</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>18</td>
      <td>importing the shap package fails due to cairo dependency</td>
      <td>2019-07-28</td>
      <td>2019-07-28</td>
      <td>1490</td>
      <td>1490</td>
      <td>NONE</td>
      <td>0</td>
      <td>1573.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1974</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>974</td>
      <td>Plot function throws exception when linear regression model is used</td>
      <td>2021-06-28</td>
      <td>2021-06-28</td>
      <td>788</td>
      <td>788</td>
      <td>NONE</td>
      <td>0</td>
      <td>1575.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2655</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>655</td>
      <td>Text masker issue with deberta tokenizer and other bpe tokenizers</td>
      <td>2023-02-01</td>
      <td>2023-02-01</td>
      <td>206</td>
      <td>206</td>
      <td>NONE</td>
      <td>0</td>
      <td>1577.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1666</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>666</td>
      <td>Problem with a fastai model (RuntimeError: hook 'deeplift_grad' has changed the size of value)</td>
      <td>2020-12-29</td>
      <td>2020-12-29</td>
      <td>969</td>
      <td>969</td>
      <td>NONE</td>
      <td>0</td>
      <td>1581.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>802</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>02</td>
      <td>Aggregation of Shap Values for time-series (3D) data</td>
      <td>2019-09-10</td>
      <td>2022-06-30</td>
      <td>1446</td>
      <td>421</td>
      <td>NONE</td>
      <td>2</td>
      <td>1582.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2030</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>030</td>
      <td>Discrepancies between GPUTree and TreeExplainer</td>
      <td>2021-08-09</td>
      <td>2021-08-09</td>
      <td>747</td>
      <td>747</td>
      <td>NONE</td>
      <td>0</td>
      <td>1586.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>434</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>34</td>
      <td>Interpretation of SHAP Values away from the mean</td>
      <td>2019-02-09</td>
      <td>2019-11-21</td>
      <td>1658</td>
      <td>1374</td>
      <td>NONE</td>
      <td>11</td>
      <td>1590.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>882</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>82</td>
      <td>SHAP DeepExplainer not working with functional API</td>
      <td>2019-11-06</td>
      <td>2021-07-11</td>
      <td>1389</td>
      <td>776</td>
      <td>NONE</td>
      <td>3</td>
      <td>1593.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2647</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>647</td>
      <td>shap_interaction_values - interpretation as difference in SHAP values</td>
      <td>2023-01-23</td>
      <td>2023-01-24</td>
      <td>214</td>
      <td>213</td>
      <td>NONE</td>
      <td>1</td>
      <td>1594.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1939</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>939</td>
      <td>Is overlay option still valid in shap.plots.scatter (v0.39)</td>
      <td>2021-06-02</td>
      <td>2021-06-02</td>
      <td>815</td>
      <td>815</td>
      <td>NONE</td>
      <td>0</td>
      <td>1595.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1205</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>205</td>
      <td>dependence_plot() on categorical(or object) feature doesn't work</td>
      <td>2020-05-12</td>
      <td>2020-08-10</td>
      <td>1201</td>
      <td>1111</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>1599.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1240</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>240</td>
      <td>TreeExplainer not returning expected_value in the presence of category type input using Lightgbm</td>
      <td>2020-05-30</td>
      <td>2020-05-30</td>
      <td>1183</td>
      <td>1183</td>
      <td>NONE</td>
      <td>0</td>
      <td>1600.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>541</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>1</td>
      <td>Shap values Error when using XGBoost Sklearn API</td>
      <td>2019-04-09</td>
      <td>2019-04-09</td>
      <td>1599</td>
      <td>1599</td>
      <td>NONE</td>
      <td>1</td>
      <td>1602.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1774</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>774</td>
      <td>Shap for LSTM binary classification model in Keras</td>
      <td>2021-02-15</td>
      <td>2021-02-25</td>
      <td>922</td>
      <td>912</td>
      <td>NONE</td>
      <td>2</td>
      <td>1617.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>869</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>69</td>
      <td>Need help for interpreting force plot. Bug in Visualization?</td>
      <td>2019-10-28</td>
      <td>2019-10-28</td>
      <td>1398</td>
      <td>1398</td>
      <td>NONE</td>
      <td>0</td>
      <td>1621.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>214</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>14</td>
      <td>Tree Shap gives extremely high shap values while Kernel Shap doesn't</td>
      <td>2018-08-13</td>
      <td>2019-11-14</td>
      <td>1839</td>
      <td>1380</td>
      <td>NONE</td>
      <td>11</td>
      <td>1624.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>810</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>10</td>
      <td>Calculating shap values with scikit learn svm regressor</td>
      <td>2019-09-17</td>
      <td>2022-10-07</td>
      <td>1439</td>
      <td>323</td>
      <td>NONE</td>
      <td>4</td>
      <td>1636.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2237</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>237</td>
      <td>SHAP with DQN</td>
      <td>2022-02-07</td>
      <td>2022-02-16</td>
      <td>565</td>
      <td>556</td>
      <td>NONE</td>
      <td>3</td>
      <td>1642.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2668</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>668</td>
      <td>Ensemble Model interpretability</td>
      <td>2023-02-23</td>
      <td>2023-02-23</td>
      <td>184</td>
      <td>184</td>
      <td>NONE</td>
      <td>0</td>
      <td>1646.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1680</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>680</td>
      <td>unexpected keyword argument 'feature_names' || shap.plots.text Example</td>
      <td>2021-01-07</td>
      <td>2021-01-23</td>
      <td>960</td>
      <td>945</td>
      <td>NONE</td>
      <td>2</td>
      <td>1647.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2318</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>318</td>
      <td>Question - why SHAP expected value is 0.5 always for my data?</td>
      <td>2022-03-31</td>
      <td>2022-03-31</td>
      <td>513</td>
      <td>513</td>
      <td>NONE</td>
      <td>0</td>
      <td>1647.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>527</td>
      <td><a href="https://github.com/shap/shap/issues/53">53</a>7</td>
      <td>Colorbar feature scale mismatch between dependence plot and summary plot</td>
      <td>2019-04-03</td>
      <td>2023-08-26</td>
      <td>1606</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>1651.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2861</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>861</td>
      <td>Incorrect force plot representation</td>
      <td>2023-07-18</td>
      <td>2023-07-18</td>
      <td>39</td>
      <td>39</td>
      <td>NONE</td>
      <td>1</td>
      <td>1658.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>993</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>93</td>
      <td>Error using custom rank on GradientExplainer:  IndexError: tuple index out of range</td>
      <td>2020-01-12</td>
      <td>2020-11-24</td>
      <td>1321</td>
      <td>1005</td>
      <td>NONE</td>
      <td>1</td>
      <td>1660.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>568</td>
      <td><a href="https://github.com/shap/shap/issues/569">569</a></td>
      <td>linear shap + error with sparse input</td>
      <td>2019-04-29</td>
      <td>2019-06-15</td>
      <td>1579</td>
      <td>1533</td>
      <td>NONE</td>
      <td>2</td>
      <td>1665.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>57</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a></td>
      <td>Support summary_plot for categorical features</td>
      <td>2018-04-17</td>
      <td>2022-02-24</td>
      <td>1957</td>
      <td>548</td>
      <td>NONE</td>
      <td>34</td>
      <td>1668.0</td>
      <td>No</td>
      <td>"Support summary issue with implemented series 'title' and 'body'."</td>
      <td>"Shape Issue"</td>
      <td>enhancement</td>
    </tr>
    <tr>
      <td>122</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>22</td>
      <td>(Paper): Implementation differences KernelShap with shapley sampling values</td>
      <td>2018-06-20</td>
      <td>2018-11-23</td>
      <td>1893</td>
      <td>1736</td>
      <td>NONE</td>
      <td>7</td>
      <td>1671.0</td>
      <td>No</td>
      <td>Issue regarding implementation of a series titled 'Paper' with shape: (1,).</td>
      <td>"Shape Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2507</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>507</td>
      <td>Error: Object of type Decimal is not JSON serializable</td>
      <td>2022-09-14</td>
      <td>2022-09-14</td>
      <td>346</td>
      <td>346</td>
      <td>NONE</td>
      <td>0</td>
      <td>1672.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>668</td>
      <td><a href="https://github.com/shap/shap/issues/67">67</a>8</td>
      <td>Shap value doesn't match model output</td>
      <td>2019-06-27</td>
      <td>2021-12-29</td>
      <td>1521</td>
      <td>605</td>
      <td>NONE</td>
      <td>7</td>
      <td>1685.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1142</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>142</td>
      <td>Getting an issue when I run the shap.force plot that appears to be related to the shap_values</td>
      <td>2020-04-07</td>
      <td>2020-04-08</td>
      <td>1235</td>
      <td>1235</td>
      <td>NONE</td>
      <td>1</td>
      <td>1690.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1292</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>292</td>
      <td>Shap value doesn't match with lgbm model output</td>
      <td>2020-06-26</td>
      <td>2021-08-16</td>
      <td>1156</td>
      <td>740</td>
      <td>NONE</td>
      <td>3</td>
      <td>1692.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>964</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>64</td>
      <td>'None' gradient wrt to the input using TF2, Embeddings and GradientExplainer.</td>
      <td>2019-12-20</td>
      <td>2021-11-10</td>
      <td>1345</td>
      <td>653</td>
      <td>NONE</td>
      <td>3</td>
      <td>1693.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>960</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>60</td>
      <td>Decision plot issue</td>
      <td>2019-12-18</td>
      <td>2020-11-05</td>
      <td>1347</td>
      <td>1024</td>
      <td>NONE</td>
      <td>6</td>
      <td>1694.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2186</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>186</td>
      <td>Replace references to deprecated Boston housing prices dataset with another dataset</td>
      <td>2021-12-14</td>
      <td>2023-07-27</td>
      <td>620</td>
      <td>30</td>
      <td>NONE</td>
      <td>1</td>
      <td>1695.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>999</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>99</td>
      <td>Additiviy Check Failed</td>
      <td>2020-01-17</td>
      <td>2020-01-17</td>
      <td>1317</td>
      <td>1317</td>
      <td>NONE</td>
      <td>0</td>
      <td>1699.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2954</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>954</td>
      <td>BUG: Zero shap values w/ llama-2 models</td>
      <td>2023-08-25</td>
      <td>2023-08-25</td>
      <td>1</td>
      <td>1</td>
      <td>NONE</td>
      <td>3</td>
      <td>1709.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2006</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>006</td>
      <td>Waterfall plotting causes \"IndexError: string index out of range\" when some categorical values = \"00\", \"0\" or any \</td>
      <td>2021-07-20</td>
      <td>2021-07-20</td>
      <td>767</td>
      <td>767</td>
      <td>NONE</td>
      <td>0</td>
      <td>1709.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2677</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>677</td>
      <td>Any support for Transformer with tabular timeseries 3D inputs?</td>
      <td>2023-03-10</td>
      <td>2023-03-10</td>
      <td>169</td>
      <td>169</td>
      <td>NONE</td>
      <td>0</td>
      <td>1714.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2699</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>699</td>
      <td>LightGBM categorical feature support for Shap values in probability</td>
      <td>2023-04-11</td>
      <td>2023-07-13</td>
      <td>137</td>
      <td>44</td>
      <td>NONE</td>
      <td>4</td>
      <td>1720.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1534</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>534</td>
      <td>Difficultly explaining the expected_value since it '= to mean of predictions on training data</td>
      <td>2020-10-31</td>
      <td>2020-10-31</td>
      <td>1028</td>
      <td>1028</td>
      <td>NONE</td>
      <td>0</td>
      <td>1738.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1303</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>303</td>
      <td>How to calculate SHAP values for simple MLP Neural Network?</td>
      <td>2020-07-09</td>
      <td>2021-02-03</td>
      <td>1143</td>
      <td>934</td>
      <td>NONE</td>
      <td>3</td>
      <td>1744.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1891</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>891</td>
      <td>GPUTreeExplainer raises import error on AWS Deep Learning AMI 44</td>
      <td>2021-04-30</td>
      <td>2022-03-04</td>
      <td>848</td>
      <td>540</td>
      <td>NONE</td>
      <td>3</td>
      <td>1752.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2586</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>586</td>
      <td>Interpretation of Shapley values returned by TreeShap for multiclass classification</td>
      <td>2022-11-17</td>
      <td>2022-11-17</td>
      <td>282</td>
      <td>282</td>
      <td>NONE</td>
      <td>0</td>
      <td>1759.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2451</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>451</td>
      <td>Explainer Index out of range</td>
      <td>2022-07-13</td>
      <td>2022-09-07</td>
      <td>409</td>
      <td>353</td>
      <td>NONE</td>
      <td>22</td>
      <td>1772.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>923</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>23</td>
      <td>DeepExplainer AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_SESSION'</td>
      <td>2019-12-03</td>
      <td>2020-05-09</td>
      <td>1361</td>
      <td>1203</td>
      <td>NONE</td>
      <td>6</td>
      <td>1774.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1543</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>543</td>
      <td>Error using DeepExplainer with a keras model when data type is a sequence</td>
      <td>2020-11-08</td>
      <td>2020-11-08</td>
      <td>1021</td>
      <td>1021</td>
      <td>NONE</td>
      <td>0</td>
      <td>1781.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2896</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>896</td>
      <td>BUG: Exception: The passed model is not callable and cannot be analyzed directly with the given masker! Model: GBTClassificationModel (uid=GBTClassifier_c6502ed2671a) with 100 trees</td>
      <td>2023-07-28</td>
      <td>2023-08-20</td>
      <td>29</td>
      <td>6</td>
      <td>NONE</td>
      <td>16</td>
      <td>1783.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1671</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>671</td>
      <td>Dimension Mismatch Error from DeepExplainer for Pytorch model</td>
      <td>2021-01-02</td>
      <td>2022-04-27</td>
      <td>966</td>
      <td>486</td>
      <td>NONE</td>
      <td>2</td>
      <td>1789.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>544</td>
      <td><a href="https://github.com/shap/shap/issues/55">55</a>4</td>
      <td>Using SHAP values to estimate value add of a feature</td>
      <td>2019-04-10</td>
      <td>2023-08-26</td>
      <td>1599</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>1797.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1332</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>332</td>
      <td>Can shap handle SparseTensor in Tensorflow input?</td>
      <td>2020-07-28</td>
      <td>2020-07-28</td>
      <td>1124</td>
      <td>1124</td>
      <td>NONE</td>
      <td>0</td>
      <td>1801.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1912</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>912</td>
      <td>background data size limited to 100, xgboost</td>
      <td>2021-05-11</td>
      <td>2021-06-07</td>
      <td>837</td>
      <td>810</td>
      <td>NONE</td>
      <td>2</td>
      <td>1801.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1747</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>747</td>
      <td>Contradiction between shap and shap_interactions</td>
      <td>2021-01-28</td>
      <td>2021-01-28</td>
      <td>940</td>
      <td>940</td>
      <td>NONE</td>
      <td>0</td>
      <td>1806.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>975</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>75</td>
      <td>AttributeError: module 'keras.backend.tensorflow_backend' has no attribute '_SESSION'</td>
      <td>2020-01-01</td>
      <td>2020-07-07</td>
      <td>1332</td>
      <td>1145</td>
      <td>NONE</td>
      <td>2</td>
      <td>1812.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>559</td>
      <td><a href="https://github.com/shap/shap/issues/56">56</a>9</td>
      <td>shap values not adding up to margins</td>
      <td>2019-04-23</td>
      <td>2019-10-25</td>
      <td>1586</td>
      <td>1400</td>
      <td>NONE</td>
      <td>2</td>
      <td>1813.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1574</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>574</td>
      <td>Error when updating the shap package</td>
      <td>2020-11-23</td>
      <td>2021-03-01</td>
      <td>1006</td>
      <td>908</td>
      <td>NONE</td>
      <td>1</td>
      <td>1820.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1082</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>082</td>
      <td>'None' gradient with GradientExplainer (Tensorflow 1)</td>
      <td>2020-03-03</td>
      <td>2020-03-03</td>
      <td>1271</td>
      <td>1271</td>
      <td>NONE</td>
      <td>0</td>
      <td>1830.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1681</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>681</td>
      <td>Linear explainer with Impute masker fails</td>
      <td>2021-01-08</td>
      <td>2021-01-08</td>
      <td>960</td>
      <td>960</td>
      <td>NONE</td>
      <td>0</td>
      <td>1848.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1571</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>571</td>
      <td>Weird SHAP value on nonsense features</td>
      <td>2020-11-20</td>
      <td>2021-01-06</td>
      <td>1009</td>
      <td>962</td>
      <td>NONE</td>
      <td>2</td>
      <td>1858.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1135</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>135</td>
      <td>cannot import name '_cext'  !!</td>
      <td>2020-04-02</td>
      <td>2023-07-24</td>
      <td>1241</td>
      <td>33</td>
      <td>NONE</td>
      <td>16</td>
      <td>1860.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1840</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>840</td>
      <td>shap.plots.force issue</td>
      <td>2021-03-27</td>
      <td>2023-04-14</td>
      <td>881</td>
      <td>134</td>
      <td>NONE</td>
      <td>4</td>
      <td>1870.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1525</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>525</td>
      <td>setting an array element with a sequence when explainer Exact</td>
      <td>2020-10-26</td>
      <td>2020-10-27</td>
      <td>1034</td>
      <td>1033</td>
      <td>NONE</td>
      <td>0</td>
      <td>1883.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1567</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>567</td>
      <td>Wrong documentation for new Explainer</td>
      <td>2020-11-18</td>
      <td>2020-11-18</td>
      <td>1011</td>
      <td>1011</td>
      <td>NONE</td>
      <td>0</td>
      <td>1887.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2415</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>415</td>
      <td>Plot_waterfall() error</td>
      <td>2022-06-06</td>
      <td>2022-06-14</td>
      <td>446</td>
      <td>438</td>
      <td>NONE</td>
      <td>1</td>
      <td>1897.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1580</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>580</td>
      <td>(Windows10) Matplotlib support failed Fatal Python error: Cannot recover from stack overflow.</td>
      <td>2020-11-28</td>
      <td>2020-11-28</td>
      <td>1001</td>
      <td>1001</td>
      <td>NONE</td>
      <td>0</td>
      <td>1902.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2544</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>544</td>
      <td>Lightgbm API pred_contrib supports sklearn TransformedTargetRegressor, but SHAP does not support</td>
      <td>2022-10-09</td>
      <td>2022-10-09</td>
      <td>321</td>
      <td>321</td>
      <td>NONE</td>
      <td>0</td>
      <td>1907.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1636</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>636</td>
      <td>RuntimeError: only Tensors of floating point dtype can require gradients</td>
      <td>2020-12-18</td>
      <td>2023-07-06</td>
      <td>980</td>
      <td>50</td>
      <td>NONE</td>
      <td>7</td>
      <td>1910.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1734</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>734</td>
      <td>How can interpret a certain feature has positive or negative impact correctly?</td>
      <td>2021-01-25</td>
      <td>2023-07-26</td>
      <td>943</td>
      <td>31</td>
      <td>NONE</td>
      <td>5</td>
      <td>1910.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>776</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>76</td>
      <td>What would be needed to implement interaction values for other Explainers? For which one would it be most straightforward?</td>
      <td>2019-08-27</td>
      <td>2019-08-31</td>
      <td>1460</td>
      <td>1456</td>
      <td>NONE</td>
      <td>1</td>
      <td>1917.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2490</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>490</td>
      <td>SHAP TreeExplainer is not compatible with XGBoost models that use Pandas categorical features</td>
      <td>2022-08-26</td>
      <td>2023-07-13</td>
      <td>365</td>
      <td>44</td>
      <td>NONE</td>
      <td>12</td>
      <td>1919.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1642</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>642</td>
      <td>Using GradientExplainer on stateful keras LSTM</td>
      <td>2020-12-21</td>
      <td>2020-12-22</td>
      <td>978</td>
      <td>977</td>
      <td>NONE</td>
      <td>0</td>
      <td>1928.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>787</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>87</td>
      <td>How to only explain a subset of the input features?</td>
      <td>2019-09-01</td>
      <td>2019-09-23</td>
      <td>1455</td>
      <td>1433</td>
      <td>NONE</td>
      <td>2</td>
      <td>1936.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1640</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>640</td>
      <td>shap.dependence_plot doesn't work with sparse matrix</td>
      <td>2020-12-20</td>
      <td>2020-12-20</td>
      <td>978</td>
      <td>978</td>
      <td>NONE</td>
      <td>0</td>
      <td>1937.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>965</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>65</td>
      <td>Unable to manually calculate expected value for CatBoostClassifier</td>
      <td>2019-12-20</td>
      <td>2020-01-08</td>
      <td>1345</td>
      <td>1326</td>
      <td>NONE</td>
      <td>5</td>
      <td>1947.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1555</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>555</td>
      <td>Why do I get different expected_value when I include the training data in TreeExplainer?</td>
      <td>2020-11-13</td>
      <td>2020-11-13</td>
      <td>1016</td>
      <td>1016</td>
      <td>NONE</td>
      <td>0</td>
      <td>1955.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1041</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>041</td>
      <td>KeyError: 'objective' with LGBMRegressor Model</td>
      <td>2020-02-12</td>
      <td>2022-10-21</td>
      <td>1290</td>
      <td>309</td>
      <td>NONE</td>
      <td>8</td>
      <td>1962.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2025</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>025</td>
      <td>Non-full backward hook with shap.DeepExplainer + PyTorch</td>
      <td>2021-08-05</td>
      <td>2023-05-10</td>
      <td>751</td>
      <td>107</td>
      <td>NONE</td>
      <td>1</td>
      <td>1963.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>981</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>81</td>
      <td>shap.DeepExplainer takes forever to finish for larget dataset</td>
      <td>2020-01-04</td>
      <td>2020-01-04</td>
      <td>1330</td>
      <td>1330</td>
      <td>NONE</td>
      <td>0</td>
      <td>1966.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>474</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>74</td>
      <td>Base_value not matching</td>
      <td>2019-03-04</td>
      <td>2019-03-14</td>
      <td>1636</td>
      <td>1626</td>
      <td>NONE</td>
      <td>3</td>
      <td>1969.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2141</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>141</td>
      <td>How to interpret force_plot output of encoded categorical variables?</td>
      <td>2021-11-17</td>
      <td>2021-11-17</td>
      <td>647</td>
      <td>647</td>
      <td>NONE</td>
      <td>0</td>
      <td>1972.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>607</td>
      <td><a href="https://github.com/shap/shap/issues/61">61</a>7</td>
      <td>KernelExplainer keep_index error with kmeans</td>
      <td>2019-05-24</td>
      <td>2021-09-07</td>
      <td>1555</td>
      <td>718</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>1974.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1502</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>502</td>
      <td>Can I use SHAP Values to Explain SHAP Values?</td>
      <td>2020-10-11</td>
      <td>2020-10-11</td>
      <td>1049</td>
      <td>1049</td>
      <td>NONE</td>
      <td>0</td>
      <td>1974.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1617</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>617</td>
      <td>Document exact GPU compilation procedure using CUDA_PATH</td>
      <td>2020-12-13</td>
      <td>2022-11-23</td>
      <td>986</td>
      <td>276</td>
      <td>NONE</td>
      <td>29</td>
      <td>1983.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>94</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>4</td>
      <td>Improved coloring of summary_plot 'dot' type</td>
      <td>2018-05-21</td>
      <td>2018-05-21</td>
      <td>1922</td>
      <td>1922</td>
      <td>CONTRIBUTOR</td>
      <td>2</td>
      <td>1996.0</td>
      <td>No</td>
      <td>Issue: Discussing improvements on color in a series titled 'title'.</td>
      <td>"Shape Issue"</td>
      <td>enhancement</td>
    </tr>
    <tr>
      <td>2474</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>474</td>
      <td>Poor performance of TreeExplainer for shap version &gt;=0.36</td>
      <td>2022-08-07</td>
      <td>2022-08-07</td>
      <td>384</td>
      <td>384</td>
      <td>NONE</td>
      <td>0</td>
      <td>2006.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2396</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>396</td>
      <td>Summary Plot in SHAP for MultioutputClassifier</td>
      <td>2022-05-23</td>
      <td>2022-07-18</td>
      <td>460</td>
      <td>404</td>
      <td>NONE</td>
      <td>1</td>
      <td>2017.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>996</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>96</td>
      <td>Not Understanding the Predicted Value in Binary Classification problem</td>
      <td>2020-01-13</td>
      <td>2020-08-08</td>
      <td>1321</td>
      <td>1113</td>
      <td>NONE</td>
      <td>3</td>
      <td>2029.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>652</td>
      <td><a href="https://github.com/shap/shap/issues/66">66</a>2</td>
      <td>tf.gradients() in phi_symbolic()of TFDeepExplainer returns None</td>
      <td>2019-06-20</td>
      <td>2019-06-24</td>
      <td>1528</td>
      <td>1523</td>
      <td>NONE</td>
      <td>2</td>
      <td>2029.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1708</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>708</td>
      <td>Python memory corruption crash</td>
      <td>2021-01-18</td>
      <td>2021-01-18</td>
      <td>950</td>
      <td>950</td>
      <td>NONE</td>
      <td>2</td>
      <td>2039.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>879</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>79</td>
      <td>Issue when using TFDeepExplainer with Keras Tf2</td>
      <td>2019-11-02</td>
      <td>2019-11-06</td>
      <td>1393</td>
      <td>1389</td>
      <td>NONE</td>
      <td>2</td>
      <td>2039.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1491</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>491</td>
      <td>TreeSHAP Expected Value is not equal to Mean of predictions</td>
      <td>2020-10-06</td>
      <td>2020-10-06</td>
      <td>1054</td>
      <td>1054</td>
      <td>NONE</td>
      <td>0</td>
      <td>2041.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1699</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>699</td>
      <td>tf.Keras and shap.Explainer fail with shap v0.37</td>
      <td>2021-01-14</td>
      <td>2023-04-19</td>
      <td>954</td>
      <td>129</td>
      <td>NONE</td>
      <td>19</td>
      <td>2052.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2240</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>240</td>
      <td>Difference in model feature importance and shap summary plot</td>
      <td>2022-02-12</td>
      <td>2022-02-26</td>
      <td>560</td>
      <td>546</td>
      <td>NONE</td>
      <td>1</td>
      <td>2059.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>458</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>58</td>
      <td>DeepExplainer with RGB images</td>
      <td>2019-02-25</td>
      <td>2019-03-15</td>
      <td>1643</td>
      <td>1625</td>
      <td>NONE</td>
      <td>6</td>
      <td>2059.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1788</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>788</td>
      <td>NGBRegressor col_sample &lt; 1 shap_values don't add up to prediction</td>
      <td>2021-02-24</td>
      <td>2021-02-24</td>
      <td>913</td>
      <td>913</td>
      <td>NONE</td>
      <td>0</td>
      <td>2063.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1139</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>139</td>
      <td>The SHAP explanations do not sum up to the model's output!</td>
      <td>2020-04-06</td>
      <td>2023-02-24</td>
      <td>1237</td>
      <td>183</td>
      <td>NONE</td>
      <td>8</td>
      <td>2080.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2581</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>581</td>
      <td>'utf-8' codec can't decode byte 0xff in position 336: invalid start byte</td>
      <td>2022-11-14</td>
      <td>2022-11-14</td>
      <td>285</td>
      <td>285</td>
      <td>NONE</td>
      <td>0</td>
      <td>2102.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2302</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>302</td>
      <td>SHAP values of 0.0 for Gaussian NB</td>
      <td>2022-03-22</td>
      <td>2022-12-25</td>
      <td>522</td>
      <td>243</td>
      <td>NONE</td>
      <td>4</td>
      <td>2111.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>291</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>91</td>
      <td>Interaction Error with LightGBM</td>
      <td>2018-10-22</td>
      <td>2018-11-02</td>
      <td>1769</td>
      <td>1757</td>
      <td>NONE</td>
      <td>3</td>
      <td>2114.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2945</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>945</td>
      <td>Partial Dependence Plots doesnt work with custom ax</td>
      <td>2023-08-21</td>
      <td>2023-08-26</td>
      <td>4</td>
      <td>0</td>
      <td>NONE</td>
      <td>2</td>
      <td>2119.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2131</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>131</td>
      <td>keras deep explainer</td>
      <td>2021-11-08</td>
      <td>2022-02-26</td>
      <td>656</td>
      <td>545</td>
      <td>NONE</td>
      <td>1</td>
      <td>2120.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2448</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>448</td>
      <td>Using DeepExplainer for LSTM : AttributeError: 'Deep' object has no attribute 'masker'</td>
      <td>2022-07-08</td>
      <td>2023-04-06</td>
      <td>414</td>
      <td>142</td>
      <td>NONE</td>
      <td>13</td>
      <td>2120.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1484</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>484</td>
      <td>Interpretation for drastic difference between shap logloss, probability and other importance metrics</td>
      <td>2020-10-02</td>
      <td>2020-10-02</td>
      <td>1057</td>
      <td>1057</td>
      <td>NONE</td>
      <td>0</td>
      <td>2121.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2920</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>920</td>
      <td>BUG: TreeExplainer with GradientBoostingClassifier incorrectly returns log odds explanations</td>
      <td>2023-08-03</td>
      <td>2023-08-12</td>
      <td>23</td>
      <td>14</td>
      <td>NONE</td>
      <td>1</td>
      <td>2129.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1670</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>670</td>
      <td>Please help me solve this error with using SHAP and KernelExplainer for a 1D CNN</td>
      <td>2021-01-01</td>
      <td>2021-01-01</td>
      <td>967</td>
      <td>967</td>
      <td>NONE</td>
      <td>0</td>
      <td>2130.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2335</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>335</td>
      <td>Explainer produces output_names with incorrect shape seemingly randomly</td>
      <td>2022-04-08</td>
      <td>2022-04-08</td>
      <td>505</td>
      <td>505</td>
      <td>NONE</td>
      <td>0</td>
      <td>2132.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>509</td>
      <td><a href="https://github.com/shap/shap/issues/51">51</a>9</td>
      <td>Question on XGBTreeModelLoader</td>
      <td>2019-03-25</td>
      <td>2023-08-26</td>
      <td>1615</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>2145.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>143</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>43</td>
      <td>Feature impact - for better or for worse</td>
      <td>2018-07-04</td>
      <td>2019-02-13</td>
      <td>1879</td>
      <td>1655</td>
      <td>NONE</td>
      <td>1</td>
      <td>2147.0</td>
      <td>No</td>
      <td>Issue with the feature impact on 'title' and 'body' series.</td>
      <td>"Feature Impact"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>695</td>
      <td><a href="https://github.com/shap/shap/issues/70">70</a>5</td>
      <td>Should global shap values depend on the variance of the feature?</td>
      <td>2019-07-10</td>
      <td>2020-02-08</td>
      <td>1508</td>
      <td>1295</td>
      <td>CONTRIBUTOR</td>
      <td>6</td>
      <td>2176.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1488</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>488</td>
      <td>Contribution of each word in the deep learning model output based on its position in the sentence using shap library</td>
      <td>2020-10-05</td>
      <td>2020-10-05</td>
      <td>1055</td>
      <td>1055</td>
      <td>NONE</td>
      <td>0</td>
      <td>2211.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1842</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>842</td>
      <td>ResourceExhaustedError when using KernelSHAP for small CNN</td>
      <td>2021-03-29</td>
      <td>2021-03-29</td>
      <td>880</td>
      <td>880</td>
      <td>NONE</td>
      <td>0</td>
      <td>2213.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1806</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>806</td>
      <td>Masking Layer results in additivity check failing</td>
      <td>2021-03-05</td>
      <td>2021-03-05</td>
      <td>904</td>
      <td>904</td>
      <td>NONE</td>
      <td>2</td>
      <td>2216.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1834</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>834</td>
      <td>SHAP values on images: low predictions have high positive SHAP values</td>
      <td>2021-03-23</td>
      <td>2021-03-23</td>
      <td>886</td>
      <td>886</td>
      <td>NONE</td>
      <td>0</td>
      <td>2216.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1531</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>531</td>
      <td>Integration with TF 2.0</td>
      <td>2020-10-28</td>
      <td>2023-02-02</td>
      <td>1032</td>
      <td>205</td>
      <td>NONE</td>
      <td>3</td>
      <td>2234.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>340</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>40</td>
      <td>using shap_values matrix in ordet to get value impact on target variable</td>
      <td>2018-11-28</td>
      <td>2018-11-30</td>
      <td>1732</td>
      <td>1730</td>
      <td>NONE</td>
      <td>1</td>
      <td>2256.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2167</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>167</td>
      <td>Cannot amend feature names in shap interaction summary plot</td>
      <td>2021-12-03</td>
      <td>2021-12-03</td>
      <td>631</td>
      <td>631</td>
      <td>NONE</td>
      <td>0</td>
      <td>2257.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1757</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>757</td>
      <td>IndexError: index 5 is out of bounds for axis 1 with size 1</td>
      <td>2021-02-04</td>
      <td>2023-06-21</td>
      <td>933</td>
      <td>66</td>
      <td>NONE</td>
      <td>14</td>
      <td>2265.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1795</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>795</td>
      <td>SHAP to explain group fairness disparity</td>
      <td>2021-03-03</td>
      <td>2021-03-23</td>
      <td>906</td>
      <td>886</td>
      <td>NONE</td>
      <td>2</td>
      <td>2275.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1870</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>870</td>
      <td>Error when using DeepExplainer on Keras model with TF feature_column layers</td>
      <td>2021-04-19</td>
      <td>2022-06-21</td>
      <td>859</td>
      <td>430</td>
      <td>NONE</td>
      <td>8</td>
      <td>2280.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2513</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>513</td>
      <td>multioutput_decision_plot gives error ValueError: The base_values and shap_values args expect lists.</td>
      <td>2022-09-18</td>
      <td>2022-09-18</td>
      <td>342</td>
      <td>342</td>
      <td>NONE</td>
      <td>0</td>
      <td>2284.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>956</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>56</td>
      <td>ImportError: cannot import name 'lobpcg'</td>
      <td>2019-12-16</td>
      <td>2020-01-03</td>
      <td>1349</td>
      <td>1331</td>
      <td>NONE</td>
      <td>2</td>
      <td>2285.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1838</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>838</td>
      <td>stacked bar plotting error for multi-class model</td>
      <td>2021-03-25</td>
      <td>2021-06-08</td>
      <td>883</td>
      <td>809</td>
      <td>NONE</td>
      <td>2</td>
      <td>2311.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1972</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>972</td>
      <td>Jupyter notebook kernel keep restarting when loading huge dataset from BigQuery when shap was introduced</td>
      <td>2021-06-25</td>
      <td>2021-09-08</td>
      <td>792</td>
      <td>716</td>
      <td>NONE</td>
      <td>2</td>
      <td>2314.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1887</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>887</td>
      <td>BUILD_INSIGHTS=1 python setup.py develop FAILURE</td>
      <td>2021-04-29</td>
      <td>2021-04-29</td>
      <td>849</td>
      <td>849</td>
      <td>NONE</td>
      <td>0</td>
      <td>2324.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2537</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>537</td>
      <td>Summary plot not matching with shap values</td>
      <td>2022-10-03</td>
      <td>2022-10-03</td>
      <td>326</td>
      <td>326</td>
      <td>NONE</td>
      <td>0</td>
      <td>2324.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>747</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>47</td>
      <td>TypeError: shap_values() got multiple values for argument 'ranked_outputs'</td>
      <td>2019-08-14</td>
      <td>2019-08-14</td>
      <td>1472</td>
      <td>1472</td>
      <td>NONE</td>
      <td>0</td>
      <td>2325.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1346</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>346</td>
      <td>Can't run genomics example</td>
      <td>2020-08-05</td>
      <td>2022-06-15</td>
      <td>1116</td>
      <td>437</td>
      <td>NONE</td>
      <td>5</td>
      <td>2325.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1829</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>829</td>
      <td>(Suspected Bug) Issue with unexpected parameter in internal Explanation function call</td>
      <td>2021-03-22</td>
      <td>2021-03-30</td>
      <td>887</td>
      <td>879</td>
      <td>NONE</td>
      <td>0</td>
      <td>2327.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1907</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>907</td>
      <td>Additivity check failed in TreeExplainer!</td>
      <td>2021-05-08</td>
      <td>2023-05-21</td>
      <td>840</td>
      <td>96</td>
      <td>NONE</td>
      <td>2</td>
      <td>2339.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1756</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>756</td>
      <td>Kernel Crash with Catboost</td>
      <td>2021-02-03</td>
      <td>2021-07-02</td>
      <td>933</td>
      <td>785</td>
      <td>NONE</td>
      <td>11</td>
      <td>2339.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2328</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>328</td>
      <td>Shap on pyspark doesn't work with a loaded model</td>
      <td>2022-04-06</td>
      <td>2022-09-22</td>
      <td>507</td>
      <td>338</td>
      <td>NONE</td>
      <td>1</td>
      <td>2346.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>985</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>85</td>
      <td>Issue with GradientExplainer and TF2</td>
      <td>2020-01-06</td>
      <td>2020-01-15</td>
      <td>1327</td>
      <td>1319</td>
      <td>NONE</td>
      <td>1</td>
      <td>2347.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>849</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>49</td>
      <td>Tensorflow 2.0 with SHAP</td>
      <td>2019-10-13</td>
      <td>2023-03-01</td>
      <td>1413</td>
      <td>178</td>
      <td>NONE</td>
      <td>11</td>
      <td>2348.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1042</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>042</td>
      <td>KernelExplainer error message</td>
      <td>2020-02-13</td>
      <td>2021-03-04</td>
      <td>1290</td>
      <td>905</td>
      <td>NONE</td>
      <td>3</td>
      <td>2349.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2147</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>147</td>
      <td>Feature importance for pycaret lightgbm multi-class  model.</td>
      <td>2021-11-19</td>
      <td>2023-01-04</td>
      <td>644</td>
      <td>234</td>
      <td>NONE</td>
      <td>4</td>
      <td>2355.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2561</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>561</td>
      <td>Help with compatibility problems with the dataset</td>
      <td>2022-10-26</td>
      <td>2023-08-26</td>
      <td>304</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>2375.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1214</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>214</td>
      <td>TreeExplainer error: 'utf-8' codec can't decode byte 0xff for xgboost model</td>
      <td>2020-05-18</td>
      <td>2022-02-21</td>
      <td>1195</td>
      <td>551</td>
      <td>NONE</td>
      <td>41</td>
      <td>2381.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>752</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>52</td>
      <td>CatBoost TreeExplainer Fails</td>
      <td>2019-08-16</td>
      <td>2019-08-20</td>
      <td>1471</td>
      <td>1466</td>
      <td>NONE</td>
      <td>2</td>
      <td>2396.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1084</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>084</td>
      <td>Error using DeepExplainer and KernelExplainer for NN model of TF 2.0</td>
      <td>2020-03-05</td>
      <td>2022-11-14</td>
      <td>1269</td>
      <td>285</td>
      <td>NONE</td>
      <td>15</td>
      <td>2403.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1202</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>202</td>
      <td>DeepExplainer returns extremely high shap values for conv1d model on spectral input data</td>
      <td>2020-05-08</td>
      <td>2022-01-14</td>
      <td>1205</td>
      <td>589</td>
      <td>NONE</td>
      <td>1</td>
      <td>2407.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2148</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>148</td>
      <td>Clustering not working with beeswarm plot</td>
      <td>2021-11-20</td>
      <td>2023-07-19</td>
      <td>643</td>
      <td>38</td>
      <td>NONE</td>
      <td>1</td>
      <td>2410.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2323</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>323</td>
      <td>TypeError: 'numpy.float64' object is not iterable</td>
      <td>2022-04-03</td>
      <td>2022-04-03</td>
      <td>510</td>
      <td>510</td>
      <td>NONE</td>
      <td>0</td>
      <td>2423.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2004</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>004</td>
      <td>Exception: An unknown model type was passed: &lt;class 'lightgbm.basic.Booster'&gt;</td>
      <td>2021-07-20</td>
      <td>2021-07-20</td>
      <td>767</td>
      <td>767</td>
      <td>NONE</td>
      <td>0</td>
      <td>2427.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1611</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>611</td>
      <td>LightGBM categoricals and shap_interactions</td>
      <td>2020-12-11</td>
      <td>2020-12-21</td>
      <td>988</td>
      <td>978</td>
      <td>NONE</td>
      <td>3</td>
      <td>2429.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1737</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>737</td>
      <td>'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'T'</td>
      <td>2021-01-26</td>
      <td>2021-01-26</td>
      <td>942</td>
      <td>942</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>2429.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>900</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>00</td>
      <td>Error using shap.DeepExplainer</td>
      <td>2019-11-18</td>
      <td>2020-04-27</td>
      <td>1377</td>
      <td>1216</td>
      <td>NONE</td>
      <td>5</td>
      <td>2431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1304</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>304</td>
      <td>Cant produce dependece plots for CatBoost model with categorical data</td>
      <td>2020-07-09</td>
      <td>2020-07-09</td>
      <td>1143</td>
      <td>1143</td>
      <td>NONE</td>
      <td>1</td>
      <td>2431.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1983</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>983</td>
      <td>Shap Explainer Segmentation Fault</td>
      <td>2021-07-05</td>
      <td>2023-07-09</td>
      <td>782</td>
      <td>48</td>
      <td>NONE</td>
      <td>15</td>
      <td>2441.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>804</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>04</td>
      <td>Brute Force linear explainer implementation</td>
      <td>2019-09-11</td>
      <td>2021-02-05</td>
      <td>1445</td>
      <td>931</td>
      <td>NONE</td>
      <td>1</td>
      <td>2445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2935</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>935</td>
      <td>BUG: shap.plots.heatmap() can't handle Explanation without feature_names</td>
      <td>2023-08-18</td>
      <td>2023-08-21</td>
      <td>8</td>
      <td>5</td>
      <td>NONE</td>
      <td>1</td>
      <td>2445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1978</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>978</td>
      <td>shap multi class xgboost classifier issue</td>
      <td>2021-07-02</td>
      <td>2021-07-19</td>
      <td>785</td>
      <td>767</td>
      <td>NONE</td>
      <td>1</td>
      <td>2445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1251</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>251</td>
      <td>Difference between shap_values[0] and shap_values[1]?</td>
      <td>2020-06-05</td>
      <td>2023-07-03</td>
      <td>1177</td>
      <td>54</td>
      <td>NONE</td>
      <td>10</td>
      <td>2448.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1361</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>361</td>
      <td>KernelExplainer: sklearn predictor trained with DataFrame with column names fails</td>
      <td>2020-08-13</td>
      <td>2021-08-14</td>
      <td>1108</td>
      <td>742</td>
      <td>NONE</td>
      <td>1</td>
      <td>2451.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>959</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>59</td>
      <td>Does SHAP give very high importance to outliers?</td>
      <td>2019-12-17</td>
      <td>2020-03-23</td>
      <td>1348</td>
      <td>1251</td>
      <td>NONE</td>
      <td>6</td>
      <td>2469.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>954</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>54</td>
      <td>Question: Background and explaining set sizes for TreeExplainer'ing large data sets</td>
      <td>2019-12-14</td>
      <td>2020-12-14</td>
      <td>1350</td>
      <td>985</td>
      <td>NONE</td>
      <td>2</td>
      <td>2469.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2100</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>100</td>
      <td>DeepExplainer:  TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;</td>
      <td>2021-10-08</td>
      <td>2022-04-17</td>
      <td>687</td>
      <td>496</td>
      <td>NONE</td>
      <td>1</td>
      <td>2478.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1689</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>689</td>
      <td>Shapley value (or SHAP) and the correlation between input features</td>
      <td>2021-01-12</td>
      <td>2021-01-12</td>
      <td>956</td>
      <td>956</td>
      <td>NONE</td>
      <td>0</td>
      <td>2487.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1013</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>013</td>
      <td>KernelExplainer not working with CatBoostRegressor and Pool</td>
      <td>2020-01-23</td>
      <td>2020-03-09</td>
      <td>1311</td>
      <td>1265</td>
      <td>NONE</td>
      <td>14</td>
      <td>2518.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1071</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>071</td>
      <td>\"tf_utils.py\" missing in the installation of shap 0.34</td>
      <td>2020-02-27</td>
      <td>2020-02-27</td>
      <td>1276</td>
      <td>1276</td>
      <td>NONE</td>
      <td>1</td>
      <td>2529.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2349</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>349</td>
      <td>Remove variables from explanation</td>
      <td>2022-04-18</td>
      <td>2022-04-18</td>
      <td>494</td>
      <td>494</td>
      <td>NONE</td>
      <td>0</td>
      <td>2529.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>799</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>99</td>
      <td>Issues using DeepExplainer with Inception v3</td>
      <td>2019-09-08</td>
      <td>2019-09-15</td>
      <td>1447</td>
      <td>1441</td>
      <td>NONE</td>
      <td>1</td>
      <td>2533.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2576</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>576</td>
      <td>Problem with DeepExplainer. Getting Error when passing background images.</td>
      <td>2022-11-11</td>
      <td>2022-11-11</td>
      <td>288</td>
      <td>288</td>
      <td>NONE</td>
      <td>0</td>
      <td>2534.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1278</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>278</td>
      <td>When running categorical column with out  one hot encoding</td>
      <td>2020-06-20</td>
      <td>2020-06-20</td>
      <td>1162</td>
      <td>1162</td>
      <td>NONE</td>
      <td>0</td>
      <td>2549.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1639</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>639</td>
      <td>Let's de-risk comparisons by not using: a) \"is\" for values and b) [in]equality signs for numbe</td>
      <td>2020-12-19</td>
      <td>2020-12-19</td>
      <td>980</td>
      <td>980</td>
      <td>NONE</td>
      <td>0</td>
      <td>2550.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1624</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>624</td>
      <td>Reshape error in XGBoost explainer.shap_values()</td>
      <td>2020-12-15</td>
      <td>2022-02-17</td>
      <td>984</td>
      <td>554</td>
      <td>NONE</td>
      <td>4</td>
      <td>2560.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1892</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>892</td>
      <td>AssertionError when only explaining one image</td>
      <td>2021-04-30</td>
      <td>2021-07-14</td>
      <td>848</td>
      <td>773</td>
      <td>NONE</td>
      <td>1</td>
      <td>2561.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1200</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>200</td>
      <td>Can tf.placeholder  be used as 'model' for DeepExplainer module??</td>
      <td>2020-05-08</td>
      <td>2022-12-06</td>
      <td>1205</td>
      <td>263</td>
      <td>NONE</td>
      <td>7</td>
      <td>2565.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1001</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>001</td>
      <td>Comments needed: Using Boosting Algorithms with SHAP to make Sociological Explanations.</td>
      <td>2020-01-19</td>
      <td>2020-01-21</td>
      <td>1315</td>
      <td>1312</td>
      <td>NONE</td>
      <td>2</td>
      <td>2613.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>883</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>83</td>
      <td>Error with Pyspark GBTClassifier</td>
      <td>2019-11-07</td>
      <td>2022-03-25</td>
      <td>1388</td>
      <td>519</td>
      <td>NONE</td>
      <td>35</td>
      <td>2613.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2690</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>690</td>
      <td>shap.force_plot() &gt; contribution_threshold not properly displaying negative contributing features</td>
      <td>2023-03-30</td>
      <td>2023-07-02</td>
      <td>149</td>
      <td>55</td>
      <td>NONE</td>
      <td>1</td>
      <td>2618.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>884</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>84</td>
      <td>Support for tf.keras?</td>
      <td>2019-11-07</td>
      <td>2021-07-21</td>
      <td>1387</td>
      <td>766</td>
      <td>NONE</td>
      <td>5</td>
      <td>2623.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2341</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>341</td>
      <td>Empty Dependence plot</td>
      <td>2022-04-09</td>
      <td>2022-04-09</td>
      <td>504</td>
      <td>504</td>
      <td>NONE</td>
      <td>0</td>
      <td>2624.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>580</td>
      <td><a href="https://github.com/shap/shap/issues/59">59</a>0</td>
      <td>Error using K.softmax in DeepExplainer</td>
      <td>2019-05-09</td>
      <td>2023-08-26</td>
      <td>1570</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>2631.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>484</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>84</td>
      <td>dependence_plot for data with multiple labels error</td>
      <td>2019-03-10</td>
      <td>2020-11-04</td>
      <td>1630</td>
      <td>1024</td>
      <td>NONE</td>
      <td>3</td>
      <td>2671.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2250</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>250</td>
      <td>Add support for spacy models</td>
      <td>2022-02-18</td>
      <td>2022-06-30</td>
      <td>554</td>
      <td>422</td>
      <td>CONTRIBUTOR</td>
      <td>0</td>
      <td>2677.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1423</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>423</td>
      <td>Use SHAP with custom class neural network</td>
      <td>2020-09-11</td>
      <td>2020-09-15</td>
      <td>1079</td>
      <td>1074</td>
      <td>NONE</td>
      <td>1</td>
      <td>2693.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2502</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>502</td>
      <td>Why is the output format of shap_value of xgboost and RF different?</td>
      <td>2022-09-09</td>
      <td>2022-09-13</td>
      <td>351</td>
      <td>347</td>
      <td>NONE</td>
      <td>1</td>
      <td>2723.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>287</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>87</td>
      <td>Stability of Shapley Values and Multicolinearity</td>
      <td>2018-10-17</td>
      <td>2023-06-19</td>
      <td>1774</td>
      <td>68</td>
      <td>NONE</td>
      <td>11</td>
      <td>2725.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1000</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>000</td>
      <td>Errors when using Deep and GradientExplainers to explain multiple inputs with different types</td>
      <td>2020-01-18</td>
      <td>2020-02-20</td>
      <td>1316</td>
      <td>1283</td>
      <td>NONE</td>
      <td>2</td>
      <td>2725.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1297</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>297</td>
      <td>shap.common.SHAPError: Additivity check failed in TreeExplainer! is thrown sometimes</td>
      <td>2020-07-04</td>
      <td>2021-01-06</td>
      <td>1148</td>
      <td>962</td>
      <td>NONE</td>
      <td>2</td>
      <td>2728.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1057</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>057</td>
      <td>Error when using KernelExplainer with H20; TypeError: ufunc 'isfinite' not supported for the input types</td>
      <td>2020-02-21</td>
      <td>2023-06-07</td>
      <td>1282</td>
      <td>80</td>
      <td>NONE</td>
      <td>10</td>
      <td>2748.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1435</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>435</td>
      <td>shap with autogluon (ensemble) model</td>
      <td>2020-09-16</td>
      <td>2022-10-18</td>
      <td>1074</td>
      <td>312</td>
      <td>NONE</td>
      <td>3</td>
      <td>2760.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1276</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>276</td>
      <td>AdditiveExplainer, KernelExplainer, and LinearExplainer don't support pyGAM</td>
      <td>2020-06-18</td>
      <td>2021-01-23</td>
      <td>1164</td>
      <td>945</td>
      <td>NONE</td>
      <td>2</td>
      <td>2762.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>263</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>63</td>
      <td>plot_cmap not working in all cases</td>
      <td>2018-09-18</td>
      <td>2020-11-04</td>
      <td>1803</td>
      <td>1025</td>
      <td>CONTRIBUTOR</td>
      <td>3</td>
      <td>2769.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2357</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>357</td>
      <td>One possible solution for DeepExplainer RuntimeError when using pytorch</td>
      <td>2022-04-21</td>
      <td>2023-08-21</td>
      <td>492</td>
      <td>5</td>
      <td>NONE</td>
      <td>5</td>
      <td>2773.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2249</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>249</td>
      <td>_PytorchGradient seems to have some shape/loop errors</td>
      <td>2022-02-16</td>
      <td>2022-02-16</td>
      <td>555</td>
      <td>555</td>
      <td>NONE</td>
      <td>0</td>
      <td>2783.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1579</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>579</td>
      <td>AttributeError: 'Text' object has no attribute '_tokenized_s'</td>
      <td>2020-11-26</td>
      <td>2020-11-26</td>
      <td>1003</td>
      <td>1002</td>
      <td>NONE</td>
      <td>0</td>
      <td>2783.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2950</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>950</td>
      <td>BUG: Inconsistent Matplot layouts</td>
      <td>2023-08-22</td>
      <td>2023-08-26</td>
      <td>3</td>
      <td>0</td>
      <td>COLLABORATOR</td>
      <td>2</td>
      <td>2797.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>293</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>93</td>
      <td>Cannot store matplotlib.pyplot figure objects with dependence_plot instead of plotting them</td>
      <td>2018-10-23</td>
      <td>2020-07-26</td>
      <td>1768</td>
      <td>1126</td>
      <td>NONE</td>
      <td>8</td>
      <td>2810.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>450</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>50</td>
      <td>Explicit handling of categorical variables in KernelExplainer</td>
      <td>2019-02-20</td>
      <td>2022-01-14</td>
      <td>1648</td>
      <td>589</td>
      <td>CONTRIBUTOR</td>
      <td>4</td>
      <td>2812.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1881</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>881</td>
      <td>NameError: name 'Model' is not defined</td>
      <td>2021-04-24</td>
      <td>2021-04-26</td>
      <td>854</td>
      <td>852</td>
      <td>NONE</td>
      <td>1</td>
      <td>2818.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2157</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>157</td>
      <td>how to use plots.force and plots.text ?</td>
      <td>2021-11-24</td>
      <td>2023-06-03</td>
      <td>640</td>
      <td>84</td>
      <td>NONE</td>
      <td>0</td>
      <td>2825.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2471</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>471</td>
      <td>Why would shap beeswarm plot look different depending on model output?</td>
      <td>2022-08-02</td>
      <td>2022-08-02</td>
      <td>388</td>
      <td>388</td>
      <td>NONE</td>
      <td>0</td>
      <td>2870.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2053</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>053</td>
      <td>Inconsistent procedure to generate beeswarm plot</td>
      <td>2021-08-28</td>
      <td>2021-08-28</td>
      <td>728</td>
      <td>728</td>
      <td>NONE</td>
      <td>0</td>
      <td>2870.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2733</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>733</td>
      <td>Shap for Large set of data points trained on DNN not working</td>
      <td>2023-05-30</td>
      <td>2023-06-05</td>
      <td>88</td>
      <td>81</td>
      <td>NONE</td>
      <td>4</td>
      <td>2877.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2439</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>439</td>
      <td>Universal Sentence Encoder Input Error: 'str' object has no attribute 'shape'</td>
      <td>2022-06-27</td>
      <td>2023-03-28</td>
      <td>425</td>
      <td>150</td>
      <td>NONE</td>
      <td>1</td>
      <td>2897.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2239</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>239</td>
      <td>retracing warning with DeepExplainer</td>
      <td>2022-02-09</td>
      <td>2022-02-26</td>
      <td>563</td>
      <td>545</td>
      <td>NONE</td>
      <td>2</td>
      <td>2897.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1327</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>327</td>
      <td>How to use sample weights in SHAP</td>
      <td>2020-07-23</td>
      <td>2022-03-10</td>
      <td>1129</td>
      <td>534</td>
      <td>NONE</td>
      <td>1</td>
      <td>2905.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1684</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>684</td>
      <td>GPUTreeShap shap-loss values different from TreeShap</td>
      <td>2021-01-11</td>
      <td>2021-01-11</td>
      <td>957</td>
      <td>957</td>
      <td>NONE</td>
      <td>0</td>
      <td>2909.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>110</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>10</td>
      <td>ValueError: left cannot be &gt;= right</td>
      <td>2018-06-08</td>
      <td>2018-09-17</td>
      <td>1905</td>
      <td>1804</td>
      <td>NONE</td>
      <td>20</td>
      <td>2910.0</td>
      <td>No</td>
      <td>"ValueError issue with unnamed Series shape in Python."\n</td>
      <td>"ValueError Issue"</td>
      <td>stale</td>
    </tr>
    <tr>
      <td>2734</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>734</td>
      <td>Kernel Explainer Very Long Run Time</td>
      <td>2023-05-31</td>
      <td>2023-06-06</td>
      <td>87</td>
      <td>81</td>
      <td>NONE</td>
      <td>0</td>
      <td>2937.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>749</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>49</td>
      <td>Summary Plot for CatBoost MultiClass Shap Values</td>
      <td>2019-08-15</td>
      <td>2020-10-06</td>
      <td>1471</td>
      <td>1054</td>
      <td>NONE</td>
      <td>8</td>
      <td>2947.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2543</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>543</td>
      <td>SHAP library does not support TransformedTargetRegressor, how to calculate SAHP in native units with target transform</td>
      <td>2022-10-09</td>
      <td>2023-01-15</td>
      <td>321</td>
      <td>223</td>
      <td>NONE</td>
      <td>1</td>
      <td>2947.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2084</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>084</td>
      <td>Why is Shap report not giving me a split by class for Binary Classifier?</td>
      <td>2021-09-22</td>
      <td>2021-09-22</td>
      <td>703</td>
      <td>703</td>
      <td>NONE</td>
      <td>0</td>
      <td>2964.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>897</td>
      <td><a href="https://github.com/shap/shap/issues/9">9</a>97</td>
      <td>ValueError: signal only works in main thread</td>
      <td>2019-11-14</td>
      <td>2019-11-14</td>
      <td>1381</td>
      <td>1381</td>
      <td>NONE</td>
      <td>0</td>
      <td>2986.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2314</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>314</td>
      <td>Error while replicating Keras-LSTM example</td>
      <td>2022-03-30</td>
      <td>2022-03-30</td>
      <td>514</td>
      <td>514</td>
      <td>NONE</td>
      <td>0</td>
      <td>2987.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1921</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>921</td>
      <td>Errors when running the notebook for \"Be Careful When Interpreting Predictive Models in Search of Causal Insights</td>
      <td>2021-05-18</td>
      <td>2021-09-23</td>
      <td>829</td>
      <td>702</td>
      <td>NONE</td>
      <td>3</td>
      <td>2993.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>592</td>
      <td><a href="https://github.com/shap/shap/issues/60">60</a>2</td>
      <td>DeepExplainer fails for PyTorch Pretrained Alexnet Model</td>
      <td>2019-05-16</td>
      <td>2019-05-16</td>
      <td>1563</td>
      <td>1563</td>
      <td>NONE</td>
      <td>1</td>
      <td>3011.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1294</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>294</td>
      <td>DeepExplainer crashes on saved models</td>
      <td>2020-06-30</td>
      <td>2021-03-18</td>
      <td>1152</td>
      <td>891</td>
      <td>NONE</td>
      <td>7</td>
      <td>3031.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2333</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>333</td>
      <td>Teacherforcing model is not working in local (source code download and run in local)</td>
      <td>2022-04-08</td>
      <td>2022-04-08</td>
      <td>505</td>
      <td>505</td>
      <td>NONE</td>
      <td>0</td>
      <td>3060.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>591</td>
      <td><a href="https://github.com/shap/shap/issues/60">60</a>1</td>
      <td>Interpreting interactions between different classes in keras model</td>
      <td>2019-05-15</td>
      <td>2023-08-26</td>
      <td>1563</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>3090.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2081</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>081</td>
      <td>AssertionError: Unknown type passed as data object: &lt;class 'list'&gt;</td>
      <td>2021-09-21</td>
      <td>2021-09-21</td>
      <td>704</td>
      <td>704</td>
      <td>NONE</td>
      <td>0</td>
      <td>3098.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1460</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>460</td>
      <td>KernelShap Issue when adding a new variable</td>
      <td>2020-09-23</td>
      <td>2020-09-24</td>
      <td>1067</td>
      <td>1066</td>
      <td>NONE</td>
      <td>1</td>
      <td>3151.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1225</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>225</td>
      <td>DeepExplainer yields 'NoneType' object cannot be interpreted as an integer</td>
      <td>2020-05-25</td>
      <td>2020-08-27</td>
      <td>1188</td>
      <td>1094</td>
      <td>NONE</td>
      <td>2</td>
      <td>3151.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>722</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>22</td>
      <td>shap_interaction_values rows not adding up to shap values for RF classifier</td>
      <td>2019-07-29</td>
      <td>2019-07-30</td>
      <td>1489</td>
      <td>1488</td>
      <td>NONE</td>
      <td>1</td>
      <td>3198.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>661</td>
      <td><a href="https://github.com/shap/shap/issues/67">67</a>1</td>
      <td>Is SHAP appropriate for mostly categorical data?</td>
      <td>2019-06-25</td>
      <td>2019-11-21</td>
      <td>1523</td>
      <td>1374</td>
      <td>NONE</td>
      <td>14</td>
      <td>3220.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2564</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>564</td>
      <td>Use shap.GPUTreeExplaine on Windows</td>
      <td>2022-10-29</td>
      <td>2022-10-29</td>
      <td>301</td>
      <td>301</td>
      <td>NONE</td>
      <td>0</td>
      <td>3221.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1174</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>174</td>
      <td>custom_record_gradient() error</td>
      <td>2020-04-24</td>
      <td>2020-04-29</td>
      <td>1219</td>
      <td>1214</td>
      <td>NONE</td>
      <td>2</td>
      <td>3231.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1430</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>430</td>
      <td>Solved, I think, an issue with _clustering.py, was not able to make a pull request</td>
      <td>2020-09-15</td>
      <td>2020-09-15</td>
      <td>1075</td>
      <td>1075</td>
      <td>NONE</td>
      <td>0</td>
      <td>3266.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1576</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>576</td>
      <td>Shap.plots.bar and shap.plots.waterfall - Are these working currently?</td>
      <td>2020-11-24</td>
      <td>2022-10-09</td>
      <td>1005</td>
      <td>320</td>
      <td>NONE</td>
      <td>20</td>
      <td>3283.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>623</td>
      <td><a href="https://github.com/shap/shap/issues/63">63</a>3</td>
      <td>ZestFinance writeup on SHAP and why it shouldn't be used on its own</td>
      <td>2019-05-31</td>
      <td>2023-08-01</td>
      <td>1548</td>
      <td>25</td>
      <td>NONE</td>
      <td>13</td>
      <td>3291.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2656</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>656</td>
      <td>Using Shapely package with feedforward keras neural network</td>
      <td>2023-02-06</td>
      <td>2023-06-17</td>
      <td>201</td>
      <td>70</td>
      <td>NONE</td>
      <td>2</td>
      <td>3307.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>186</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>86</td>
      <td>Pandas Categorical columns are not compatible</td>
      <td>2018-07-29</td>
      <td>2018-08-02</td>
      <td>1854</td>
      <td>1850</td>
      <td>NONE</td>
      <td>6</td>
      <td>3334.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>282</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>82</td>
      <td>Some questions about the calculation using tree SHAP</td>
      <td>2018-10-12</td>
      <td>2018-10-19</td>
      <td>1779</td>
      <td>1772</td>
      <td>NONE</td>
      <td>1</td>
      <td>3407.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2952</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>952</td>
      <td>BUG: random_state in shap.utils.sample not preserved between v0.41.0 -&gt; v0.42.1</td>
      <td>2023-08-23</td>
      <td>2023-08-26</td>
      <td>2</td>
      <td>0</td>
      <td>NONE</td>
      <td>14</td>
      <td>3411.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2890</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>890</td>
      <td>ENH: Categorical feature not working with `shap.plots.scatter`</td>
      <td>2023-07-25</td>
      <td>2023-08-23</td>
      <td>32</td>
      <td>3</td>
      <td>CONTRIBUTOR</td>
      <td>5</td>
      <td>3445.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2263</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>263</td>
      <td>Performance difference KernelExplainer model vs. function</td>
      <td>2022-02-23</td>
      <td>2022-02-26</td>
      <td>549</td>
      <td>545</td>
      <td>NONE</td>
      <td>1</td>
      <td>3501.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2482</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>482</td>
      <td>Segfault in _cext.compute_expectations for CatBoost model with categorical features</td>
      <td>2022-08-19</td>
      <td>2022-08-19</td>
      <td>372</td>
      <td>371</td>
      <td>NONE</td>
      <td>0</td>
      <td>3510.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1364</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>364</td>
      <td>Proposal for adding functionality 'calculating + accessing individual feature contributions in the case that link=\"logit\</td>
      <td>2020-08-14</td>
      <td>2020-08-14</td>
      <td>1107</td>
      <td>1107</td>
      <td>NONE</td>
      <td>0</td>
      <td>3514.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>619</td>
      <td><a href="https://github.com/shap/shap/issues/62">62</a>9</td>
      <td>TreeExplainer on LightGBM model throws JSONDecode Error</td>
      <td>2019-05-30</td>
      <td>2019-10-01</td>
      <td>1549</td>
      <td>1425</td>
      <td>NONE</td>
      <td>9</td>
      <td>3522.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1675</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>675</td>
      <td>Explainer for CatBoostClassifier with iris: ValueError array is too big</td>
      <td>2021-01-05</td>
      <td>2021-01-05</td>
      <td>963</td>
      <td>963</td>
      <td>NONE</td>
      <td>0</td>
      <td>3529.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1150</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>150</td>
      <td>Shap values do not sum to model output - expected value for interventional TreeExplainer (v 0.35) [xgboost]</td>
      <td>2020-04-13</td>
      <td>2021-07-13</td>
      <td>1230</td>
      <td>774</td>
      <td>NONE</td>
      <td>1</td>
      <td>3536.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1573</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>573</td>
      <td>TypeError: object of type 'NoneType' has no len() while using shap on keras</td>
      <td>2020-11-23</td>
      <td>2022-07-29</td>
      <td>1006</td>
      <td>393</td>
      <td>NONE</td>
      <td>2</td>
      <td>3537.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>971</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>71</td>
      <td>shap dependence_plot does not work in version 0.33 for lightgbm</td>
      <td>2019-12-25</td>
      <td>2019-12-27</td>
      <td>1339</td>
      <td>1338</td>
      <td>NONE</td>
      <td>1</td>
      <td>3541.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1954</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>954</td>
      <td>Error with 3D input on shap.DeepExplainer (pytorch model)</td>
      <td>2021-06-10</td>
      <td>2022-04-21</td>
      <td>806</td>
      <td>492</td>
      <td>NONE</td>
      <td>3</td>
      <td>3550.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1043</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>043</td>
      <td>Error when using KernelExplainer to explain a Tensorflow DNNLinearCombinedClassifier</td>
      <td>2020-02-13</td>
      <td>2020-02-27</td>
      <td>1290</td>
      <td>1276</td>
      <td>NONE</td>
      <td>3</td>
      <td>3565.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2031</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>031</td>
      <td>Usage for multimodal data (data with fundamentally different characteristics)</td>
      <td>2021-08-10</td>
      <td>2021-08-10</td>
      <td>746</td>
      <td>746</td>
      <td>NONE</td>
      <td>0</td>
      <td>3588.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1660</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>660</td>
      <td>shap 0.37.0 shap.Explainer bug</td>
      <td>2020-12-24</td>
      <td>2020-12-28</td>
      <td>975</td>
      <td>971</td>
      <td>NONE</td>
      <td>1</td>
      <td>3594.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2859</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>859</td>
      <td>BUG:  multi-dimensional features. ambiguous Boolean definition of array ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()</td>
      <td>2023-07-17</td>
      <td>2023-08-17</td>
      <td>39</td>
      <td>9</td>
      <td>NONE</td>
      <td>1</td>
      <td>3599.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1164</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>164</td>
      <td>Unexpectedly found an instance of type `&lt;class 'numpy.ndarray'&gt;`. Expected a symbolic tensor instance.</td>
      <td>2020-04-17</td>
      <td>2020-06-01</td>
      <td>1225</td>
      <td>1180</td>
      <td>NONE</td>
      <td>2</td>
      <td>3619.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>270</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>70</td>
      <td>keep_dims instead of keepdims in the latest version TF version</td>
      <td>2018-09-26</td>
      <td>2018-09-29</td>
      <td>1794</td>
      <td>1791</td>
      <td>NONE</td>
      <td>1</td>
      <td>3639.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1494</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>494</td>
      <td>DeepExplainer+softmax no correlation between input and output (with reproducible code)</td>
      <td>2020-10-07</td>
      <td>2020-10-07</td>
      <td>1053</td>
      <td>1053</td>
      <td>NONE</td>
      <td>0</td>
      <td>3649.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>686</td>
      <td><a href="https://github.com/shap/shap/issues/687">687</a></td>
      <td>Issue with shap values in model with merged layers in keras?</td>
      <td>2019-07-09</td>
      <td>2019-07-09</td>
      <td>1509</td>
      <td>1509</td>
      <td>NONE</td>
      <td>0</td>
      <td>3651.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2927</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>927</td>
      <td>BUG: Inconsistency and error in returned explainer objects with TreeExplainer</td>
      <td>2023-08-11</td>
      <td>2023-08-26</td>
      <td>15</td>
      <td>0</td>
      <td>NONE</td>
      <td>4</td>
      <td>3652.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1831</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>831</td>
      <td>ImportError: numpy.core.multiarray failed to import</td>
      <td>2021-03-22</td>
      <td>2022-01-13</td>
      <td>886</td>
      <td>590</td>
      <td>NONE</td>
      <td>6</td>
      <td>3654.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1990</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>990</td>
      <td>pip install shap giving cuda/gcc error</td>
      <td>2021-07-12</td>
      <td>2021-08-10</td>
      <td>774</td>
      <td>746</td>
      <td>NONE</td>
      <td>1</td>
      <td>3667.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1540</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>540</td>
      <td>Issue with shap, slicer==0.0.3 and Databricks</td>
      <td>2020-11-05</td>
      <td>2022-08-09</td>
      <td>1023</td>
      <td>382</td>
      <td>NONE</td>
      <td>1</td>
      <td>3668.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1310</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>310</td>
      <td>Use SHAP to make sense on misclassified predictions</td>
      <td>2020-07-10</td>
      <td>2020-07-10</td>
      <td>1142</td>
      <td>1142</td>
      <td>NONE</td>
      <td>0</td>
      <td>3747.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2445</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>445</td>
      <td>Can't retrieve SHAP values from scikit-learn Pipeline?</td>
      <td>2022-07-07</td>
      <td>2023-07-24</td>
      <td>415</td>
      <td>33</td>
      <td>NONE</td>
      <td>3</td>
      <td>3760.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2248</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>248</td>
      <td>Interpretation of Bias value from TreeShap from weighted xgboost model R</td>
      <td>2022-02-15</td>
      <td>2022-03-09</td>
      <td>556</td>
      <td>534</td>
      <td>NONE</td>
      <td>1</td>
      <td>3788.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>671</td>
      <td><a href="https://github.com/shap/shap/issues/672">672</a></td>
      <td>CNN model not including Dense layer cannot run GradientExplainer</td>
      <td>2019-07-01</td>
      <td>2019-07-01</td>
      <td>1517</td>
      <td>1517</td>
      <td>NONE</td>
      <td>0</td>
      <td>3796.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2531</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>531</td>
      <td>SHAP waterfall plot errors with lightgbm.lgbmclassifier</td>
      <td>2022-09-29</td>
      <td>2023-03-13</td>
      <td>331</td>
      <td>166</td>
      <td>NONE</td>
      <td>7</td>
      <td>3813.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1038</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>038</td>
      <td>SHAP Values in a neural network with an Embedding layer</td>
      <td>2020-02-11</td>
      <td>2021-02-09</td>
      <td>1292</td>
      <td>927</td>
      <td>NONE</td>
      <td>4</td>
      <td>3815.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1899</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>899</td>
      <td>SHAP plots fail for sklearn's Isolation Forest</td>
      <td>2021-05-05</td>
      <td>2022-09-21</td>
      <td>843</td>
      <td>339</td>
      <td>NONE</td>
      <td>1</td>
      <td>3846.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2233</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>233</td>
      <td>Image Partition Explainer does not work with PyTorch</td>
      <td>2022-01-31</td>
      <td>2022-02-21</td>
      <td>572</td>
      <td>551</td>
      <td>NONE</td>
      <td>1</td>
      <td>3953.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1474</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>474</td>
      <td>Deep Explainer fails on Resnet50 pretrained model.</td>
      <td>2020-09-28</td>
      <td>2023-06-28</td>
      <td>1062</td>
      <td>59</td>
      <td>NONE</td>
      <td>19</td>
      <td>4041.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1112</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>112</td>
      <td>summary_plot crashes with plot_type=\"bar\" if color defined on binary classificati</td>
      <td>2020-03-19</td>
      <td>2020-03-19</td>
      <td>1254</td>
      <td>1254</td>
      <td>NONE</td>
      <td>0</td>
      <td>4067.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2515</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>515</td>
      <td>KeyError: 'label'</td>
      <td>2022-09-19</td>
      <td>2022-09-19</td>
      <td>341</td>
      <td>341</td>
      <td>NONE</td>
      <td>0</td>
      <td>4099.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1911</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>911</td>
      <td>Encountering `TypeError` with nulls in either background data or examples</td>
      <td>2021-05-10</td>
      <td>2021-05-10</td>
      <td>837</td>
      <td>837</td>
      <td>NONE</td>
      <td>0</td>
      <td>4107.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2308</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>308</td>
      <td>Setting algorithm to \"auto\" in shap.Explainer() class throws error due to missing mask</td>
      <td>2022-03-26</td>
      <td>2023-06-14</td>
      <td>518</td>
      <td>73</td>
      <td>CONTRIBUTOR</td>
      <td>1</td>
      <td>4128.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1109</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>109</td>
      <td>shap_values fails to run on keras model with BatchNormalization layer</td>
      <td>2020-03-19</td>
      <td>2023-02-10</td>
      <td>1255</td>
      <td>197</td>
      <td>NONE</td>
      <td>23</td>
      <td>4249.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1264</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>264</td>
      <td>Additivity for xgboost multiclass model with background data</td>
      <td>2020-06-12</td>
      <td>2020-06-12</td>
      <td>1170</td>
      <td>1170</td>
      <td>NONE</td>
      <td>0</td>
      <td>4287.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2198</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>198</td>
      <td>LightGBM shap_values output != XGBoost shap_values output for binary classification</td>
      <td>2021-12-24</td>
      <td>2022-01-25</td>
      <td>610</td>
      <td>577</td>
      <td>NONE</td>
      <td>2</td>
      <td>4298.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1619</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>619</td>
      <td>KernelShap class problem (binary)</td>
      <td>2020-12-14</td>
      <td>2020-12-14</td>
      <td>985</td>
      <td>985</td>
      <td>NONE</td>
      <td>0</td>
      <td>4390.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2556</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>556</td>
      <td>SHAP values on the partial dependence plot seems to be broken?</td>
      <td>2022-10-19</td>
      <td>2022-11-02</td>
      <td>311</td>
      <td>297</td>
      <td>NONE</td>
      <td>0</td>
      <td>4513.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2130</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>130</td>
      <td>Waterfall plot (from website example) breaks with sklearn.ensemble.RandomForestRegressor</td>
      <td>2021-11-05</td>
      <td>2023-06-17</td>
      <td>659</td>
      <td>70</td>
      <td>NONE</td>
      <td>2</td>
      <td>4581.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2213</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>213</td>
      <td>ModuleNotFoundError: No module named 'cv2'</td>
      <td>2022-01-10</td>
      <td>2023-04-24</td>
      <td>593</td>
      <td>124</td>
      <td>NONE</td>
      <td>1</td>
      <td>4591.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1659</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>659</td>
      <td>AttributeError: 'KerasTensor' object has no attribute 'graph'</td>
      <td>2020-12-23</td>
      <td>2022-07-01</td>
      <td>976</td>
      <td>421</td>
      <td>NONE</td>
      <td>24</td>
      <td>4601.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>323</td>
      <td><a href="https://github.com/shap/shap/issues/4">4</a>23</td>
      <td>DeepExplainer - TypeError: Fetch argument None has invalid type &lt;type 'NoneType'&gt;</td>
      <td>2018-11-13</td>
      <td>2022-05-12</td>
      <td>1747</td>
      <td>471</td>
      <td>NONE</td>
      <td>8</td>
      <td>4616.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>966</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>66</td>
      <td>Issue with highly-codependent variables with data generated by simple linear equation</td>
      <td>2019-12-21</td>
      <td>2019-12-27</td>
      <td>1344</td>
      <td>1337</td>
      <td>NONE</td>
      <td>1</td>
      <td>4642.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1938</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>938</td>
      <td>AttributeError: module 'tensorflow.python.eager.backprop' has no attribute '_record_gradient'</td>
      <td>2021-06-01</td>
      <td>2021-10-26</td>
      <td>816</td>
      <td>669</td>
      <td>NONE</td>
      <td>7</td>
      <td>4666.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2177</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>177</td>
      <td>ITE Explanations for a set of background vectors vs. average of explanations for individual background vectors</td>
      <td>2021-12-09</td>
      <td>2021-12-09</td>
      <td>625</td>
      <td>625</td>
      <td>NONE</td>
      <td>0</td>
      <td>4727.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>765</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>65</td>
      <td>AttributeError: 'list' object has no attribute 'shape' and TypeError: Object of type 'ndarray' is not JSON serializable</td>
      <td>2019-08-23</td>
      <td>2019-08-27</td>
      <td>1464</td>
      <td>1460</td>
      <td>NONE</td>
      <td>1</td>
      <td>4793.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2532</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>532</td>
      <td>Getting error when trying to import SHAP</td>
      <td>2022-09-29</td>
      <td>2022-09-29</td>
      <td>331</td>
      <td>331</td>
      <td>NONE</td>
      <td>0</td>
      <td>4801.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1732</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>732</td>
      <td>How to use TreeExplainer on XGBoost model trained with Sparse CSR matrix for model_output='probability'</td>
      <td>2021-01-24</td>
      <td>2022-11-24</td>
      <td>944</td>
      <td>275</td>
      <td>NONE</td>
      <td>2</td>
      <td>4808.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2829</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>829</td>
      <td>MAINT: address all deprecation warnings in test suite</td>
      <td>2023-07-05</td>
      <td>2023-08-22</td>
      <td>51</td>
      <td>4</td>
      <td>COLLABORATOR</td>
      <td>7</td>
      <td>4869.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2700</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>700</td>
      <td>Compare True Contribution with SHAP Contribution, using simulated data</td>
      <td>2023-04-12</td>
      <td>2023-08-26</td>
      <td>136</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>4891.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>746</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>46</td>
      <td>Intuitiveness of SHAP explanation based on example - some doubts and question about possible solution</td>
      <td>2019-08-14</td>
      <td>2019-08-15</td>
      <td>1473</td>
      <td>1472</td>
      <td>NONE</td>
      <td>1</td>
      <td>4928.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2737</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>737</td>
      <td>AssertionError: The SHAP explanations do not sum up to the model's output!</td>
      <td>2023-06-02</td>
      <td>2023-06-04</td>
      <td>85</td>
      <td>83</td>
      <td>NONE</td>
      <td>1</td>
      <td>4948.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1909</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>909</td>
      <td>self._traceback = tf_stack.extract_stack() when running GradientExplainer.shap_values</td>
      <td>2021-05-10</td>
      <td>2021-12-17</td>
      <td>838</td>
      <td>617</td>
      <td>NONE</td>
      <td>2</td>
      <td>5058.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1339</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>339</td>
      <td>Deep learning example with GradientExplainer (TensorFlow/Keras/PyTorch models) --&gt; FailedPreconditionError</td>
      <td>2020-08-03</td>
      <td>2022-05-10</td>
      <td>1118</td>
      <td>473</td>
      <td>NONE</td>
      <td>2</td>
      <td>5092.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1188</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>188</td>
      <td>Unable to create dependence plot if one of the features is of type category</td>
      <td>2020-04-29</td>
      <td>2020-06-17</td>
      <td>1214</td>
      <td>1165</td>
      <td>NONE</td>
      <td>2</td>
      <td>5118.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2015</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>015</td>
      <td>AttributeError: 'TFDeep' object has no attribute 'between_tensors'</td>
      <td>2021-07-28</td>
      <td>2022-12-21</td>
      <td>758</td>
      <td>248</td>
      <td>NONE</td>
      <td>6</td>
      <td>5133.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2584</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>584</td>
      <td>DeepExplainer does not work with wrapped model (add layer to a pre-trained model)</td>
      <td>2022-11-16</td>
      <td>2022-11-16</td>
      <td>283</td>
      <td>283</td>
      <td>NONE</td>
      <td>0</td>
      <td>5240.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>952</td>
      <td><a href="https://github.com/shap/shap/issues/10">10</a>52</td>
      <td>TreeExplainer with scikit-learn's RandomForestClassifier throws error with sparse matrix, and with dense matrix the additivity check failed.</td>
      <td>2019-12-14</td>
      <td>2022-12-17</td>
      <td>1351</td>
      <td>252</td>
      <td>NONE</td>
      <td>5</td>
      <td>5247.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>738</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>38</td>
      <td>SHAP throwing error for multi-input DeepExplainer</td>
      <td>2019-08-09</td>
      <td>2020-06-10</td>
      <td>1478</td>
      <td>1172</td>
      <td>NONE</td>
      <td>3</td>
      <td>5267.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2372</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>372</td>
      <td>Shap KernelExplainer doesn't work with AutoSklearn fitted to pandasDataFrame with categorical values</td>
      <td>2022-05-02</td>
      <td>2022-05-02</td>
      <td>481</td>
      <td>481</td>
      <td>NONE</td>
      <td>0</td>
      <td>5444.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>760</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>60</td>
      <td>CatBoost with nan values not supported</td>
      <td>2019-08-19</td>
      <td>2020-02-05</td>
      <td>1468</td>
      <td>1298</td>
      <td>NONE</td>
      <td>9</td>
      <td>5473.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2207</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>207</td>
      <td>SHAP Tree algorithm breaks Shapley symmetry property</td>
      <td>2022-01-05</td>
      <td>2023-02-17</td>
      <td>598</td>
      <td>190</td>
      <td>NONE</td>
      <td>5</td>
      <td>5706.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2208</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>208</td>
      <td>reshape error in HAN model with multi inputs and timedistributed</td>
      <td>2022-01-06</td>
      <td>2023-03-07</td>
      <td>597</td>
      <td>172</td>
      <td>NONE</td>
      <td>2</td>
      <td>5880.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1125</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>125</td>
      <td>DeepExplainer: shap_values containing \"nan\" valu</td>
      <td>2020-04-01</td>
      <td>2020-06-05</td>
      <td>1242</td>
      <td>1177</td>
      <td>NONE</td>
      <td>4</td>
      <td>6326.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>578</td>
      <td><a href="https://github.com/shap/shap/issues/58">58</a>8</td>
      <td>SHAP tensorflow model deeplab_v3</td>
      <td>2019-05-07</td>
      <td>2019-07-31</td>
      <td>1572</td>
      <td>1487</td>
      <td>NONE</td>
      <td>2</td>
      <td>6345.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1258</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>258</td>
      <td>keras is no longer supported, please use tf.keras instead.</td>
      <td>2020-06-09</td>
      <td>2023-04-13</td>
      <td>1173</td>
      <td>135</td>
      <td>NONE</td>
      <td>1</td>
      <td>6564.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2090</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>090</td>
      <td>Partial dependence plot</td>
      <td>2021-10-01</td>
      <td>2021-10-01</td>
      <td>694</td>
      <td>694</td>
      <td>NONE</td>
      <td>0</td>
      <td>6566.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2727</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>727</td>
      <td>IndexError: index out of range in self while using GPT2LMHeadModel.from_pretrained(\"gpt2\</td>
      <td>2023-05-22</td>
      <td>2023-05-22</td>
      <td>96</td>
      <td>96</td>
      <td>NONE</td>
      <td>0</td>
      <td>6669.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2805</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>805</td>
      <td>[Meta-issue] Notebooks are outdated / non-runnable</td>
      <td>2023-06-23</td>
      <td>2023-08-22</td>
      <td>64</td>
      <td>4</td>
      <td>COLLABORATOR</td>
      <td>4</td>
      <td>6684.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1118</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>118</td>
      <td>Unable to obtain shap values using embedding layer, tf 2.1.0 &amp; shap 0.35.0</td>
      <td>2020-03-24</td>
      <td>2022-10-10</td>
      <td>1250</td>
      <td>320</td>
      <td>NONE</td>
      <td>8</td>
      <td>7091.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1793</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>793</td>
      <td>Python3: shap tree explainer: Exception ignored in: 'array_dealloc'</td>
      <td>2021-03-01</td>
      <td>2021-03-01</td>
      <td>908</td>
      <td>908</td>
      <td>NONE</td>
      <td>0</td>
      <td>7154.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1203</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>203</td>
      <td>Loky crashes when calculating shap values with a large scikit-learn RF model</td>
      <td>2020-05-10</td>
      <td>2022-03-18</td>
      <td>1203</td>
      <td>525</td>
      <td>NONE</td>
      <td>2</td>
      <td>7277.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>499</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>99</td>
      <td>error on import shap: module 'skimage' has no attribute 'color'</td>
      <td>2019-03-20</td>
      <td>2019-07-21</td>
      <td>1620</td>
      <td>1497</td>
      <td>NONE</td>
      <td>2</td>
      <td>7336.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1496</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>496</td>
      <td>Failed to install - No such file or directory: 'llvm-config': 'llvm-config'</td>
      <td>2020-10-07</td>
      <td>2020-12-01</td>
      <td>1053</td>
      <td>998</td>
      <td>NONE</td>
      <td>2</td>
      <td>7929.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2620</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>620</td>
      <td>Import shap causes UnknownError raised (Fail to find the dnn implementation)</td>
      <td>2022-12-20</td>
      <td>2022-12-20</td>
      <td>249</td>
      <td>249</td>
      <td>NONE</td>
      <td>0</td>
      <td>8097.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2618</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>618</td>
      <td>shap.DeepExplainer Error on LSM :  'TFDeep' object has no attribute 'between_tensors' Exception encountered when calling layer \"lstm\"</td>
      <td>2022-12-19</td>
      <td>2023-06-08</td>
      <td>250</td>
      <td>79</td>
      <td>NONE</td>
      <td>14</td>
      <td>8567.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>412</td>
      <td><a href="https://github.com/shap/shap/issues/5">5</a>12</td>
      <td>Not able to install using conda forge</td>
      <td>2019-01-25</td>
      <td>2019-08-11</td>
      <td>1674</td>
      <td>1476</td>
      <td>NONE</td>
      <td>5</td>
      <td>8858.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2591</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>591</td>
      <td>Could not compile cuda extensions on Linux Ubuntu 20.04</td>
      <td>2022-11-23</td>
      <td>2023-05-08</td>
      <td>276</td>
      <td>109</td>
      <td>NONE</td>
      <td>1</td>
      <td>9476.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2435</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>435</td>
      <td>DeepExplainer doesn't work with global_max_pooling1d</td>
      <td>2022-06-22</td>
      <td>2022-11-09</td>
      <td>430</td>
      <td>290</td>
      <td>NONE</td>
      <td>1</td>
      <td>10387.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>734</td>
      <td><a href="https://github.com/shap/shap/issues/8">8</a>34</td>
      <td>XGBoost GPU raise Segmentation Fault when explainer is instantiated.</td>
      <td>2019-08-07</td>
      <td>2020-02-14</td>
      <td>1479</td>
      <td>1289</td>
      <td>NONE</td>
      <td>5</td>
      <td>11356.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1715</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>715</td>
      <td>SHAP with sequences data.</td>
      <td>2021-01-19</td>
      <td>2021-01-19</td>
      <td>948</td>
      <td>948</td>
      <td>NONE</td>
      <td>0</td>
      <td>11395.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2050</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>050</td>
      <td>SHAP Values for Network with LSTM and Dense Layer Input Branches</td>
      <td>2021-08-25</td>
      <td>2022-11-08</td>
      <td>731</td>
      <td>291</td>
      <td>NONE</td>
      <td>2</td>
      <td>12039.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>538</td>
      <td><a href="https://github.com/shap/shap/issues/54">54</a>8</td>
      <td>pip install shap fail</td>
      <td>2019-04-08</td>
      <td>2021-04-08</td>
      <td>1600</td>
      <td>869</td>
      <td>NONE</td>
      <td>13</td>
      <td>13006.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1177</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>177</td>
      <td>error in shap installation</td>
      <td>2020-04-25</td>
      <td>2021-11-05</td>
      <td>1218</td>
      <td>659</td>
      <td>NONE</td>
      <td>9</td>
      <td>14270.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1342</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>342</td>
      <td>Front Page DeepExplainer MNIST tutorial is broken</td>
      <td>2020-08-03</td>
      <td>2021-06-17</td>
      <td>1118</td>
      <td>799</td>
      <td>NONE</td>
      <td>3</td>
      <td>15110.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1385</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>385</td>
      <td>cannot pip install shap or conda install -c conda-forge shap</td>
      <td>2020-08-27</td>
      <td>2021-04-08</td>
      <td>1094</td>
      <td>870</td>
      <td>NONE</td>
      <td>5</td>
      <td>16727.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1123</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>123</td>
      <td>Building wheel for shap (setup.py) ... error</td>
      <td>2020-03-30</td>
      <td>2023-07-28</td>
      <td>1244</td>
      <td>29</td>
      <td>NONE</td>
      <td>7</td>
      <td>17596.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>501</td>
      <td><a href="https://github.com/shap/shap/issues/51">51</a>1</td>
      <td>tensorflow:Cannot use 'gradients_2/f_count_1' as input to 'gradients_2/f_count' because they are in different while loops</td>
      <td>2019-03-21</td>
      <td>2023-08-26</td>
      <td>1619</td>
      <td>0</td>
      <td>NONE</td>
      <td>1</td>
      <td>20881.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2607</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>607</td>
      <td>using GradientExplainer with Inception_V3</td>
      <td>2022-12-12</td>
      <td>2022-12-12</td>
      <td>257</td>
      <td>257</td>
      <td>NONE</td>
      <td>0</td>
      <td>22516.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>1263</td>
      <td><a href="https://github.com/shap/shap/issues/2">2</a>263</td>
      <td>ERROR: Failed building wheel for shap while installing pycaret in anaconda prompt</td>
      <td>2020-06-11</td>
      <td>2020-06-11</td>
      <td>1170</td>
      <td>1170</td>
      <td>NONE</td>
      <td>0</td>
      <td>45459.0</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2070</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>070</td>
      <td>Cannot install shap on pycharm</td>
      <td>2021-09-15</td>
      <td>2022-08-09</td>
      <td>710</td>
      <td>382</td>
      <td>NONE</td>
      <td>4</td>
      <td>NaN</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2139</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>139</td>
      <td>Why I set n_samples = 0 for the shap.KernelExplainer, it can still give reasonable shapley value? Is the setting of n_samples invalid for the kernelshap class?</td>
      <td>2021-11-16</td>
      <td>2021-11-16</td>
      <td>647</td>
      <td>647</td>
      <td>NONE</td>
      <td>0</td>
      <td>NaN</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2188</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>188</td>
      <td>IS DeepExplainer able to draw all types of  interpreted images like the TreeExplainer?</td>
      <td>2021-12-16</td>
      <td>2021-12-16</td>
      <td>618</td>
      <td>618</td>
      <td>NONE</td>
      <td>0</td>
      <td>NaN</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2494</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>494</td>
      <td>How to apply SHAP specifically TreeExplainer on MultiOutputClassifier?</td>
      <td>2022-08-31</td>
      <td>2023-01-04</td>
      <td>360</td>
      <td>233</td>
      <td>NONE</td>
      <td>1</td>
      <td>NaN</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>2552</td>
      <td><a href="https://github.com/shap/shap/issues/3">3</a>552</td>
      <td>how to change the color of 'violin' plot in summary plot</td>
      <td>2022-10-16</td>
      <td>2023-01-10</td>
      <td>314</td>
      <td>228</td>
      <td>NONE</td>
      <td>2</td>
      <td>NaN</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>