{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\"../.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issue_reponses(title, body):\n",
    "    cost = 0\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=config[\"OPENAI_ENGINE\"], \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that is python master and have years of experience with github moderation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Is the description of issue good? \\ntitle: {title}\\nbody: {body}\\nAnswer with Yes/No as single word\"},\n",
    "        ]\n",
    "    )\n",
    "    description_quality = response['choices'][0]['message']['content']\n",
    "    cost += response['usage'][\"total_tokens\"]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=config[\"OPENAI_ENGINE\"], \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that is python master and have years of experience with github moderation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Give me one sentence summary of following issue, use ten words or less: \\ntitle: {title}\\nbody: {body}\"},\n",
    "        ]\n",
    "    )\n",
    "    summary = response['choices'][0]['message']['content']\n",
    "    cost += response['usage'][\"total_tokens\"]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=config[\"OPENAI_ENGINE\"], \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that is python master and have years of experience with github moderation. You are maintainer of shap package\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Suggest short label for this issue. Label should be of maximum two words: \\ntitle: {title}\\nbody: {body}\"},\n",
    "        ]\n",
    "    )\n",
    "    short_label = response['choices'][0]['message']['content']\n",
    "    cost += response['usage'][\"total_tokens\"]\n",
    "\n",
    "    issue_labels = [\n",
    "        \"bug\",\n",
    "        \"documentation\",\n",
    "        \"enhancement\",\n",
    "        \"good first issue\",\n",
    "        \"stale\"\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=config[\"OPENAI_ENGINE\"], \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that is python master and have years of experience with github moderation. You are maintainer of shap package\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Select label from {issue_labels}, where stale label is for issues that are too short and not clear: \\ntitle: {title}\\nbody: {body}\\nAnswer with label name from list and nothing else\"},\n",
    "        ]\n",
    "    )\n",
    "    label = response['choices'][0]['message']['content']\n",
    "    cost += response['usage'][\"total_tokens\"]\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    #     engine=config[\"OPENAI_ENGINE\"], \n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": \"You are a helpful assistant that is python master and have years of experience with github moderation. You are maintainer of shap package\"},\n",
    "    #         {\"role\": \"user\", \"content\": f\"Write first comment for: \\ntitle: {title}\\nbody: {body}\\n\"},\n",
    "    #     ]\n",
    "    # )\n",
    "    # comment = response['choices'][0]['message']['content']\n",
    "\n",
    "    return description_quality, summary, short_label, label, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = config[\"OPENAI_ENDPOINT\"]\n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = config[\"OPENAI_KEY\"]\n",
    "\n",
    "data = pl.read_json(\"../data/issues_v1.json\").filter(pl.col(\"number\").is_not_null()).sort(\"number\")\n",
    "data = data.with_columns([\n",
    "    pl.lit(\"\").alias(\"description_quality\"),\n",
    "    pl.lit(\"\").alias(\"summary\"),\n",
    "    pl.lit(\"\").alias(\"short_label\"),\n",
    "    pl.lit(\"\").alias(\"label\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "multiple exception types must be parenthesized (3163616539.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    except openai.error.RateLimitError, openai.error.APIConnectionError:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m multiple exception types must be parenthesized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    if data[i, \"summary\"] != \"\":\n",
    "        continue\n",
    "    row = data[i]\n",
    "    title = row[\"title\"]\n",
    "    body = row[\"body\"]\n",
    "    try:\n",
    "        description_quality, summary, short_label, label, tokens = get_issue_reponses(title, body)\n",
    "        data[i, \"description_quality\"] = description_quality\n",
    "        data[i, \"summary\"] = summary\n",
    "        data[i, \"short_label\"] = short_label\n",
    "        data[i, \"label\"] = label\n",
    "        total_tokens += tokens\n",
    "    except (openai.error.RateLimitError, openai.error.APIConnectionError):\n",
    "        time.sleep(20)\n",
    "        description_quality, summary, short_label, label, tokens = get_issue_reponses(title, body)\n",
    "        data[i, \"description_quality\"] = description_quality\n",
    "        data[i, \"summary\"] = summary\n",
    "        data[i, \"short_label\"] = short_label\n",
    "        data[i, \"label\"] = label\n",
    "        total_tokens += tokens\n",
    "    # print(f\"Total tokens: {total_tokens}\")\n",
    "    # print(f\"Average tokens per issue: {total_tokens / (i + 1)}\")\n",
    "    print(f\"Estimated cost: {total_tokens / 1000 * 0.028}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write_json(\"../data/issues_v1_gpt.json\", row_oriented=True, pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
